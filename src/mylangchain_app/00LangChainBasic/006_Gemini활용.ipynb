{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "네, AI 전문가로서 LangChain과 LangGraph에 대해 명확하고 깊이 있게 설명해 드리겠습니다.\n",
      "\n",
      "간단히 요약하자면, **LangChain은 LLM(거대 언어 모델) 애플리케이션을 만들기 위한 기본적인 '레고 블록'이고, LangGraph는 이 블록들을 이용해 복잡하고 순환적인 '작업 흐름도'를 만드는 도구**입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. LangChain: LLM 애플리케이션 개발의 기반 프레임워크\n",
      "\n",
      "**LangChain**은 LLM을 단독으로 사용하는 것을 넘어, 외부 데이터, 다른 API, 계산 능력 등과 결합하여 강력한 애플리케이션을 쉽게 만들 수 있도록 도와주는 **개발 프레임워크**입니다.\n",
      "\n",
      "LLM을 위한 '스위스 군용 칼'이라고 생각하시면 쉽습니다.\n",
      "\n",
      "#### **핵심 구성 요소 (레고 블록들):**\n",
      "\n",
      "1.  **Models**: OpenAI의 GPT, Anthropic의 Claude, Google의 Gemini 등 다양한 LLM을 쉽게 교체하며 사용할 수 있는 인터페이스를 제공합니다.\n",
      "2.  **Prompts**: LLM에 보낼 지시문(프롬프트)을 효과적으로 관리하고, 변수를 넣어 동적으로 생성할 수 있는 템플릿 기능을 제공합니다.\n",
      "3.  **Chains**: LangChain의 핵심 개념으로, LLM 호출과 다른 작업들을 **순차적으로** 연결하는 것을 의미합니다. 예를 들어, `(사용자 질문) -> (데이터베이스 검색) -> (검색 결과와 질문을 LLM에 전달) -> (최종 답변 생성)`과 같은 흐름을 하나의 '체인'으로 묶을 수 있습니다.\n",
      "4.  **Agents**: LLM을 단순히 텍스트 생성기가 아닌, **추론하는 엔진**으로 사용합니다. LLM이 스스로 어떤 '도구(Tool)'를 사용해야 할지 판단하고, 그 결과를 바탕으로 다음 행동을 결정하게 만듭니다. (예: \"오늘 파리 날씨를 알려주고, 한국 원화로 환산한 비행기표 값을 검색해줘\" -> 날씨 API 사용, 환율 API 사용, 검색 엔진 사용을 스스로 결정)\n",
      "5.  **RAG (Retrieval-Augmented Generation)**: LLM이 학습하지 않은 최신 정보나 특정 내부 문서에 대해 답변하게 하는 기술입니다. 외부 데이터 소스(PDF, DB 등)에서 관련 정보를 검색(Retrieval)한 후, 이 정보를 LLM에게 참고자료로 함께 주어 답변을 생성(Generation)하게 합니다.\n",
      "6.  **Memory**: 챗봇처럼 대화의 맥락을 기억하게 하는 기능입니다. 이전 대화 내용을 저장하고 다음 LLM 호출 시 함께 전달하여, 사용자와의 연속적인 상호작용을 가능하게 합니다.\n",
      "\n",
      "#### **LangChain의 한계:**\n",
      "\n",
      "기본적인 'Chain'은 **방향성이 있는 비순환 그래프(DAG, Directed Acyclic Graph)**, 즉 **한 방향으로만 흐르는 선형적인 구조**에 최적화되어 있습니다. 이 때문에 다음과 같은 복잡한 로직을 구현하기 어렵습니다.\n",
      "*   **순환(Cycle) 또는 루프(Loop)**: 특정 조건이 충족될 때까지 작업을 반복하는 것.\n",
      "*   **복잡한 분기**: 여러 에이전트가 서로 상의하며 결정을 내리는 것.\n",
      "*   **상태 수정**: 여러 단계에 걸쳐 공유되는 상태를 동적으로 수정하고 관리하는 것.\n",
      "\n",
      "이러한 한계를 극복하기 위해 등장한 것이 바로 LangGraph입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. LangGraph: 복잡한 LLM 워크플로우를 위한 상태 머신\n",
      "\n",
      "**LangGraph**는 LangChain 라이브러리를 기반으로, **주기적이고 상태 기반(Stateful)인 다중 에이전트(Multi-Agent) 애플리케이션**을 구축하기 위해 특별히 설계된 확장 라이브러리입니다.\n",
      "\n",
      "LangChain이 '레시피'라면, LangGraph는 여러 요리사가 협력하고, 맛을 보며 레시피를 수정해 나가는 '주방의 총괄 지휘 시스템'과 같습니다.\n",
      "\n",
      "#### **핵심 개념:**\n",
      "\n",
      "1.  **그래프(Graph) 구조**: LangGraph는 작업의 흐름을 '노드(Node)'와 '엣지(Edge)'로 구성된 그래프로 표현합니다.\n",
      "    *   **노드(Node)**: 특정 작업을 수행하는 단위입니다. 함수나 LangChain의 Chain이 될 수 있습니다. (예: '웹 검색 노드', '답변 생성 노드', '코드 작성 노드')\n",
      "    *   **엣지(Edge)**: 한 노드에서 다음 노드로 어떻게 이동할지를 결정하는 **조건부 로직**입니다. 이 엣지 덕분에 순환과 분기가 가능해집니다.\n",
      "\n",
      "2.  **상태(State)**: 그래프의 모든 노드가 공유하는 **중앙 데이터 저장소**입니다. 각 노드는 이 '상태' 객체를 읽고, 자신의 작업 결과를 '상태'에 업데이트합니다. 이로써 전체 작업 흐름 동안 정보가 지속적으로 유지되고 수정될 수 있습니다.\n",
      "\n",
      "#### **LangGraph가 강력한 이유:**\n",
      "\n",
      "*   **순환 및 루프 구현**: \"결과가 만족스럽지 않으면, 웹 검색 노드로 다시 돌아가라\"와 같은 루프를 쉽게 만들 수 있습니다. 에이전트가 스스로 계획을 수정하고 작업을 반복하는 데 필수적입니다.\n",
      "*   **다중 에이전트 협업**: '기획자 에이전트'가 계획을 세워 상태에 저장하면, '개발자 에이전트'가 그 계획을 보고 코드를 작성하고, '리뷰어 에이전트'가 코드를 검토하는 식의 복잡한 협업 워크플로우를 만들 수 있습니다. 각 에이전트는 노드가 되고, 엣지는 이들 간의 상호작용을 제어합니다.\n",
      "*   **인간의 개입(Human-in-the-loop)**: 특정 노드에서 실행을 멈추고 사용자에게 확인이나 수정을 요청한 뒤, 그 피드백을 바탕으로 다음 작업을 이어가는 흐름을 쉽게 구현할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 핵심 차이점 및 관계 요약\n",
      "\n",
      "| 구분 | **LangChain** | **LangGraph** |\n",
      "| :--- | :--- | :--- |\n",
      "| **핵심 추상화** | **체인 (Chain)** | **그래프 (Graph)** |\n",
      "| **작업 흐름** | **선형적, 순차적 (DAG)** | **순환적, 비선형적, 상태 기반** |\n",
      "| **주요 용도** | 간단한 RAG, 요약, 질의응답 등 단일 목적의 LLM 애플리케이션 | 다중 에이전트 시스템, 자가 수정 코드 생성, 복잡한 리서치 자동화 등 |\n",
      "| **상태 관리** | 비교적 단순 (주로 Memory 객체에 의존) | 명시적이고 중앙화된 상태 객체를 통해 전체 그래프가 공유 |\n",
      "| **관계** | **기반 프레임워크** | LangChain 위에 구축된 **확장 라이브러리** |\n",
      "\n",
      "### 결론\n",
      "\n",
      "**LangChain**은 LLM을 활용한 애플리케이션을 만들기 위한 필수적인 **기본 도구 모음**입니다. 대부분의 LLM 기반 기능을 만들 때 LangChain으로 시작하게 됩니다.\n",
      "\n",
      "그러다 애플리케이션이 고도화되어 여러 에이전트가 서로 소통하거나, 작업 계획을 동적으로 수정하고, 특정 작업을 반복해야 하는 등 **복잡한 제어 흐름**이 필요해지면, **LangGraph**를 도입하여 이러한 동적이고 순환적인 워크플로우를 효과적으로 구축할 수 있습니다.\n",
      "\n",
      "즉, **LangChain으로 부품을 만들고, LangGraph로 이 부품들을 지능적으로 조립하여 복잡한 기계를 완성**한다고 이해하시면 가장 정확합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",  # 또는 \"gemini-pro-vision\"\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain과 LangGraph\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-1.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "예제 1: 기본 대화형 챗봇\n",
      "==================================================\n",
      "응답:  파이썬에서 리스트를 정렬하는 방법은 여러 가지가 있습니다. 가장 일반적인 방법은 `list.sort()` 메서드와 `sorted()` 함수를 사용하는 것입니다.\n",
      "\n",
      "**1. `list.sort()` 메서드**\n",
      "\n",
      "`list.sort()` 메서드는 리스트 자체를 제자리에서 정렬합니다. 즉, 원본 리스트가 변경됩니다.  새로운 리스트를 반환하지 않습니다.\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "my_list.sort()\n",
      "print(my_list)  # 출력: [1, 1, 2, 3, 4, 5, 6, 9]\n",
      "```\n",
      "\n",
      "`reverse=True` 인수를 사용하여 내림차순으로 정렬할 수 있습니다.\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "my_list.sort(reverse=True)\n",
      "print(my_list)  # 출력: [9, 6, 5, 4, 3, 2, 1, 1]\n",
      "```\n",
      "\n",
      "`key` 인수를 사용하여 정렬 기준을 지정할 수 있습니다. 예를 들어, 문자열 리스트를 길이 순으로 정렬하려면 다음과 같이 합니다.\n",
      "\n",
      "```python\n",
      "my_list = [\"apple\", \"banana\", \"kiwi\", \"orange\"]\n",
      "my_list.sort(key=len)\n",
      "print(my_list)  # 출력: ['kiwi', 'apple', 'orange', 'banana']\n",
      "```\n",
      "\n",
      "\n",
      "**2. `sorted()` 함수**\n",
      "\n",
      "`sorted()` 함수는 원본 리스트를 변경하지 않고 정렬된 새로운 리스트를 반환합니다.\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "sorted_list = sorted(my_list)\n",
      "print(my_list)      # 출력: [3, 1, 4, 1, 5, 9, 2, 6] (원본 리스트는 변경되지 않음)\n",
      "print(sorted_list)  # 출력: [1, 1, 2, 3, 4, 5, 6, 9] (정렬된 새로운 리스트)\n",
      "```\n",
      "\n",
      "`sorted()` 함수도 `reverse=True` 와 `key` 인수를 지원합니다.  `list.sort()`와 동일한 방식으로 사용할 수 있습니다.\n",
      "\n",
      "\n",
      "**어떤 방법을 사용해야 할까요?**\n",
      "\n",
      "* 원본 리스트를 변경하지 않고 정렬된 새로운 리스트를 얻고 싶다면 `sorted()` 함수를 사용하세요.\n",
      "* 원본 리스트를 직접 정렬하고 메모리를 절약하고 싶다면 `list.sort()` 메서드를 사용하세요.  `list.sort()`는 일반적으로 `sorted()` 함수보다 약간 더 효율적입니다.\n",
      "\n",
      "\n",
      "어떤 방법을 선택하든,  자신의 코드와 상황에 맞는 방법을 선택하는 것이 중요합니다.  필요에 따라 `reverse` 와 `key` 인수를 적절히 사용하면 더욱 유연하게 리스트를 정렬할 수 있습니다.  궁금한 점이 있다면 더 질문해 주세요!\n",
      "\n",
      "==================================================\n",
      "예제 2: JSON 구조화 출력\n",
      "==================================================\n",
      "JSON 결과: ```json\n",
      "{\"name\": \"네이버\", \"year\": \"1999\", \"location\": \"경기도 성남\"}\n",
      "```\n",
      "\n",
      "==================================================\n",
      "예제 3: 번역 체인\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2331af30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번역 결과: 안녕하세요, 오늘 어떻게 지내세요?\n",
      "\n",
      "==================================================\n",
      "예제 4: 감정 분석\n",
      "==================================================\n",
      "감정 분석: 긍정, 10점\n",
      "\n",
      "==================================================\n",
      "예제 5: 코드 생성\n",
      "==================================================\n",
      "생성된 코드:\n",
      "유클리드 호제법을 사용하는 가장 간단한 방법은 다음과 같습니다.\n",
      "\n",
      "```python\n",
      "def gcd(a, b):\n",
      "  \"\"\"유클리드 호제법을 사용하여 두 숫자의 최대공약수를 계산합니다.\"\"\"\n",
      "  while(b):\n",
      "    a, b = b, a % b\n",
      "  return a\n",
      "\n",
      "# 예시\n",
      "num1 = 48\n",
      "num2 = 18\n",
      "result = gcd(num1, num2)\n",
      "print(f\"{num1}과 {num2}의 최대공약수는 {result}입니다.\")\n",
      "\n",
      "num1 = 100\n",
      "num2 = 50\n",
      "result = gcd(num1, num2)\n",
      "print(f\"{num1}과 {num2}의 최대공약수는 {result}입니다.\")\n",
      "\n",
      "num1 = 17\n",
      "num2 = 23\n",
      "result = gcd(num1, num2)\n",
      "print(f\"{num1}과 {num2}의 최대공약수는 {result}입니다.\")\n",
      "\n",
      "```\n",
      "\n",
      "이 코드는 재귀를 사용하지 않고 반복문으로 유클리드 호제법을 구현하여 효율성을 높였습니다.  `while(b):` 루프는 `b`가 0이 될 때까지 계속되며,  `a % b`는 `a`를 `b`로 나눈 나머지를 계산합니다.  최종적으로 `a`에 최대공약수가 저장됩니다.\n",
      "\n",
      "\n",
      "다른 방법으로 재귀 함수를 사용할 수도 있지만, 위의 반복문 방식이 더 효율적입니다.  재귀 방식은 다음과 같습니다.\n",
      "\n",
      "```python\n",
      "def gcd_recursive(a, b):\n",
      "  \"\"\"재귀 함수를 사용하여 두 숫자의 최대공약수를 계산합니다.\"\"\"\n",
      "  if b == 0:\n",
      "    return a\n",
      "  else:\n",
      "    return gcd_recursive(b, a % b)\n",
      "```\n",
      "\n",
      "두 함수 모두 동일한 결과를 반환하지만, 큰 숫자를 다룰 때는 반복문 방식이 스택 오버플로우를 방지하는 데 더 안전합니다.  따라서 일반적으로 첫 번째 방법을 추천합니다.\n",
      "\n",
      "==================================================\n",
      "예제 6: 창의적 콘텐츠 생성\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001da18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "창의적 아이디어: ## 스카이로드: 도심 상공을 가로지르는 자기 부상 열차\n",
      "\n",
      "**개념:** 스카이로드는 도심 상공에 설치된 자기 부상 레일을 따라 운행되는 친환경 대중교통 시스템입니다.  지상 교통 체증을 완전히 우회하며, 고속으로 목적지까지 안전하게 이동할 수 있도록 설계되었습니다.\n",
      "\n",
      "**혁신적인 요소:**\n",
      "\n",
      "* **자기 부상 기술:**  초전도 자석을 이용한 자기 부상 기술을 통해 마찰을 최소화하고 고속 운행과 저소음 운행을 동시에 달성합니다. 기존의 자기 부상 열차보다 더욱 효율적이고 안정적인 시스템을 구축하기 위해, 차세대 초전도 재료 및 에너지 관리 시스템을 통합합니다.\n",
      "* **모듈형 레일 시스템:**  도심 구조에 맞춰 레일을 유연하게 설치하고 확장할 수 있는 모듈형 시스템을 채택합니다. 건물과 건물 사이, 혹은 기존 교량을 활용하여 건설 비용을 절감하고 설치 시간을 단축합니다.  레일은 태양광 패널을 통합하여 자체 전력을 생산하는 친환경 시스템으로 설계됩니다.\n",
      "* **개방형 캡슐 디자인:**  승객들은 캡슐형 차량 내에서 360도 파노라마 도심 전망을 즐길 수 있습니다. 캡슐 내부는 개인 맞춤형 조명과 온도 조절 시스템을 갖추고 있으며, Wi-Fi 및 엔터테인먼트 시스템도 제공합니다.  캡슐은 필요에 따라 크기와 용량을 조절할 수 있는 모듈형 구조로 설계됩니다.\n",
      "* **AI 기반 운영 시스템:**  AI 기반 운영 시스템은 실시간 교통량을 분석하여 최적의 경로를 설정하고, 차량 간 간격을 조절하며, 에너지 소비를 최소화합니다. 또한, 승객들의 이동 패턴을 예측하여 효율적인 배차 시스템을 운영합니다.\n",
      "* **안전 시스템:**  다중 안전 시스템이 탑재되어 만약의 사고 발생 시에도 신속하고 안전하게 대처할 수 있도록 설계됩니다.  비상 착륙 장치와 긴급 통신 시스템 등이 포함됩니다.\n",
      "\n",
      "\n",
      "**실현 가능성:**\n",
      "\n",
      "* **기존 기술 활용:**  자기 부상 기술은 이미 상용화된 기술이며, 지속적인 발전을 통해 더욱 안정적이고 효율적인 시스템 구축이 가능합니다.\n",
      "* **단계적 구축:**  도심의 특정 구역부터 시범적으로 구축하여 운영 효율성을 검증하고, 점차적으로 확장하는 단계적 접근 방식을 통해 위험 부담을 최소화합니다.\n",
      "* **정부 지원:**  친환경 교통 시스템 구축에 대한 정부의 적극적인 지원과 투자를 통해 프로젝트 추진에 필요한 자금을 확보할 수 있습니다.\n",
      "* **민간 투자 유치:**  스카이로드는 새로운 대중교통 시스템으로서 큰 사업적 가능성을 가지고 있으며, 민간 투자를 유치하여 프로젝트를 성공적으로 추진할 수 있습니다.\n",
      "\n",
      "\n",
      "스카이로드는 단순한 교통수단이 아닌, 미래 도시의 새로운 랜드마크가 될 수 있습니다.  도심의 혼잡을 해소하고, 환경 보호에 기여하며, 시민들에게 편리하고 쾌적한 이동 경험을 제공하는 혁신적인 교통 시스템으로 자리매김할 것입니다.\n",
      "\n",
      "==================================================\n",
      "Gemini 모델 옵션\n",
      "==================================================\n",
      "• gemini-1.5-flash: 빠른 응답, 일반 작업\n",
      "• gemini-1.5-pro: 정확한 분석, 복잡한 추론\n",
      "• gemini-pro-vision: 이미지 처리 가능\n",
      "• temperature: 0.1(정확) ~ 0.9(창의적)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
