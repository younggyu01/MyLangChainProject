{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 방대한 텍스트 데이터를 이용해 다음에 올 단어를 예측하도록 사전학습(pre‑training)된 '\n",
      " '트랜스포머(Transformer) 모델입니다. 사전학습 후에는 인간 피드백을 기반으로 보상 모델을 만들고, 이를 통해 정책을 최적화하는 '\n",
      " '강화학습(RLHF) 과정을 거쳐 대화에 적합하도록 미세조정됩니다. 이렇게 학습된 파라미터들은 입력 문맥을 고려해 가장 자연스럽고 의미 '\n",
      " '있는 답변을 생성하도록 작동합니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"openai/gpt-oss-120b\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('**ChatGPT 모델의 학습 원리 (3문장)**  \\n'\n",
      " '1. 대규모 텍스트 데이터셋을 이용해 **자기 지도 학습**(self‑supervised learning) 방식으로 사전 '\n",
      " '학습(pre‑training)한다.  \\n'\n",
      " '2. 사전 학습 단계에서 모델은 문맥을 예측하도록 토큰을 마스킹하거나 다음 토큰을 맞추는 과제를 수행해 언어 패턴과 의미 관계를 '\n",
      " '학습한다.  \\n'\n",
      " '3. 이후 특정 작업에 맞게 **지도 학습**(fine‑tuning)이나 강화 학습(RLHF) 등을 통해 사용자 의도에 부합하도록 미세 '\n",
      " '조정한다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT 모델의 장점 요약  \\n'\n",
      " '\\n'\n",
      " '- **다양한 주제와 언어에 대한 높은 이해도**: 방대한 텍스트와 다양한 도메인 데이터를 학습해 폭넓은 지식과 문맥 파악 능력을 '\n",
      " '갖춤.  \\n'\n",
      " '- **자연스러운 대화 흐름**: 문맥을 유지하면서 일관된 답변을 생성하고, 질문 의도를 파악해 적절한 수준과 톤으로 응답함.  \\n'\n",
      " '- **확장성과 커스터마이징**: 사전 학습된 모델을 기반으로 특정 분야에 맞게 파인튜닝하거나, 플러그인·API를 통해 다양한 '\n",
      " '애플리케이션에 쉽게 통합 가능.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT와 비슷한 AI 모델 (영어 모델명)\\n'\n",
      " '\\n'\n",
      " '- **GPT‑4** (OpenAI)  \\n'\n",
      " '- **Claude** (Anthropic)  \\n'\n",
      " '- **Llama 2** (Meta)  \\n'\n",
      " '- **Gemma** (Google DeepMind)  \\n'\n",
      " '- **Mistral** (Mistral AI)  \\n'\n",
      " '- **Phi‑2** (Microsoft)  \\n'\n",
      " '- **BLOOM** (BigScience)  \\n'\n",
      " '- **Jasper** (Cohere)  \\n'\n",
      " '\\n'\n",
      " '이 모델들은 모두 트랜스포머 기반의 대규모 언어 모델이며, 사전 학습 후 파인튜닝이나 RLHF 등으로 대화형 AI 혹은 다양한 자연어 '\n",
      " '처리 작업에 활용됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Anima 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'Figma 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT‑4는 방대한 인터넷 텍스트 데이터를 수집해, 다음에 올 단어를 예측하도록 스스로 학습하는 **자기지도(pre‑training)** '\n",
      " '과정을 거칩니다. 이후 인간이 만든 질문‑답변 쌍이나 피드백을 이용해 모델의 출력을 조정하는 **지도학습(fine‑tuning)** 및 '\n",
      " '인간 피드백을 반영해 보상을 최적화하는 **강화학습(RLHF)** 을 적용해 실제 사용 상황에 맞는 응답 품질을 높입니다. 이렇게 두 '\n",
      " '단계의 학습을 반복하면서 모델은 언어 구조와 의미를 일반화하고, 다양한 과업에 적용 가능한 범용 인공지능으로 발전합니다.')\n",
      "<class 'str'> Anima 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Anima 모델은 대규모 텍스트 데이터를 사전 학습(pre‑training)하여 언어의 통계적 패턴과 의미 관계를 학습합니다.  \\n'\n",
      " '그 후, 특정 작업에 맞게 라벨이 부착된 데이터셋을 이용해 지도 학습(supervised fine‑tuning)이나 인간 피드백을 반영한 '\n",
      " '강화 학습(RLHF)으로 성능을 최적화합니다.  \\n'\n",
      " '학습 과정에서는 손실 함수(loss function)를 최소화하도록 가중치를 역전파(backpropagation)하고, 옵티마이저가 '\n",
      " '파라미터를 업데이트합니다.  \\n'\n",
      " '이러한 단계들을 반복하면서 모델은 점차 더 정확하고 일관된 언어 이해·생성 능력을 갖추게 됩니다.')\n",
      "<class 'str'> Figma 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Figma 모델은 대량의 이미지와 텍스트 데이터 쌍을 이용해 사전 학습됩니다.  \\n'\n",
      " '학습 과정에서 텍스트 프롬프트를 입력하면 해당 설명에 맞는 시각적 특징을 추출하도록 이미지 인코더와 텍스트 인코더를 동시에 '\n",
      " '최적화합니다.  \\n'\n",
      " '그 후, 확산 모델(denoising diffusion model)을 사용해 노이즈가 섞인 초기 이미지에서 점진적으로 디노이징하면서 '\n",
      " '원하는 이미지로 변환합니다.  \\n'\n",
      " '최종적으로, 사용자의 프롬프트와 일치하는 고해상도 이미지를 생성하도록 반복적인 역전파와 샘플링 과정을 거칩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Anima\", \"count\": 4},\n",
    "    {\"model_name\": \"Figma\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## ChatGPT 모델의 학습 원리  \n",
      "(한국어로 자세히 설명합니다)\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 전체 흐름\n",
      "\n",
      "ChatGPT와 같은 대형 언어 모델(LLM)은 크게 **세 단계**로 학습됩니다.\n",
      "\n",
      "| 단계 | 목적 | 주요 방법 |\n",
      "|------|------|-----------|\n",
      "| **① 사전학습 (Pre‑training)** | 방대한 텍스트 데이터를 통해 **언어의 일반적인 패턴**을 습득 | 자기지도 학습 (self‑supervised), 토큰 예측 (next‑token prediction) |\n",
      "| **② 지도학습 (Supervised Fine‑tuning, SFT)** | 모델을 **대화형** 혹은 **특정 태스크**에 맞게 조정 | 인간이 만든 질문‑답변 쌍을 이용해 지도학습 |\n",
      "| **③ 인간 피드백 기반 강화학습 (RLHF)** | 모델이 **사용자 의도**에 맞는, **친절하고 안전한** 출력을 생성하도록 최적화 | 인간 평가자·시스템이 만든 보상 모델을 이용해 강화학습 수행 |\n",
      "\n",
      "각 단계는 앞 단계에서 얻은 지식을 바탕으로 점진적으로 특화됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 사전학습 (Pre‑training)\n",
      "\n",
      "#### 2.1 데이터\n",
      "- **규모**: 수조(token) 수준, 웹 페이지, 책, 논문, 위키피디아, 포럼, 코드 저장소 등 다양한 출처\n",
      "- **전처리**:  \n",
      "  - **토크나이징** → 텍스트를 **토큰**(보통 서브워드) 단위로 변환  \n",
      "  - **정제**: 저작권 문제, 개인 정보, 명시적 불법·폭력·혐오 콘텐츠 제거  \n",
      "  - **샘플링**: 데이터 편향을 완화하기 위해 다양한 도메인·언어 비율을 조정\n",
      "\n",
      "#### 2.2 모델 아키텍처\n",
      "- **Transformer** (Vaswani et al., 2017) 기반의 **디코더**만 사용 (GPT 시리즈)\n",
      "- 핵심 구성 요소  \n",
      "  - **멀티‑헤드 셀프‑어텐션**: 각 토큰이 문맥 전체와 어떻게 연관되는지 학습  \n",
      "  - **피드‑포워드 네트워크 (FFN)**: 비선형 변환으로 표현력 강화  \n",
      "  - **잔차 연결 + 레이어 정규화**: 학습 안정성 및 깊은 네트워크 학습 가능하게 함  \n",
      "- **스케일링**: 파라미터 수(수억~수천억), 레이어 수, 헤드 수, 은닉 차원 등을 크게 늘려 성능 향상\n",
      "\n",
      "#### 2.3 학습 목표 (Loss)\n",
      "- **다음 토큰 예측**:  \n",
      "  \\[\n",
      "  \\mathcal{L}_{\\text{LM}} = -\\sum_{t=1}^{T} \\log P_{\\theta}(x_t \\mid x_{<t})\n",
      "  \\]\n",
      "  - 여기서 \\(x_t\\)는 t번째 토큰, \\(\\theta\\)는 모델 파라미터\n",
      "- **교차 엔트로피 손실**을 최소화하면서, 모델은 **조건부 확률 분포** \\(P_{\\theta}(x_t|x_{<t})\\) 를 학습\n",
      "- **샘플링 전략**(예: 토큰 마스킹, 시퀀스 길이 변형)으로 다양한 문맥을 경험하게 함\n",
      "\n",
      "#### 2.4 학습 인프라\n",
      "- **GPU/TPU 클러스터**: 수천 개의 가속기, 데이터 병렬 및 모델 병렬(ZeRO, FSDP 등) 사용\n",
      "- **학습 스케줄**: **AdamW** 옵티마이저 + **학습률 워밍업 → 라디얼 감소**  \n",
      "- **혼합 정밀도**(FP16/ BF16) → 메모리 절감 및 속도 향상\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 지도학습 (Supervised Fine‑tuning, SFT)\n",
      "\n",
      "#### 3.1 목적\n",
      "- 사전학습된 모델을 **대화** 혹은 **특정 작업**에 맞게 조정\n",
      "- “질문 → 답변” 형태의 데이터로 **사용자 기대에 부합하는** 출력을 학습\n",
      "\n",
      "#### 3.2 데이터 구성\n",
      "- **프롬프트‑응답 쌍**: 인간 라벨러가 만든 고품질 대화 예시\n",
      "- **시스템 프롬프트**: 모델에게 역할(예: “친절한 어시스턴트”)을 명시\n",
      "- **다양성**: 여러 도메인·톤·난이도 포함 → 일반화 능력 유지\n",
      "\n",
      "#### 3.3 학습 방법\n",
      "- **교차 엔트로피 손실**을 그대로 사용하지만 입력은 **프롬프트 + 답변** 전체 시퀀스로 구성\n",
      "- **Teacher‑forcing**: 정답 토큰을 바로 다음 입력에 사용해 빠른 수렴 유도\n",
      "- **학습률**은 사전학습보다 낮게 설정 (보통 1e‑5~1e‑4)\n",
      "\n",
      "---\n",
      "\n",
      "### 4. 인간 피드백 기반 강화학습 (RLHF)\n",
      "\n",
      "#### 4.1 왜 RLHF가 필요한가?\n",
      "- 단순히 정답을 맞추는 것이 아니라 **사용자 의도, 안전성, 윤리성**을 고려한 출력이 필요\n",
      "- 지도학습만으로는 **다양한 상황**에서 최적 행동을 정의하기 어려움\n",
      "\n",
      "#### 4.2 구성 요소\n",
      "1. **Reward Model (보상 모델)**  \n",
      "   - 인간 라벨러가 여러 모델 출력(예: 2~3가지 답변)을 **선호도 순위**로 평가  \n",
      "   - 이 순위를 **쌍wise 비교** 형태로 변환하고, **PPO**(Proximal Policy Optimization) 등으로 학습  \n",
      "   - 보상 함수 \\(R_{\\phi}(y|x)\\)는 “얼마나 좋은 답변인가”를 점수화\n",
      "\n",
      "2. **Policy Model (정책 모델)**  \n",
      "   - 초기에는 SFT 단계에서 얻은 모델을 사용  \n",
      "   - **강화학습**을 통해 보상 모델이 주는 점수를 최대화하도록 파라미터 \\(\\theta\\)를 업데이트\n",
      "\n",
      "#### 4.3 PPO 기반 강화학습 흐름\n",
      "1. **샘플 생성**: 현재 정책 \\(\\pi_{\\theta}\\) 로 프롬프트에 대한 답변 \\(y\\) 를 여러 개 생성\n",
      "2. **보상 계산**: 보상 모델 \\(R_{\\phi}(y|x)\\) 로 각 답변에 점수 부여\n",
      "3. **클립된 목적 함수**:\n",
      "   \\[\n",
      "   L^{\\text{PPO}}(\\theta) = \\mathbb{E}\\!\\left[ \\min\\!\\big( r_t(\\theta) \\hat{A}_t, \\text{clip}(r_t(\\theta),1-\\epsilon,1+\\epsilon)\\hat{A}_t \\big) \\right]\n",
      "   \\]\n",
      "   - 여기서 \\(r_t(\\theta)=\\frac{\\pi_{\\theta}(a_t|s_t)}{\\pi_{\\theta_{\\text{old}}}(a_t|s_t)}\\) (importance ratio)  \n",
      "   - \\(\\hat{A}_t\\)는 **Advantage** (보상 - 가치 추정)  \n",
      "   - \\(\\epsilon\\)은 클리핑 파라미터 (보통 0.2)\n",
      "\n",
      "4. **값 함수와 엔트로피 보너스**도 함께 최적화해 **안정성**과 **다양성**을 유지\n",
      "\n",
      "#### 4.4 결과\n",
      "- 모델은 “**사용자에게 도움이 되면서도 안전하고**” 하는 방향으로 행동을 조정\n",
      "- 실제 서비스에서는 **다중 라운드 대화**, **컨텍스트 유지**, **거부 응답**(예: 정책 위반 질문에 대한 거절) 등도 RLHF를 통해 학습\n",
      "\n",
      "---\n",
      "\n",
      "### 5. 토큰화와 어휘 (Tokenizer & Vocabulary)\n",
      "\n",
      "- **Byte‑Pair Encoding (BPE)** 혹은 **SentencePiece** 기반 **subword** 토크나이저 사용  \n",
      "- 장점  \n",
      "  - **어휘 크기**를 수만~수십만 수준으로 제한하면서도 **희귀 단어**를 표현 가능  \n",
      "  - **다국어** 모델에서는 **Unicode 기반** 토크나이저가 한 번에 여러 언어를 다룸\n",
      "- **특수 토큰**:  \n",
      "  - `` → 문장/문서 종료  \n",
      "  - `<|assistant|>` 등 시스템/역할 구분 토큰  \n",
      "\n",
      "---\n",
      "\n",
      "### 6. 안전성·윤리·편향 관리\n",
      "\n",
      "1. **데이터 필터링**: 폭력·혐오·음란·허위 정보 등을 사전 차단\n",
      "2. **후처리(정책 엔진)**: 모델 출력이 정책을 위반하면 차단·수정\n",
      "3. **편향 완화**:  \n",
      "   - **데이터 균형**(다양한 문화·성별·연령) 확보  \n",
      "   - **디버깅**: 특정 프롬프트에 대한 편향 응답을 자동 탐지·수정\n",
      "4. **인간 검토**: 고위험 상황(법률·의료 등)에서는 인간 전문가가 최종 검증\n",
      "\n",
      "---\n",
      "\n",
      "### 7. 요약 흐름도\n",
      "\n",
      "```\n",
      "대규모 텍스트 데이터\n",
      "   │\n",
      "   ▼ (토크나이징, 정제)\n",
      "사전학습 (Self‑Supervised LM)\n",
      "   │\n",
      "   ▼ (프롬프트‑답변 데이터)\n",
      "지도학습 (SFT)  ←─ 인간 라벨러가 만든 QA/대화 데이터\n",
      "   │\n",
      "   ▼ (인간 평가 → 보상 모델)\n",
      "RLHF (PPO)  ←─ 보상 모델과 정책 모델을 반복적으로 업데이트\n",
      "   │\n",
      "   ▼\n",
      "배포된 ChatGPT (안전·편향 관리 + 모니터링)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 핵심 포인트 정리\n",
      "\n",
      "| 단계 | 핵심 내용 |\n",
      "|------|-----------|\n",
      "| **사전학습** | 방대한 텍스트를 **다음 토큰 예측**으로 학습 → 언어 일반 지식 습득 |\n",
      "| **지도학습** | 인간이 만든 **대화 예시**로 모델을 **대화형**으로 조정 |\n",
      "| **RLHF** | 인간 피드백 → **보상 모델** → **PPO** 로 정책을 최적화 → **사용자 의도·안전**에 부합 |\n",
      "| **토크나이저** | Subword 기반 → 어휘 크기 제한 + 희귀어 표현 |\n",
      "| **안전·편향** | 데이터 필터링, 정책 엔진, 편향 완화, 인간 검토 등 다중 레이어로 관리 |\n",
      "\n",
      "---\n",
      "\n",
      "### 참고 문헌 (핵심 논문·리소스)\n",
      "\n",
      "1. **Vaswani et al., 2017** – *Attention is All You Need* (Transformer 기본)\n",
      "2. **Radford et al., 2018/2019/2021** – GPT‑1, GPT‑2, GPT‑3 논문\n",
      "3. **Ouyang et al., 2022** – *Training language models to follow instructions with human feedback* (RLHF 소개)\n",
      "4. **Stiennon et al., 2020** – *Learning to summarize with human feedback* (RLHF 초기 사례)\n",
      "5. **OpenAI Cookbook** – 실제 구현 예시와 파라미터 튜닝 팁\n",
      "\n",
      "---\n",
      "\n",
      "**끝으로**, ChatGPT는 **대규모 사전학습 → 대화 특화 지도학습 → 인간 피드백 기반 강화학습**이라는 3단계 파이프라인을 통해 “언어를 이해하고, 대화를 이어가며, 사용자의 의도에 맞는 안전한 답변을 생성”하는 능력을 갖추게 됩니다. 궁금한 점이 더 있으면 언제든 질문해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## ChatGPT 모델이 어떻게 학습되는지 단계별로 살펴보기  \n",
      "\n",
      "아래 내용은 **Transformer 기반 대규모 언어 모델**(예: GPT‑4, GPT‑3.5 등)이 훈련되는 전형적인 과정을 한국어로 정리한 것입니다. 핵심 흐름은 크게 **데이터 준비 → 사전 학습(Pre‑training) → 지도 학습( supervised fine‑tuning) → 강화 학습(RLHF)** 로 나눌 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 데이터 준비 (Corpus Construction)\n",
      "\n",
      "| 요소 | 설명 |\n",
      "|------|------|\n",
      "| **대규모 텍스트 코퍼스** | 인터넷 웹페이지, 책, 논문, 뉴스, 위키피디아, 포럼, 코드 저장소 등 다양한 출처에서 수십억 토큰 규모의 텍스트를 수집합니다. |\n",
      "| **클렌징 & 필터링** | 저작권 위반, 개인 정보, 폭력·혐오 표현 등 부적절한 내용은 자동·수동으로 제거합니다. 또한 중복 문서, HTML 태그, 스크립트 등 비텍스트 요소를 정리합니다. |\n",
      "| **토크나이징 (Tokenization)** | 텍스트를 **Byte‑Pair Encoding (BPE)** 혹은 **SentencePiece**와 같은 서브워드 토크나이저로 변환합니다. 하나의 토큰은 보통 1~4개의 문자(영문 기준) 또는 한글 자모·음절을 포함합니다. |\n",
      "| **데이터 샤플링** | 학습 효율과 편향 감소를 위해 전체 코퍼스를 여러 작은 청크(chunk)로 나누고, 각 청크를 무작위로 섞어 학습 배치를 구성합니다. |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 사전 학습 (Pre‑training) – **자기지도 학습 (Self‑Supervised Learning)**  \n",
      "\n",
      "#### 2.1 목표 함수 (Loss Function)\n",
      "- **다음 토큰 예측 (Causal Language Modeling)**  \n",
      "  \\[\n",
      "  \\mathcal{L}_{\\text{LM}} = -\\sum_{t=1}^{T}\\log P\\big(x_t \\mid x_{<t}; \\theta\\big)\n",
      "  \\]\n",
      "  여기서 \\(x_t\\)는 t번째 토큰, \\(\\theta\\)는 모델 파라미터, \\(x_{<t}\\)는 앞선 토큰들입니다. 모델은 **조건부 확률**을 학습해 “앞 문맥이 주어졌을 때 다음에 올 토큰은 무엇인가?”를 예측합니다.\n",
      "\n",
      "#### 2.2 모델 아키텍처\n",
      "- **Transformer Decoder**  \n",
      "  - **멀티‑헤드 어텐션**: 입력 시퀀스 전체에 대해 각 토큰이 다른 토큰을 얼마나 “참고”해야 하는지 가중치를 학습합니다.  \n",
      "  - **포지셔널 인코딩**: 순서 정보를 추가해 토큰 위치를 구분합니다.  \n",
      "  - **피드‑포워드 레이어**: 각 토큰에 독립적인 비선형 변환을 적용합니다.  \n",
      "  - **Layer Normalization + Residual Connection**: 학습 안정성 및 깊은 네트워크 전파를 돕습니다.\n",
      "\n",
      "#### 2.3 학습 세부 사항\n",
      "| 항목 | 설명 |\n",
      "|------|------|\n",
      "| **배치 크기 (Batch Size)** | 수천~수만 시퀀스 (GPU/TPU 클러스터 사용) |\n",
      "| **학습률 스케줄** | **Warm‑up** 단계 (예: 10k step) → **Cosine decay** 혹은 **Linear decay** |\n",
      "| **옵티마이저** | **AdamW** (weight decay 포함) |\n",
      "| **Mixed‑precision (FP16/ BF16)** | 메모리 절감 및 연산 속도 향상 |\n",
      "| **분산 학습** | 데이터 병렬(Data Parallel) + 모델 병렬(Model Parallel) 혹은 **ZeRO**와 같은 파라미터 셰어링 기법 사용 |\n",
      "\n",
      "#### 2.4 결과\n",
      "- 모델은 **언어 구조(문법, 어휘, 상식)**와 **통계적 패턴**을 내재화합니다.  \n",
      "- 아직 **특정 목표**(예: 질문‑답변, 대화)와는 무관한 **일반적인 텍스트 생성 능력**을 갖게 됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 지도 학습 (Supervised Fine‑tuning)\n",
      "\n",
      "사전 학습만으로는 **“사용자 의도에 맞는 응답”**을 보장하기 어렵습니다. 따라서 **인간이 만든 라벨**(예: 질문‑답변 쌍, 대화 스크립트)을 이용해 모델을 추가 학습시킵니다.\n",
      "\n",
      "| 단계 | 내용 |\n",
      "|------|------|\n",
      "| **데이터** | - 질문‑답변(Q‑A) 페어<br>- 대화 로그(프롬프트‑응답)<br>- 특정 도메인(법률, 의료 등) 텍스트 |\n",
      "| **목표** | 입력(프롬프트) → 기대되는 출력(정답) 사이의 **조건부 확률**을 최대화합니다. |\n",
      "| **손실** | 사전 학습과 동일한 **Cross‑Entropy** 손실을 사용하지만, 라벨이 명확히 정의된 데이터에만 적용합니다. |\n",
      "| **학습 비율** | 사전 학습에 비해 **학습률을 낮게** (예: 1e‑5 ~ 5e‑5) 설정하고 **짧은 epoch**(수십만~수백만 스텝)만 진행합니다. |\n",
      "\n",
      "이 단계에서 모델은 **“어떤 상황에서 어떤 형태의 답변을 해야 하는가”**를 배우게 됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. 강화 학습을 통한 인간 피드백 (RLHF: Reinforcement Learning from Human Feedback)\n",
      "\n",
      "#### 4.1 왜 RLHF가 필요한가?\n",
      "- **다중 목표**: 정확성, 유용성, 안전성, 친절함 등을 동시에 만족시켜야 함.  \n",
      "- **라벨 부족**: 모든 가능한 상황에 대해 완전한 정답을 미리 정의하기가 불가능함.\n",
      "\n",
      "#### 4.2 RLHF 파이프라인\n",
      "1. **프롬프트 → 여러 후보 응답 생성**  \n",
      "   - 현재 모델(또는 사전‑fine‑tuned 모델)으로 동일한 질문에 대해 N개의 서로 다른 답변을 만든다.\n",
      "2. **인간 라벨러가 순위 매김**  \n",
      "   - 라벨러가 “가장 좋은”, “보통”, “가장 안 좋은” 등으로 답변을 비교·순위화한다.\n",
      "3. **Reward Model (RM) 학습**  \n",
      "   - 라벨러의 순위 데이터를 이용해 **Reward Model**을 학습한다. 보통 **Binary Cross‑Entropy** 혹은 **Pairwise Ranking Loss**를 사용한다.\n",
      "   - RM은 텍스트를 입력받아 **점수**(예: 0~1)를 출력한다. 높은 점수 = 인간이 선호하는 답변.\n",
      "4. **Proximal Policy Optimization (PPO) 등으로 정책 업데이트**  \n",
      "   - 기존 언어 모델을 **정책(policy)**으로 간주하고, RM이 제공하는 보상을 최대화하도록 **강화 학습**을 수행한다.  \n",
      "   - PPO는 **KL‑divergence** 제약을 넣어 기존 모델과 너무 크게 달라지지 않게 조절한다.\n",
      "\n",
      "#### 4.3 결과\n",
      "- 모델은 **“사용자에게 친절하고, 사실에 근거하며, 위험한 정보를 최소화하는”** 방향으로 스스로 행동을 조정한다.  \n",
      "- RLHF 단계는 **안전성·윤리성**을 크게 개선하지만, 여전히 완벽하지 않으며 지속적인 인간 검증이 필요하다.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. 배포와 지속적 개선\n",
      "\n",
      "| 활동 | 설명 |\n",
      "|------|------|\n",
      "| **모델 압축·양자화** | **8‑bit, 4‑bit** 등 저비트 양자화로 추론 비용 절감 (응답 지연 감소). |\n",
      "| **모니터링** | 실시간 로그, 사용자 피드백, 자동화된 안전 검증 도구를 통해 모델 출력 품질을 지속 감시. |\n",
      "| **주기적 재학습** | 새로운 데이터(예: 최신 사건, 정책 변화)와 피드백을 반영해 **주기적 업데이트** 수행. |\n",
      "| **안전 장치** | - **콘텐츠 필터** (사전·사후 차단)<br>- **시스템 프롬프트**(행동 가이드라인) <br>- **인간‑인‑더‑루프(HITL)** 검증 단계 |\n",
      "\n",
      "---\n",
      "\n",
      "## 핵심 포인트 요약\n",
      "\n",
      "| 단계 | 목적 | 핵심 기술 |\n",
      "|------|------|-----------|\n",
      "| **데이터 준비** | 다양하고 깨끗한 텍스트 확보 | 크롤링, 클렌징, BPE 토크나이저 |\n",
      "| **사전 학습** | 언어 전반적 통계·구조 습득 | Causal LM, Transformer Decoder, 대규모 분산 학습 |\n",
      "| **지도 학습** | 특정 작업(대화, QA 등)에 맞춤 | 라벨링된 데이터, Cross‑Entropy |\n",
      "| **RLHF** | 인간 선호도·안전성 반영 | Human ranking → Reward Model → PPO |\n",
      "| **배포·운영** | 실서비스 적용 및 지속 개선 | 양자화, 모니터링, HITL, 정책 업데이트 |\n",
      "\n",
      "---\n",
      "\n",
      "### 부가 설명 – “왜 Transformer인가?”\n",
      "\n",
      "- **Self‑Attention** 덕분에 **문맥 전체**를 한 번에 고려할 수 있어, RNN·LSTM보다 **병렬 처리**가 쉽고 **장거리 의존성**을 잘 포착합니다.  \n",
      "- **스케일링 법칙**(파라미터 수, 데이터 양, 연산량) 에 따라 모델 크기를 키우면 성능이 예측 가능한 형태로 향상됩니다. 이는 GPT 시리즈가 **수십억 → 수천억 → 수조 파라미터**로 성장하면서도 일관된 개선을 보인 이유입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 마무리\n",
      "\n",
      "ChatGPT와 같은 대형 언어 모델은 **대규모 텍스트 데이터를 통한 사전 학습 → 인간 라벨을 활용한 지도 학습 → 인간 피드백을 보상으로 삼은 강화 학습**이라는 3단계 학습 파이프라인을 거쳐 최종적인 대화 능력을 얻게 됩니다. 각 단계마다 **데이터 품질**, **모델 아키텍처**, **학습 목표**, **안전·윤리 고려사항**이 중요한 역할을 하며, 배포 후에도 **지속적인 모니터링과 업데이트**가 필수적입니다.\n",
      "\n",
      "궁금한 점이나 더 깊이 알고 싶은 부분이 있으면 언제든 질문해 주세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Deep Learning – A Clear, Detailed Overview\n",
      "\n",
      "### 1. What It Is, in One Sentence  \n",
      "**Deep learning** is a sub‑field of machine learning that uses **artificial neural networks with many (deep) layers** to automatically learn hierarchical representations of data, enabling computers to perform tasks such as image recognition, speech transcription, language translation, and more—often with performance comparable to or surpassing human experts.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Why “Deep”?\n",
      "\n",
      "| Concept | Explanation |\n",
      "|---------|-------------|\n",
      "| **Neural network** | A computational model loosely inspired by the brain’s network of neurons. Each “neuron” receives inputs, applies a weighted sum, passes the result through a non‑linear **activation function**, and outputs a value. |\n",
      "| **Depth** | The number of *hidden* layers (layers between input and output). A **deep** network has many hidden layers (typically ≥ 3, often dozens or hundreds). Depth lets the model build **progressively more abstract features**: low‑level edges → shapes → objects → concepts. |\n",
      "| **Width** | Number of neurons per layer. Both depth and width affect the network’s capacity to model complex functions. |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Core Building Blocks\n",
      "\n",
      "| Block | Role | Typical Choices |\n",
      "|-------|------|-----------------|\n",
      "| **Input layer** | Holds raw data (pixels, audio samples, word indices, etc.) | Size = dimensionality of data |\n",
      "| **Hidden layers** | Extract and transform features | Fully‑connected (dense), convolutional, recurrent, attention, etc. |\n",
      "| **Output layer** | Produces predictions (class probabilities, continuous values, token probabilities…) | Softmax (classification), sigmoid, linear, etc. |\n",
      "| **Activation functions** | Introduce non‑linearity, enabling the network to approximate complex functions | ReLU, Leaky ReLU, ELU, tanh, sigmoid, GELU (used in transformers) |\n",
      "| **Loss function** | Quantifies prediction error for a given example | Cross‑entropy, mean‑squared error, hinge loss, CTC loss, etc. |\n",
      "| **Optimizer** | Updates weights to minimize loss | Stochastic Gradient Descent (SGD), Adam, RMSprop, LAMB, etc. |\n",
      "| **Regularization** | Prevents over‑fitting | Dropout, weight decay (L2), batch normalization, data augmentation |\n",
      "\n",
      "---\n",
      "\n",
      "### 4. How Training Works (High‑Level)\n",
      "\n",
      "1. **Forward Pass** – Input data flows through the network, producing an output.\n",
      "2. **Loss Computation** – Compare output to the ground‑truth label using a loss function.\n",
      "3. **Backward Pass (Back‑propagation)** – Compute gradients of the loss w.r.t. every weight using the chain rule.\n",
      "4. **Weight Update** – Apply an optimizer to adjust weights in the direction that reduces loss.\n",
      "5. **Iterate** – Repeat over many mini‑batches for many epochs until performance plateaus.\n",
      "\n",
      "*Key point*: **Back‑propagation** is what makes deep learning feasible; it efficiently propagates error signals through many layers.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. Major Architectures & When to Use Them\n",
      "\n",
      "| Architecture | Typical Data Type | Core Idea | Notable Applications |\n",
      "|--------------|-------------------|-----------|----------------------|\n",
      "| **Multilayer Perceptron (MLP)** | Tabular, low‑dimensional vectors | Stacked dense layers | Simple classification/regression tasks |\n",
      "| **Convolutional Neural Network (CNN)** | Images, video, 2‑D/3‑D grids | Local receptive fields + weight sharing → translation‑invariant features | Image classification, object detection, medical imaging |\n",
      "| **Recurrent Neural Network (RNN) / LSTM / GRU** | Sequences (text, speech, time series) | Hidden state carries information across time steps | Language modeling, speech recognition, time‑series forecasting |\n",
      "| **Transformer** | Sequences (especially language) | Self‑attention lets each token attend to all others; highly parallelizable | Machine translation, large‑scale language models (GPT, BERT), protein folding |\n",
      "| **Graph Neural Network (GNN)** | Graph‑structured data (social networks, molecules) | Message passing between nodes | Recommendation systems, drug discovery |\n",
      "| **Variational Autoencoder (VAE) / Generative Adversarial Network (GAN)** | Any modality (images, audio, etc.) | Learn to generate new data samples | Image synthesis, style transfer, data augmentation |\n",
      "\n",
      "---\n",
      "\n",
      "### 6. Real‑World Success Stories\n",
      "\n",
      "| Domain | Example | What Deep Learning Did |\n",
      "|--------|---------|------------------------|\n",
      "| **Computer Vision** | *ImageNet* competition (2012) – AlexNet | Reduced top‑5 error from ~26 % to ~15 % → sparked the modern DL boom |\n",
      "| **Speech** | Google Voice Search, Siri, Alexa | End‑to‑end models transcribe speech with > 95 % accuracy in many languages |\n",
      "| **Natural Language Processing** | OpenAI GPT‑4, Google PaLM, BERT | Achieve human‑level performance on translation, summarization, code generation |\n",
      "| **Healthcare** | Radiology (detecting pneumonia, breast cancer) | Match or exceed radiologists in specific tasks |\n",
      "| **Games & Planning** | AlphaGo, AlphaZero, OpenAI Five | Learned strategies from raw game states, beating world champions |\n",
      "\n",
      "---\n",
      "\n",
      "### 7. Advantages Over Traditional Machine Learning\n",
      "\n",
      "| Aspect | Traditional ML (e.g., SVM, Random Forest) | Deep Learning |\n",
      "|--------|-------------------------------------------|---------------|\n",
      "| **Feature Engineering** | Hand‑crafted, domain‑specific | Learned automatically from raw data |\n",
      "| **Scalability** | Often limited by feature size | Handles millions of parameters and billions of data points |\n",
      "| **Performance on Unstructured Data** | Poor to moderate | State‑of‑the‑art on images, audio, text |\n",
      "| **Transfer Learning** | Rarely used | Pre‑trained models can be fine‑tuned for new tasks with little data |\n",
      "\n",
      "---\n",
      "\n",
      "### 8. Common Challenges & How to Mitigate Them\n",
      "\n",
      "| Challenge | Why It Happens | Mitigation Strategies |\n",
      "|-----------|----------------|-----------------------|\n",
      "| **Data Hungry** | Large networks need massive labeled datasets | Use data augmentation, synthetic data, self‑supervised pretraining, transfer learning |\n",
      "| **Over‑fitting** | Model memorizes training data | Regularization (dropout, weight decay), early stopping, cross‑validation |\n",
      "| **Training Instability** | Vanishing/exploding gradients, poor initialization | Proper weight initialization (He, Xavier), batch normalization, residual connections (ResNets) |\n",
      "| **Compute Cost** | Millions‑to‑billions of FLOPs | Use GPUs/TPUs, mixed‑precision training, model pruning, knowledge distillation |\n",
      "| **Interpretability** | Black‑box nature | Saliency maps, SHAP, LIME, concept activation vectors, attention visualisation |\n",
      "| **Bias & Fairness** | Model learns biases present in data | Careful dataset curation, bias detection tools, fairness‑aware loss functions |\n",
      "\n",
      "---\n",
      "\n",
      "### 9. Getting Started – A Practical Roadmap\n",
      "\n",
      "1. **Learn the Foundations**  \n",
      "   - Linear algebra, calculus, probability basics.  \n",
      "   - Intro to machine learning (supervised vs. unsupervised, bias‑variance trade‑off).\n",
      "\n",
      "2. **Pick a Framework**  \n",
      "   - **PyTorch** (dynamic graph, research‑friendly) or **TensorFlow/Keras** (production‑oriented).  \n",
      "   - Follow official tutorials: *“Deep Learning with PyTorch: A 60‑Minute Blitz”* or *“TensorFlow 2.x Quickstart”*.\n",
      "\n",
      "3. **Hands‑On Projects**  \n",
      "   - **Image classification** with CIFAR‑10 using a small CNN.  \n",
      "   - **Text sentiment analysis** with an LSTM or a pre‑trained BERT model.  \n",
      "   - **GAN** to generate handwritten digits (MNIST).\n",
      "\n",
      "4. **Study Core Papers**  \n",
      "   - *AlexNet* (2012) – first breakthrough CNN.  \n",
      "   - *ResNet* (2015) – residual connections.  \n",
      "   - *Vaswani et al., “Attention Is All You Need”* (2017) – transformer.  \n",
      "   - *Goodfellow et al., “Generative Adversarial Networks”* (2014) – GAN.\n",
      "\n",
      "5. **Explore Transfer Learning**  \n",
      "   - Load a pre‑trained model (e.g., `torchvision.models.resnet50(pretrained=True)`) and fine‑tune on a small custom dataset.\n",
      "\n",
      "6. **Deploy**  \n",
      "   - Convert to ONNX/TensorFlow Lite for edge devices.  \n",
      "   - Use cloud services (AWS SageMaker, GCP Vertex AI) for scalable inference.\n",
      "\n",
      "---\n",
      "\n",
      "### 10. Key Terminology (Quick Glossary)\n",
      "\n",
      "| Term | Meaning |\n",
      "|------|---------|\n",
      "| **Epoch** | One full pass through the entire training dataset. |\n",
      "| **Batch / Mini‑batch** | Subset of training examples processed together; enables efficient GPU utilization. |\n",
      "| **Learning rate** | Step size for weight updates; too high → divergence, too low → slow convergence. |\n",
      "| **Gradient descent** | Optimization algorithm that follows the negative gradient of the loss. |\n",
      "| **Back‑propagation** | Algorithm to compute gradients efficiently across many layers. |\n",
      "| **Over‑fitting / Under‑fitting** | Model too complex vs. too simple for the data. |\n",
      "| **Dropout** | Randomly zeroes a fraction of activations during training to prevent co‑adaptation. |\n",
      "| **Batch Normalization** | Normalizes layer inputs per mini‑batch, stabilizing training. |\n",
      "| **Residual connection** | Shortcut that adds input to output of a block (helps train very deep nets). |\n",
      "| **Self‑attention** | Mechanism where each element of a sequence weighs all other elements, forming the basis of transformers. |\n",
      "\n",
      "---\n",
      "\n",
      "### 11. Further Learning Resources\n",
      "\n",
      "| Type | Resource | Why It’s Good |\n",
      "|------|----------|---------------|\n",
      "| **Books** | *Deep Learning* – Ian Goodfellow, Yoshua Bengio, Aaron Courville | Comprehensive theory + math |\n",
      "| **Online Courses** | **fast.ai** “Practical Deep Learning for Coders” | Code‑first, top‑down approach |\n",
      "| | **CS231n** (Stanford) – Convolutional Neural Networks for Visual Recognition | Visual intuition + assignments |\n",
      "| | **CS224n** – Natural Language Processing with Deep Learning | Transformer‑focused |\n",
      "| **Tutorials** | PyTorch official tutorials, TensorFlow/Keras guides | Hands‑on, up‑to‑date |\n",
      "| **Communities** | Reddit r/MachineLearning, Stack Overflow, Discord AI servers | Quick help, latest news |\n",
      "| **Paper Repositories** | arXiv.org (search “deep learning”) | Cutting‑edge research |\n",
      "\n",
      "---\n",
      "\n",
      "### 12. Bottom Line\n",
      "\n",
      "Deep learning **automates the extraction of hierarchical features** from raw data by stacking many layers of artificial neurons. Its ability to learn directly from massive datasets, combined with modern hardware (GPUs/TPUs) and algorithmic tricks (batch norm, residual connections, attention), has made it the dominant technology behind today’s most impressive AI systems—from self‑driving cars to conversational agents.\n",
      "\n",
      "If you’re just starting, focus on **building simple models, understanding why they work, and then progressively explore more sophisticated architectures**. The field evolves quickly, but the core ideas—*layers, non‑linearities, gradient‑based learning*—remain the same foundation. Happy learning!\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "나는 프로그래밍을 사랑합니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "**태양계 행성 간략 정리**\n",
      "\n",
      "| 순서(태양으로부터) | 행성 | 종류 | 평균 지름 (km) | 특징 |\n",
      "|-------------------|------|------|----------------|------|\n",
      "| 1 | **수성 (Mercury)** | 암석형 행성 | 4,880 | 가장 작은 행성, 대기가 거의 없으며 표면 온도 차이가 극심함 |\n",
      "| 2 | **금성 (Venus)** | 암석형 행성 | 12,104 | 두꺼운 이산화탄소 대기와 황산 구름, 온실 효과로 표면 온도 ~470 °C |\n",
      "| 3 | **지구 (Earth)** | 암석형 행성 | 12,742 | 물이 액체 상태로 존재하는 유일한 행성, 풍부한 대기와 생명 |\n",
      "| 4 | **화성 (Mars)** | 암석형 행성 | 6,779 | 얇은 이산화탄소 대기, 적색 토양, 과거에 물이 흐른 흔적 |\n",
      "| 5 | **목성 (Jupiter)** | 가스 행성 | 139,822 | 태양계 최대의 행성, 거대한 폭풍(대적점)과 수많은 위성 |\n",
      "| 6 | **토성 (Saturn)** | 가스 행성 | 116,464 | 눈에 띄는 고리 시스템, 80여 개 이상의 위성 |\n",
      "| 7 | **천왕성 (Uranus)** | 얼음 거대 행성 | 50,724 | 자전축이 약 98° 기울어져 있어 ‘옆으로 누운’ 행성, 푸른색은 메탄 가스 |\n",
      "| 8 | **해왕성 (Neptune)** | 얼음 거대 행성 | 49,244 | 가장 강한 바람(시속 2,400 km)과 눈에 띄는 청색, 트위터(Triton) 위성 보유 |\n",
      "\n",
      "**주요 포인트**\n",
      "\n",
      "- **암석형 행성**(수성, 금성, 지구, 화성) : 고체 표면과 얇은 대기(또는 없음).  \n",
      "- **가스 행성**(목성, 토성) : 주로 수소·헬륨으로 이루어져 있으며, 핵은 존재하지만 표면이 명확하지 않음.  \n",
      "- **얼음 거대 행성**(천왕성, 해왕성) : 가스 행성보다 물, 암모니아, 메탄 같은 ‘얼음’ 물질 비중이 높음.  \n",
      "- **위성·고리** : 목성·토성·천왕성·해왕성은 각각 수십 개 이상의 위성을 가지고 있으며, 토성은 가장 뚜렷한 고리 시스템을 가짐.  \n",
      "\n",
      "> **간단 요약**  \n",
      "> 태양계는 내행성 4개(수성·금성·지구·화성)와 외행성 4개(목성·토성·천왕성·해왕성)로 구성됩니다. 내행성은 암석으로 이루어졌고, 외행성은 주로 가스와 얼음으로 이루어진 거대한 행성들입니다. 각 행성은 크기, 대기, 온도, 위성·고리 등에서 독특한 특징을 보여 줍니다.\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A947AF59A0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A947FEE8D0>, root_client=<openai.OpenAI object at 0x000001A94678F830>, root_async_client=<openai.AsyncOpenAI object at 0x000001A947BBC590>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "## 🎓 소프트웨어융합학과 졸업생을 위한 AI 시대 취업 로드맵  \n",
      "\n",
      "아래는 **AI·데이터·소프트웨어**가 핵심이 되는 10가지 직업군을 **직무 소개 → 주요 기술·역량 → 왜 전망이 좋은지** 순으로 정리했어요.  \n",
      "각 직무마다 “시작하기 쉬운 입문 단계”와 “경력 3~5년 차에 도전하면 좋은 고급 포지션”도 함께 적어 두었으니, 지금부터 차근차근 준비해 보세요!\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ AI·머신러닝 엔지니어  \n",
      "**직무** : 모델 설계·학습·배포, 데이터 파이프라인 구축, 성능 튜닝  \n",
      "**핵심 기술**  \n",
      "- Python (NumPy, Pandas, Scikit‑learn)  \n",
      "- 딥러닝 프레임워크: TensorFlow, PyTorch  \n",
      "- 클라우드 AI 서비스(AWS SageMaker, Azure ML, GCP Vertex AI)  \n",
      "- 기본 수학·통계 (선형대수, 확률)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- 기업·공공기관이 AI 제품·서비스를 빠르게 출시하려고 함 → 인재 수요 폭발  \n",
      "- “AI 모델을 실제 서비스에 적용하는(MLOps) 역량”이 가장 뜨거운 스킬  \n",
      "\n",
      "**입문 단계** → Kaggle 초급 대회 참여 → 사내 AI 파일럿 프로젝트  \n",
      "**고급 단계** → MLOps 엔지니어, AI 연구원, AI 아키텍트  \n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ 데이터 사이언티스트 / 데이터 분석가  \n",
      "**직무** : 데이터 수집·정제·분석·시각화, 비즈니스 인사이트 도출  \n",
      "**핵심 기술**  \n",
      "- SQL, Python/R, Tableau/PowerBI  \n",
      "- 통계·머신러닝 모델링 (회귀, 군집, 시계열)  \n",
      "- 데이터 엔지니어링 기본 (ETL, Airflow)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- 모든 산업이 “데이터 기반 의사결정”을 목표로 함 → 데이터 전문가가 필수  \n",
      "- AI와 결합하면 **데이터 사이언스 → AI 솔루션** 으로 성장 가능  \n",
      "\n",
      "**입문 단계** → 데이터 시각화 프로젝트(예: 공공 데이터 활용)  \n",
      "**고급 단계** → 데이터 전략가, AI 제품 매니저  \n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ 소프트웨어 개발자 (AI·클라우드 특화)  \n",
      "**직무** : 웹·앱·백엔드 개발, AI API 연동, 클라우드 인프라 설계  \n",
      "**핵심 기술**  \n",
      "- 언어: Java, Kotlin, Go, Node.js, Python  \n",
      "- 프레임워크: Spring, Django, FastAPI  \n",
      "- 클라우드: AWS, Azure, GCP (특히 AI 서비스 연동)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- AI 서비스는 **소프트웨어**와 결합돼야 실제 제품이 되므로, 전통 개발자와 AI 개발자 사이의 “브릿지” 역할이 크게 필요함  \n",
      "\n",
      "**입문 단계** → 개인 프로젝트(예: 챗봇 웹앱)  \n",
      "**고급 단계** → AI 플랫폼 엔지니어, 풀스택 AI 개발자  \n",
      "\n",
      "---\n",
      "\n",
      "## 4️⃣ MLOps 엔지니어 (AI 운영 전문가)  \n",
      "**직무** : 모델 배포·모니터링·CI/CD 파이프라인 구축, 인프라 자동화  \n",
      "**핵심 기술**  \n",
      "- Docker, Kubernetes, Terraform  \n",
      "- CI/CD 도구: GitHub Actions, Jenkins, GitLab CI  \n",
      "- 모델 서빙: TensorFlow Serving, TorchServe, FastAPI  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- 모델을 **실제 서비스에 안정적으로 운영**하는 능력이 가장 부족한 영역 → 높은 연봉·책임감  \n",
      "\n",
      "**입문 단계** → Docker로 간단한 모델 서빙 실습  \n",
      "**고급 단계** → AI 플랫폼 팀 리드, 클라우드 AI 솔루션 아키텍트  \n",
      "\n",
      "---\n",
      "\n",
      "## 5️⃣ 로보틱스·자동화 엔지니어  \n",
      "**직무** : 로봇 제어·시뮬레이션·AI 기반 인식·산업 자동화 시스템 개발  \n",
      "**핵심 기술**  \n",
      "- ROS (Robot Operating System)  \n",
      "- C++/Python, 실시간 제어 이론  \n",
      "- 컴퓨터 비전 (OpenCV, YOLO)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- 제조·물류·의료 등에서 **AI 로봇** 도입이 급증 → 융합 전공이 강점  \n",
      "\n",
      "**입문 단계** → 라즈베리파이·아두이노 로봇 키트 제작  \n",
      "**고급 단계** → 자율주행 로봇, 스마트 팩토리 솔루션 개발  \n",
      "\n",
      "---\n",
      "\n",
      "## 6️⃣ 컴퓨터 비전·영상 처리 엔지니어  \n",
      "**직무** : 이미지·동영상 분석, 객체 탐지·세분화, AR/VR 콘텐츠 개발  \n",
      "**핵심 기술**  \n",
      "- OpenCV, PyTorch/TensorFlow (CNN, Transformer)  \n",
      "- Edge AI (NVIDIA Jetson, Coral)  \n",
      "- 3D 모델링 기초 (Blender, Unity)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- 자율주행, 스마트 시티, 의료 영상 등 **시각 데이터** 활용 분야가 급성장  \n",
      "\n",
      "**입문 단계** → CCTV 영상에서 사람/차량 검출 프로젝트  \n",
      "**고급 단계** → 의료 영상 AI, AR/VR 콘텐츠 엔지니어  \n",
      "\n",
      "---\n",
      "\n",
      "## 7️⃣ 자연어 처리(NLP) 엔지니어  \n",
      "**직무** : 텍스트 분석·챗봇·요약·번역·감성 분석 시스템 개발  \n",
      "**핵심 기술**  \n",
      "- Transformers (BERT, GPT, T5)  \n",
      "- Hugging Face, spaCy, NLTK  \n",
      "- 대용량 텍스트 파이프라인 (ElasticSearch, Kafka)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- 기업의 고객 서비스·마케팅·문서 자동화에 **언어 AI**가 필수 → 꾸준한 수요  \n",
      "\n",
      "**입문 단계** → 뉴스 기사 요약 모델 만들기  \n",
      "**고급 단계** → 대화형 AI, 도메인 특화 언어 모델 구축  \n",
      "\n",
      "---\n",
      "\n",
      "## 8️⃣ AI 제품·서비스 기획자 (AI PM)  \n",
      "**직무** : AI 제품 로드맵 설계·요구사항 정의·팀 조율·시장 검증  \n",
      "**핵심 역량**  \n",
      "- AI 기술 기본 이해 (모델·데이터·인프라)  \n",
      "- UX/UI 기초, 비즈니스 모델 설계  \n",
      "- 데이터·AI 프로젝트 관리 (Agile, Scrum)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- 기술과 비즈니스를 연결하는 “가교” 역할 → 기술 이해도가 높은 기획자를 기업이 찾음  \n",
      "\n",
      "**입문 단계** → 학교·동아리 AI 프로젝트 기획·시연  \n",
      "**고급 단계** → AI 스타트업 공동창업, 대기업 AI 전략팀  \n",
      "\n",
      "---\n",
      "\n",
      "## 9️⃣ AI 윤리·데이터 거버넌스 전문가  \n",
      "**직무** : AI 윤리 가이드라인 수립·데이터 프라이버시·규제 대응·공정성 검증  \n",
      "**핵심 지식**  \n",
      "- 개인정보 보호법, GDPR, AI 윤리 원칙  \n",
      "- 데이터 품질·라벨링 관리  \n",
      "- AI Explainability (SHAP, LIME)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- AI 규제와 사회적 책임이 강조되면서 **전문가** 수요가 급증  \n",
      "\n",
      "**입문 단계** → AI 윤리 워크숍 참여·관련 논문/보고서 리뷰  \n",
      "**고급 단계** → 기업 AI 윤리 담당, 정부·공공기관 데이터 정책 자문  \n",
      "\n",
      "---\n",
      "\n",
      "## 🔟 AI 스타트업 창업·프리랜서  \n",
      "**직무** : 아이디어 발굴·MVP 개발·투자 유치·시장 검증  \n",
      "**핵심 준비**  \n",
      "- 한두 개의 **핵심 기술**에 깊이 파고들기 (예: 이미지 AI, 챗봇)  \n",
      "- 비즈니스 모델 캔버스, 린 스타트업 방법론  \n",
      "- 네트워킹·멘토링 (창업 지원센터, 해커톤)  \n",
      "\n",
      "**왜 좋은가?**  \n",
      "- AI 기반 서비스는 **초기 진입 장벽이 낮아** 빠르게 시장 검증 가능 → 성공 시 높은 보상  \n",
      "\n",
      "**입문 단계** → 대학 내 창업동아리·해커톤 참가 → 작은 프로젝트 MVP 만들기  \n",
      "**고급 단계** → 시드 투자 유치·시리즈 A 라운드 진행  \n",
      "\n",
      "---\n",
      "\n",
      "## 📚 **공통으로 갖추면 좋은 스킬**  \n",
      "\n",
      "| 영역 | 구체적인 학습 방법 |\n",
      "|------|-------------------|\n",
      "| **프로그래밍** | Python 기본 → 프로젝트 기반 학습 (GitHub에 코드 공개) |\n",
      "| **수학·통계** | Khan Academy, Coursera “Mathematics for Machine Learning” |\n",
      "| **클라우드** | AWS/Azure/GCP 무료 티어 활용, “AI/ML on Cloud” 실습 |\n",
      "| **협업·소통** | Git 협업 흐름, Agile 스프린트 경험 (팀 프로젝트) |\n",
      "| **포트폴리오** | 1~2개의 **실제 문제 해결** 프로젝트 (데이터 전처리 → 모델 → 배포) 를 블로그/Notion에 정리 |\n",
      "| **자격·인증** | (선택) AWS Certified Machine Learning – Specialty, Google Cloud Professional Data Engineer 등 |\n",
      "\n",
      "---\n",
      "\n",
      "## 🗓️ **3‑5년 차 로드맵 예시**  \n",
      "\n",
      "| 연도 | 목표 | 구체적인 액션 |\n",
      "|------|------|----------------|\n",
      "| **1학년~2학년** | 기초 프로그래밍·수학·데이터 분석 습득 | 교과목 외에 Python 입문, Kaggle 초급 대회, 데이터 시각화 프로젝트 |\n",
      "| **3학년** | AI·ML 기본 모델 구현 경험 | 교내 AI 경진대회 참가, 교수·연구실 인턴, 간단한 웹 서비스에 모델 연동 |\n",
      "| **졸업 전** | 포트폴리오 2~3개 완성 + 인턴십 | 기업·연구소 AI 인턴 (MLOps, NLP 등), GitHub에 코드 공개 |\n",
      "| **졸업 후 1~2년** | 전문 분야 선택 → 주니어 엔지니어 | 선택한 분야(AI 엔지니어, 데이터 사이언티스트 등)에서 **실무 프로젝트** 수행, 클라우드 인증 취득 |\n",
      "| **3~5년 차** | 고급 역할·리더십 | MLOps 팀 리드, AI 제품 매니저, 혹은 스타트업 공동창업 등 목표에 맞게 경력 전환 |\n",
      "\n",
      "---\n",
      "\n",
      "## 🎯 **마무리 팁**  \n",
      "\n",
      "1. **“문제 해결”에 초점** – 기술보다 *어떤 문제를 AI로 풀 수 있느냐*가 채용 담당자의 눈에 띕니다.  \n",
      "2. **오픈소스·커뮤니티 참여** – GitHub, Hugging Face, Papers With Code 등에서 기여하면 눈에 보이는 실력이 쌓입니다.  \n",
      "3. **꾸준한 학습** – AI는 빠르게 변하니, 매주 2~3시간씩 최신 논문·기술 블로그(ArXiv, Medium) 읽기를 습관화하세요.  \n",
      "4. **네트워킹** – 학교 동아리, AI 컨퍼런스, 온라인 세미나(Zoom, MeetUp)에서 사람을 만나면 기회가 늘어납니다.  \n",
      "\n",
      "> **당신이 지금 쌓는 작은 실험·프로젝트가, 5년 뒤 “AI 전문가”라는 큰 그림을 완성하는 퍼즐 조각**이 됩니다.  \n",
      "지금부터 차근차근 한 걸음씩 나아가면, AI 시대에도 자신감 있게 활躍할 수 있을 거예요! 🚀\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"소프트웨어융합학과를 재학중인데 졸업 후 요즘 AI때문에 미래를 생각했을때 취업하기 좋은 직업을 정리해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 가을에 일어나는 대표적인 지구과학 현상은 태풍 발생이 맞나요? 가을에 주로 발생하는 지구과학 현상을 3개 알려주세요\n",
      " 모델 응답: **가을에 주로 나타나는 대표적인 지구과학 현상**  \n",
      "\n",
      "| # | 현상 | 왜 가을에 많이 나타나는가? (주요 메커니즘) | 주요 영향·관측 특징 |\n",
      "|---|------|---------------------------------------------|-------------------|\n",
      "| 1 | **태풍(열대 저기압) 발생·접근** | • 7·8월에 가장 활발한 열대 저기압이 형성되지만, **가을 초(9월~10월)** 은 남서쪽 태평양의 해수면 온도가 아직 26 °C ~ 28 °C 로 높아 태풍이 계속 발달할 수 있는 환경이 유지됩니다.<br>• 가을이 되면 서쪽 태평양 고기압(태평양 고기압·동아시아 고기압)이 서서히 남하하면서, 태풍이 북쪽으로 이동·진로가 바뀌어 한반도·동북아 지역에 접근하기 쉬워집니다. | • 강풍·폭우·해일(Storm surge) 등 재해 위험이 급증.<br>• 기상청·위성·레이다를 통한 실시간 추적이 활발히 이루어짐. |\n",
      "| 2 | **중위도 저기압·전선 활동 강화** (냉난류 교차) | • 가을은 **여름철 고온·습한 대류와 겨울철 차가운 대륙 고기압** 사이의 전이기.<br>• 남쪽에서 따뜻하고 습한 해양성 공기가, 북쪽에서 차가운 대륙성 공기가 만나면서 **전선(특히 한랭 전선)과 저기압**이 자주 형성됩니다.<br>• 제트기류가 남쪽으로 내려오면서 전선의 이동 속도가 빨라지고, 저기압의 강도가 강화됩니다. | • 급격한 기온 강하, 강수(소나기·폭우)와 바람이 동반되는 날씨.<br>• 교통·농업·에너지(난방) 수요에 큰 영향을 미침. |\n",
      "| 3 | **대기 온도역전·안개·연무 발생** | • 가을 밤에는 **지표면이 급격히 냉각**되고, 위층에 남아 있던 여름의 따뜻한 공기가 위에 머무르게 됩니다.<br>• 이때 **온도역전층**이 형성돼 수직 혼합이 억제되고, 습도가 높은 저층 공기가 포화상태에 가까워져 **안개·연무**가 자주 발생합니다.<br>• 특히 해안·강변·산간 계곡 등 지형적인 요인이 결합하면 안개의 지속 시간이 길어집니다. | • 가시거리 저하 → 항공·해운·도로 교통에 지장.<br>• 대기오염 물질(예: 미세먼지·황사)의 하강 및 농축을 촉진. |\n",
      "\n",
      "---\n",
      "\n",
      "### 요약\n",
      "\n",
      "- **태풍**은 가을 초에 가장 활발히 나타나는 대표적인 현상이며, “가을에 일어나는 대표적인 지구과학 현상”이라고 할 수 있습니다. 다만, 가을에는 이 외에도 **중위도 저기압·전선 활동**과 **대기 온도역전·안개**와 같은 현상이 동시에 많이 발생합니다.  \n",
      "- 이 세 가지 현상은 모두 **대기·해양의 열·수분 흐름이 계절 전이 과정에서 급격히 변할 때** 나타나는 현상으로, 기상·재해 대비에 중요한 의미를 갖습니다.  \n",
      "\n",
      "필요하시면 각 현상의 자세한 시계열 자료(예: 기상청 관측 그래프)나 대비·예방 팁도 추가로 알려드릴 수 있습니다. 언제든 질문 주세요!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n",
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "가을에 주로 발생하는 대표적인 지구과학 현상 3가지는 다음과 같습니다.\n",
      "\n",
      "*   **편서풍의 계절 변화**: 가을이 되면 북반구에서 낮과 밤의 길이(일교차)가 짧아지게 되며, 편서풍의 위치가 남쪽으로 이동하게 됩니다. 이로 인해 우리나라에는 따뜻한 북태평양 기단과 차가운 오호츠크 해 기단이 만나서 형성된 전선의 영향으로 비가 자주 내리게 됩니다.\n",
      "\n",
      "*   **성층권 오존층 감소**: 가을이 되면 지구의 자전축에 따른 태양 빛의 입사각도 변화로 인해 오존층이 약화되어 오존층의 구멍이 나타날 수 있습니다. 이로 인해 자외선 차단 효과가 약화되어 인체에 미치는 피해가 증가할 수 있습니다.\n",
      "\n",
      "*   **북반구 단풍**: 가을이 되면 북반구의 낮의 길이가 짧아지게 되며, 밤과 낮의 일교차가 커지게 됩니다. 이로 인해 나무의 잎이 변색되어 단풍이 발생하게 됩니다. 이러한 단풍은 대개 10월 중순에 절정에 이르게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season = get_current_season(\"north\")  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season}\")\n",
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: ## Summary\n",
      "\n",
      "Based on the current exchange rate of 1 USD = 1,377.98 KRW, this response provides an analysis of the currency market.\n",
      "\n",
      "## Analysis\n",
      "\n",
      "The current exchange rate of 1 USD = 1,377.98 KRW indicates that the Korean won (KRW) is relatively weak compared to the US dollar (USD). A higher exchange rate means that it takes more won to buy one dollar.\n",
      "\n",
      "## Possible Reasons for the Exchange Rate\n",
      "\n",
      "Several factors contribute to the current exchange rate:\n",
      "\n",
      "*   **Economic indicators**: Korea's economic growth rate, inflation rate, and interest rates influence the value of the won.\n",
      "*   **Global market trends**: The US dollar's value against other major currencies, such as the euro and yen, also affects the KRW/USD exchange rate.\n",
      "*   **Trade balance**: Korea's trade balance, including exports and imports, impacts the demand for and supply of won and dollars.\n",
      "*   **Capital flows**: Foreign investment in Korea and Korean investment abroad influence the exchange rate.\n",
      "\n",
      "## Implications\n",
      "\n",
      "The current exchange rate may have implications for:\n",
      "\n",
      "*   **Exporters and importers**: A weaker won can make Korean exports more competitive in the global market, but it may also increase the cost of imports.\n",
      "*   **Investors**: The exchange rate affects the attractiveness of Korean assets to foreign investors and vice versa.\n",
      "*   **Tourists and travelers**: A weaker won can make traveling to Korea more expensive for foreigners, while a stronger won can make traveling abroad more affordable for Koreans.\n",
      "\n",
      "## Outlook\n",
      "\n",
      "The exchange rate may fluctuate based on various market and economic factors. It is essential to monitor economic indicators, global market trends, and geopolitical events to predict future exchange rate movements.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The current exchange rate of 1 USD = 1,377.98 KRW reflects the complex interactions of various economic and market factors. Understanding these factors and their implications can help individuals and businesses make informed decisions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
