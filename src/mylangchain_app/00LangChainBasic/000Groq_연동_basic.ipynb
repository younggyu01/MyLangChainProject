{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6123bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e5654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_t3ZxLr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv(dotenv_path='.env')\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957689d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c43c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: 당신은 개발자입니다.\n",
      "Human: 파이썬은 무엇인가요? 자세하게 설명해주세요\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189e2d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002B11881B9E0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002B11881B5C0> root_client=<openai.OpenAI object at 0x000002B11881BC50> root_async_client=<openai.AsyncOpenAI object at 0x000002B1188197C0> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1bc0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "응답: ## 파이썬(Python)이란?\n",
      "\n",
      "파이썬은 **고수준(high‑level), 인터프리터 방식(interpreted), 범용(general‑purpose) 프로그래밍 언어**입니다. 1991년 네덜란드의 프로그래머 **귀도 반 로썸(Guido van Rossum)**이 처음 발표했으며, 현재는 전 세계 개발자 커뮤니티와 기업에서 폭넓게 사용되고 있습니다.  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. 파이썬의 주요 특징\n",
      "\n",
      "| 특징 | 설명 | 장점 |\n",
      "|------|------|------|\n",
      "| **읽기 쉬운 문법** | 들여쓰기(indent) 기반 블록 구조, 최소한의 구문(syntax) | 코드 가독성·유지보수성 향상 |\n",
      "| **동적 타입** | 변수 선언 시 타입을 명시하지 않음 | 빠른 프로토타이핑, 생산성 증가 |\n",
      "| **인터프리터** | 코드를 한 줄씩 실행, REPL(대화형 셸) 제공 | 즉시 피드백·디버깅이 용이 |\n",
      "| **풍부한 표준 라이브러리** | `os`, `datetime`, `json`, `http`, `re` 등 200여 개 모듈 | 외부 패키지 없이도 다양한 작업 가능 |\n",
      "| **멀티패러다임** | 절차적, 객체지향, 함수형 프로그래밍 지원 | 문제에 맞는 스타일 선택 가능 |\n",
      "| **플랫폼 독립성** | Windows, macOS, Linux, 모바일, 임베디드 등 | 한 번 작성하면 거의 모든 환경에서 실행 |\n",
      "| **오픈소스** | MIT‑style 라이선스(PSF License) | 자유로운 사용·배포·수정 가능 |\n",
      "| **활발한 생태계** | PyPI(Python Package Index) 300k+ 패키지 | 데이터 과학, 웹, 자동화, AI 등 거의 모든 분야에 솔루션 존재 |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 파이썬의 역사와 버전\n",
      "\n",
      "| 연도 | 주요 사건 |\n",
      "|------|-----------|\n",
      "| **1980년대 후반** | 귀도 반 로썸이 “ABC” 언어의 후속으로 설계 시작 |\n",
      "| **1991년** | 파이썬 0.9.0 공개 (예외 처리, 모듈, 함수 등 기본 기능) |\n",
      "| **2000년** | 파이썬 2.0 출시 – 리스트 컴프리헨션, 가비지 컬렉션 등 |\n",
      "| **2008년** | 파이썬 3.0 출시 – 문자열·바이트 구분, `print` 함수 등 비호환적인 변화 |\n",
      "| **2020년** | 파이썬 3.9, 3.10, 3.11 연속 출시 – 패턴 매칭, 성능 최적화, 타입 힌트 강화 |\n",
      "| **2023년** | 파이썬 3.12 발표 – 파서 개선, 메모리 사용량 감소 등 |\n",
      "| **현재** | 최신 LTS(Long‑Term Support) 버전은 **3.12**이며, 3.13이 곧 출시 예정 |\n",
      "\n",
      "> **Tip**: 프로젝트를 시작할 때는 가급적 최신 LTS 버전을 사용하고, `pyenv`·`conda`·`virtualenv` 등 가상 환경 도구로 버전을 관리하는 것이 좋습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 파이썬이 쓰이는 분야\n",
      "\n",
      "| 분야 | 주요 라이브러리·프레임워크 | 활용 예시 |\n",
      "|------|---------------------------|----------|\n",
      "| **웹 개발** | Django, Flask, FastAPI | 웹 사이트·REST API 서버 |\n",
      "| **데이터 과학·분석** | NumPy, pandas, SciPy, matplotlib, seaborn | 데이터 전처리·시각화·통계 분석 |\n",
      "| **머신러닝·AI** | scikit‑learn, TensorFlow, PyTorch, Keras | 모델 학습·추론·배포 |\n",
      "| **자동화·스크립트** | `os`, `shutil`, `subprocess`, `pyautogui` | 파일 관리·시스템 관리·테스트 자동화 |\n",
      "| **클라우드·인프라** | Boto3(AWS), google-cloud, Azure SDK | 클라우드 리소스 프로비저닝·관리 |\n",
      "| **게임 개발** | Pygame, Panda3D | 2D·3D 간단 게임 |\n",
      "| **임베디드·IoT** | MicroPython, CircuitPython | 마이크로컨트롤러 프로그래밍 |\n",
      "| **교육** | Jupyter Notebook, Google Colab | 인터랙티브 학습·실험 |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 파이썬 기본 문법 소개\n",
      "\n",
      "아래는 파이썬의 핵심 문법을 간단히 보여주는 예시입니다.\n",
      "\n",
      "```python\n",
      "# 1️⃣ 변수와 동적 타입\n",
      "x = 10          # 정수\n",
      "y = 3.14        # 실수\n",
      "msg = \"Hello\"   # 문자열\n",
      "\n",
      "# 2️⃣ 리스트와 딕셔너리 (컬렉션)\n",
      "numbers = [1, 2, 3, 4]\n",
      "person = {\"name\": \"홍길동\", \"age\": 30}\n",
      "\n",
      "# 3️⃣ 조건문\n",
      "if x > 5:\n",
      "    print(\"x는 5보다 큽니다\")\n",
      "elif x == 5:\n",
      "    print(\"x는 5와 같습니다\")\n",
      "else:\n",
      "    print(\"x는 5보다 작습니다\")\n",
      "\n",
      "# 4️⃣ 반복문 (for, while)\n",
      "for n in numbers:\n",
      "    print(n * 2)          # 2배 출력\n",
      "\n",
      "i = 0\n",
      "while i < 3:\n",
      "    print(i)\n",
      "    i += 1                # i = i + 1\n",
      "\n",
      "# 5️⃣ 함수 정의와 기본 인자\n",
      "def greet(name: str = \"World\") -> str:\n",
      "    \"\"\"인사 메시지를 반환합니다.\"\"\"\n",
      "    return f\"Hello, {name}!\"\n",
      "\n",
      "print(greet())           # Hello, World!\n",
      "print(greet(\"파이썬\"))   # Hello, 파이썬\n",
      "\n",
      "# 6️⃣ 클래스와 객체지향\n",
      "class Animal:\n",
      "    def __init__(self, species: str):\n",
      "        self.species = species\n",
      "\n",
      "    def speak(self):\n",
      "        raise NotImplementedError\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"멍멍!\"\n",
      "\n",
      "my_dog = Dog(\"개\")\n",
      "print(my_dog.speak())    # 멍멍!\n",
      "```\n",
      "\n",
      "### 핵심 포인트\n",
      "- **들여쓰기(Indentation)**: 블록 구분에 탭이나 스페이스 4칸을 사용합니다. 중괄호 `{}` 가 없습니다.\n",
      "- **주석**: `#` 한 줄 주석, `\"\"\"` 혹은 `'''` 로 여러 줄 주석(문서 문자열) 작성.\n",
      "- **표현식과 문장**: 파이썬은 표현식(expression)과 문(statement)을 명확히 구분합니다. 예를 들어 `a = 5`는 문, `a + 3`은 표현식.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 파이썬 개발 환경 설정\n",
      "\n",
      "| 단계 | 도구/명령 | 설명 |\n",
      "|------|-----------|------|\n",
      "| **1. 파이썬 설치** | `python.org` 공식 설치 파일 또는 `brew install python3` (macOS) | 최신 버전 설치 |\n",
      "| **2. 가상 환경** | `python -m venv .venv` → `source .venv/bin/activate` (Linux/macOS) <br> `.\\.venv\\Scripts\\activate` (Windows) | 프로젝트마다 독립적인 패키지 관리 |\n",
      "| **3. 패키지 관리** | `pip install <패키지>` <br> `pip freeze > requirements.txt` | 의존성 기록·재현 |\n",
      "| **4. IDE/편집기** | VS Code (Python extension), PyCharm, Jupyter Notebook/Lab, Spyder | 코드 자동완성·디버깅·리팩터링 지원 |\n",
      "| **5. 형식 검사·테스트** | `black` (코드 포맷) <br> `flake8`/`pylint` (정적 분석) <br> `pytest` (단위 테스트) | 코드 품질 유지 |\n",
      "| **6. 배포** | `setuptools`/`wheel` + `twine` (PyPI 배포) <br> `Dockerfile` (컨테이너화) | 배포 자동화·버전 관리 |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 파이썬 성능 최적화 팁\n",
      "\n",
      "1. **내장 함수·표현식 활용**  \n",
      "   - `sum()`, `any()`, `all()`, 리스트 컴프리헨션 등은 C 레벨 구현이라 빠릅니다.\n",
      "\n",
      "2. **프로파일링**  \n",
      "   - `cProfile`, `line_profiler`, `memory_profiler` 로 병목 지점 파악.\n",
      "\n",
      "3. **외부 C/Fortran 라이브러리**  \n",
      "   - NumPy, pandas 등은 내부적으로 C/Fortran 코드를 사용해 수치 연산을 가속화합니다.\n",
      "\n",
      "4. **JIT 컴파일러**  \n",
      "   - **PyPy**(Python 구현) 사용 시, 런타임에 JIT 컴파일로 2~5배 가속.\n",
      "\n",
      "5. **멀티스레드 vs 멀티프로세스**  \n",
      "   - GIL(Global Interpreter Lock) 때문에 CPU 바운드 작업은 `multiprocessing` 혹은 `concurrent.futures.ProcessPoolExecutor` 사용.\n",
      "\n",
      "6. **Cython / Numba**  \n",
      "   - 성능이 중요한 루프는 Cython(정적 타입 선언)이나 Numba(데코레이터 기반 JIT) 로 변환.\n",
      "\n",
      "---\n",
      "\n",
      "## 7. 파이썬 학습 로드맵 (초급 → 고급)\n",
      "\n",
      "1. **기초**  \n",
      "   - 변수, 자료형, 제어문, 함수, 기본 I/O  \n",
      "   - 간단한 프로젝트: 계산기, 파일 정렬 스크립트\n",
      "\n",
      "2. **자료구조·알고리즘**  \n",
      "   - 리스트, 튜플, 딕셔너리, 집합 활용  \n",
      "   - `collections` 모듈 (Counter, defaultdict, deque)  \n",
      "\n",
      "3. **객체지향**  \n",
      "   - 클래스, 상속, 다형성, 메타클래스 기본 이해  \n",
      "\n",
      "4. **표준 라이브러리**  \n",
      "   - `os`, `sys`, `pathlib`, `json`, `logging`, `argparse`  \n",
      "\n",
      "5. **가상 환경·패키지 관리**  \n",
      "   - `pip`, `venv`, `conda`  \n",
      "\n",
      "6. **웹·API**  \n",
      "   - Flask/FastAPI 로 REST API 만들기, `requests` 로 클라이언트 구현  \n",
      "\n",
      "7. **데이터 과학**  \n",
      "   - NumPy, pandas, matplotlib, seaborn, Jupyter Notebook  \n",
      "\n",
      "8. **머신러닝**  \n",
      "   - scikit-learn, TensorFlow/PyTorch 기본 모델 구현  \n",
      "\n",
      "9. **테스트·CI/CD**  \n",
      "   - `pytest`, GitHub Actions, Docker  \n",
      "\n",
      "10. **고급 주제**  \n",
      "    - 비동기 프로그래밍 (`asyncio`), 메타프로그래밍, 타입 힌트(`typing`), 패키지 배포  \n",
      "\n",
      "---\n",
      "\n",
      "## 8. 파이썬 커뮤니티와 학습 자료\n",
      "\n",
      "| 종류 | 링크 | 특징 |\n",
      "|------|------|------|\n",
      "| **공식 문서** | https://docs.python.org/3/ | 가장 정확하고 최신 정보 |\n",
      "| **튜토리얼** | https://docs.python.org/3/tutorial/ | 입문자용 단계별 가이드 |\n",
      "| **온라인 강의** | Coursera, edX, Udemy, FastCampus, Inflearn | 영상 + 실습 |\n",
      "| **블로그·사이트** | Real Python, Towards Data Science, PyBites | 실전 팁·예제 |\n",
      "| **Q&A** | Stack Overflow, Reddit r/learnpython | 문제 해결·토론 |\n",
      "| **오프라인 모임** | PyCon, 지역 PyLadies, Meetups | 네트워킹·세미나 |\n",
      "| **패키지 레지스트리** | PyPI (https://pypi.org/) | 300k+ 오픈소스 패키지 |\n",
      "| **코드 호스팅** | GitHub, GitLab | 오픈소스 프로젝트 참여 |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. 결론\n",
      "\n",
      "- **파이썬은 가독성, 생산성, 풍부한 라이브러리**를 갖춘 언어라서 초보자부터 전문가까지 모두에게 적합합니다.\n",
      "- **다양한 분야**(웹, 데이터, AI, 자동화 등)에서 핵심 도구로 자리 잡고 있어, 하나만 배워도 여러 프로젝트에 바로 적용할 수 있습니다.\n",
      "- **커뮤니티와 생태계**가 활발하므로, 학습 중에 언제든지 도움을 받을 수 있고 최신 트렌드도 빠르게 따라잡을 수 있습니다.\n",
      "\n",
      "> **시작 팁**: “Hello, World!”부터 시작해, **가상 환경**을 만든 뒤, **pandas**로 CSV 파일을 읽어보고, **Flask**로 간단한 웹 API를 만들면서 단계적으로 스택을 확장해 보세요. 실전 프로젝트를 진행하면서 공식 문서와 커뮤니티를 병행하면 가장 효과적인 학습이 됩니다.  \n",
      "\n",
      "궁금한 점이나 구체적인 예제가 필요하면 언제든 알려 주세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1240cfa",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0440de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9de0ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002B11881B9E0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002B11881B5C0>, root_client=<openai.OpenAI object at 0x000002B11881BC50>, root_async_client=<openai.AsyncOpenAI object at 0x000002B1188197C0>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36af0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"LangChain은 뭐야?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d8844d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "**LangChain**은 **LLM(대형 언어 모델)** 을 활용한 **애플리케이션**을 보다 쉽게 설계·구현·운용할 수 있도록 도와주는 **오픈소스 프레임워크**입니다.  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. 핵심 목표\n",
      "- **LLM을 단독으로 쓰는 것**을 넘어서, **데이터베이스, 검색 엔진, 도구(API), 사용자 인터페이스** 등 다양한 외부 시스템과 연동된 **복합적인 워크플로우**를 빠르게 만들게 함  \n",
      "- **재사용 가능한 컴포넌트**와 **표준화된 인터페이스**를 제공해, 프로젝트마다 처음부터 모든 로직을 구현할 필요를 없앰  \n",
      "\n",
      "---\n",
      "\n",
      "## 2. 주요 개념·구조\n",
      "\n",
      "| 구성 요소 | 역할 | 주요 클래스·함수 |\n",
      "|-----------|------|-----------------|\n",
      "| **Chain** | 여러 LLM 호출·전처리·후처리 단계를 순차·조건부로 연결 | `SequentialChain`, `RouterChain`, `TransformChain` |\n",
      "| **PromptTemplate** | 변수(예: `{question}`)를 포함한 프롬프트를 정의·렌더링 | `PromptTemplate`, `FewShotPromptTemplate` |\n",
      "| **LLM** | 실제 언어 모델 호출 (OpenAI, Anthropic, Cohere, HuggingFace 등) | `OpenAI`, `ChatOpenAI`, `HuggingFaceHub` |\n",
      "| **Retriever** | 벡터 DB·검색 엔진 등에서 관련 문서를 찾아 반환 | `FAISS`, `ElasticVectorSearch`, `PineconeRetriever` |\n",
      "| **Memory** | 대화/세션 상태를 보관해 컨텍스트 유지 | `ConversationBufferMemory`, `ConversationSummaryMemory` |\n",
      "| **Tool** | 외부 API·함수·스크립트 등 LLM이 호출할 수 있는 작업 | `Tool`, `StructuredTool`, `PythonREPLTool` |\n",
      "| **Agent** | LLM이 “어떤 도구를 언제 사용할지”를 스스로 판단하도록 하는 프레임 | `ZeroShotAgent`, `ReactAgent`, `OpenAIFunctionsAgent` |\n",
      "| **Callbacks** | 실행 흐름을 로깅·모니터링·디버깅하기 위한 훅 | `StdOutCallbackHandler`, `LangChainTracer` |\n",
      "\n",
      "> **핵심 흐름**  \n",
      "> `PromptTemplate` → `LLM` → (필요 시) `Retriever` → `Memory` → `Tool` → `Agent` → `Chain`  \n",
      "\n",
      "---\n",
      "\n",
      "## 3. 대표적인 사용 시나리오\n",
      "\n",
      "| 시나리오 | 구현 예시 |\n",
      "|----------|-----------|\n",
      "| **Q&A with Knowledge Base** | `RetrievalQAChain` + FAISS 벡터스토어 → 사용자가 질문하면 관련 문서 검색 후 LLM이 답변 |\n",
      "| **Chatbot with Tool Use** | `AgentExecutor` + `OpenAIFunctionsAgent` + 여러 `Tool` (날씨 API, 계산기 등) → LLM이 필요 시 도구를 호출 |\n",
      "| **데이터 요약·보고서 자동 생성** | `MapReduceChain` 또는 `RefineChain` → 대량 문서를 단계별 요약 |\n",
      "| **코드 생성·디버깅** | `PythonREPLTool` + `Agent` → LLM이 코드를 실행·피드백을 받아 수정 |\n",
      "| **멀티턴 대화** | `ConversationBufferMemory` + `ChatOpenAI` → 대화 이력을 유지하며 자연스러운 흐름 제공 |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 간단한 코드 예시 (Python)\n",
      "\n",
      "```python\n",
      "from langchain import PromptTemplate, LLMChain\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.memory import ConversationBufferMemory\n",
      "\n",
      "# 1️⃣ 프롬프트 템플릿 정의\n",
      "prompt = PromptTemplate(\n",
      "    input_variables=[\"question\", \"history\"],\n",
      "    template=\"\"\"\n",
      "    이전 대화:\n",
      "    {history}\n",
      "    \n",
      "    질문: {question}\n",
      "    답변을 한국어로, 간결하게 주세요.\n",
      "    \"\"\"\n",
      ")\n",
      "\n",
      "# 2️⃣ LLM 인스턴스 (OpenAI ChatGPT)\n",
      "llm = OpenAI(model_name=\"gpt-4o-mini\", temperature=0.2)\n",
      "\n",
      "# 3️⃣ 메모리 (대화 기록)\n",
      "memory = ConversationBufferMemory(memory_key=\"history\")\n",
      "\n",
      "# 4️⃣ 체인 구성\n",
      "qa_chain = LLMChain(\n",
      "    llm=llm,\n",
      "    prompt=prompt,\n",
      "    memory=memory,\n",
      "    verbose=True\n",
      ")\n",
      "\n",
      "# 5️⃣ 실행\n",
      "response = qa_chain.run(question=\"파이썬에서 리스트를 정렬하는 가장 빠른 방법은?\")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "- `ConversationBufferMemory`가 자동으로 이전 대화를 `history` 변수에 삽입해, LLM이 컨텍스트를 인식하게 함.  \n",
      "- `LLMChain`은 프롬프트 → LLM 호출 → 결과 반환까지 한 번에 처리해 줍니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 왜 LangChain을 사용하나요?\n",
      "\n",
      "| 장점 | 설명 |\n",
      "|------|------|\n",
      "| **모듈화** | 각 컴포넌트를 독립적으로 교체·재사용 가능 (예: 다른 벡터 DB로 교체) |\n",
      "| **생산성** | “LLM → 검색 → 메모리 → 도구” 같은 복합 흐름을 몇 줄의 코드로 구현 |\n",
      "| **확장성** | 커스텀 `Tool`, `Retriever`, `Memory` 등을 직접 구현해 대규모 서비스에 적용 |\n",
      "| **관측·디버깅** | 콜백·트레이서가 실행 로그를 남겨, 프로덕션 환경에서 문제 파악이 쉬움 |\n",
      "| **커뮤니티·생태계** | 2024년 기준 10,000+ 스타터 템플릿, 300+ 플러그인, 활발한 GitHub·Discord 커뮤니티 |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 최신 동향 (2024‑2025)\n",
      "\n",
      "1. **LangChain 2.x** (2024년 9월 릴리즈)  \n",
      "   - **Typed API** 도입: `pydantic`‑style 타입 힌트로 IDE 자동완성·검증 강화  \n",
      "   - **LangGraph**: 복잡한 비선형 워크플로우(조건·루프·병렬)를 그래프 형태로 정의하는 새로운 DSL  \n",
      "   - **멀티모델 체인**: LLM + 이미지·음성 모델을 한 체인 안에서 순차/동시 실행 가능  \n",
      "\n",
      "2. **LangChain Hub**  \n",
      "   - 사전 구축된 `Chain`, `Prompt`, `Retriever` 등을 공유·재사용할 수 있는 중앙 레포지터리 (예: `langchainhub/knowledge-base-qa`)  \n",
      "\n",
      "3. **클라우드 통합**  \n",
      "   - **LangChain Cloud** (베타): 실행 로그, 비용 추적, 자동 스케일링을 제공하는 관리형 서비스  \n",
      "   - 주요 클라우드(AWS, Azure, GCP)와 직접 연동되는 **Serverless** 배포 템플릿 제공  \n",
      "\n",
      "4. **보안·컴플라이언스**  \n",
      "   - `PromptGuard` 모듈: 프롬프트/응답에 대한 정책 기반 필터링 (PII, 금지어 등)  \n",
      "   - `AuditTrail` 콜백: 모든 LLM 호출·툴 사용을 암호화된 로그에 기록  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. 시작하기 (간단 가이드)\n",
      "\n",
      "1. **설치**  \n",
      "   ```bash\n",
      "   pip install langchain openai   # 기본 패키지\n",
      "   # 필요 시 추가: faiss-cpu, pinecone-client, langchain-community 등\n",
      "   ```\n",
      "\n",
      "2. **API 키 설정** (예: OpenAI)  \n",
      "   ```bash\n",
      "   export OPENAI_API_KEY=\"sk-...\"\n",
      "   ```\n",
      "\n",
      "3. **첫 번째 체인 만들기** (위 코드 예시 참고)\n",
      "\n",
      "4. **LangChain Hub 탐색**  \n",
      "   ```python\n",
      "   from langchain import hub\n",
      "   qa_template = hub.pull(\"langchain/qa-retrieval\")\n",
      "   ```\n",
      "\n",
      "5. **배포**  \n",
      "   - 로컬 테스트 → Docker 이미지 빌드 → **LangChain Cloud** 혹은 **AWS Lambda**/**Azure Functions**에 배포  \n",
      "\n",
      "---\n",
      "\n",
      "## 8. 마무리\n",
      "\n",
      "- **LangChain**은 “LLM + 외부 도구”라는 **복합 시스템**을 **프로그래밍** 수준에서 추상화해, **아이디어 → 프로토타입 → 프로덕션**까지의 전 과정을 가속화합니다.  \n",
      "- 특히 **검색 기반 QA**, **도구 활용 챗봇**, **멀티모달 파이프라인**을 구축하고자 할 때, 직접부터 구현할 필요 없이 **컴포넌트 조합**만으로도 충분히 강력한 서비스를 만들 수 있습니다.  \n",
      "\n",
      "궁금한 점이나 실제 프로젝트에 적용하고 싶은 시나리오가 있으면 언제든 물어보세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
