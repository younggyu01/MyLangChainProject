{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_t\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 다음과 같습니다.\\n\\n1.  **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 모델이 학습할 수 있는 형태로 가공되어야 합니다.\\n2.  **데이터 전처리**: 수집된 데이터를 모델이 학습할 수 있는 형태로 변환하는 과정을 말합니다. 예를 들어, 이미지 데이터를 학습시키기 위해서는 이미지를 픽셀 단위로 분해하여 숫자로 표현하는 과정이 필요합니다.\\n3.  **모델 정의**: 인공지능 모델을 정의하는 과정입니다. 모델은 입력 데이터를 받아서 출력 데이터를 생성하는 함수로 정의됩니다. 예를 들어, 이미지 분류 모델은 입력 이미지로부터 카테고리를 분류하는 출력을 생성하는 함수로 정의됩니다.\\n4.  **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. 손실 함수는 모델의 출력과 실제 출력 간의 차이를 측정합니다. 예를 들어, 이미지 분류 모델의 경우 크로스 엔트로피 손실 함수를 사용할 수 있습니다.\\n5.  **최적화 알고리즘 적용**: 모델의 가중치를 업데이트하기 위해 최적화 알고리즘을 적용합니다. 최적화 알고리즘은 손실 함수를 최소화하는 방향으로 모델의 가중치를 업데이트합니다. 예를 들어, 경사 하강법이나 Adam 최적화 알고리즘을 사용할 수 있습니다.\\n6.  **학습**: 모델을 학습시키는 과정입니다. 학습 과정에서는 모델에 입력 데이터를 제공하고, 모델의 출력을 계산합니다. 그런 다음, 손실 함수를 계산하고, 최적화 알고리즘을 적용하여 모델의 가중치를 업데이트합니다. 이 과정을 반복하여 모델의 성능을 향상시킵니다.\\n\\n예를 들어, 고양이와 강아지의 이미지를 분류하는 모델을 학습시킨다고 가정해 봅시다.\\n\\n*   **데이터 수집**: 고양이와 강아지의 이미지 데이터를 수집합니다.\\n*   **데이터 전처리**: 이미지를 픽셀 단위로 분해하여 숫자로 표현합니다.\\n*   **모델 정의**: 이미지 분류 모델을 정의합니다. 예를 들어, 합성곱 신경망(CNN) 모델을 사용할 수 있습니다.\\n*   **손실 함수 정의**: 크로스 엔트로피 손실 함수를 정의합니다.\\n*   **최적화 알고리즘 적용**: Adam 최적화 알고리즘을 적용합니다.\\n*   **학습**: 모델에 입력 이미지를 제공하고, 모델의 출력을 계산합니다. 손실 함수를 계산하고, 최적화 알고리즘을 적용하여 모델의 가중치를 업데이트합니다. 이 과정을 반복하여 모델의 성능을 향상시킵니다.\\n\\n이를 통해 모델은 고양이와 강아지의 이미지를 분류하는 법을 학습하게 됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 531, 'prompt_tokens': 24, 'total_tokens': 555, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.204980001, 'prompt_time': 0.000352534, 'completion_time': 1.267172726, 'total_time': 1.26752526}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-e6ad93a6-240b-4a66-aff5-53aa42543999', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--bfe1112a-cb26-451c-9d03-db7ade1e2f1c-0' usage_metadata={'input_tokens': 24, 'output_tokens': 531, 'total_tokens': 555, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 모델이 학습할 수 있는 형태로 가공되어야 합니다.\n",
      "2.  **데이터 전처리**: 수집된 데이터를 모델이 학습할 수 있는 형태로 변환하는 과정을 말합니다. 예를 들어, 이미지 데이터를 학습시키기 위해서는 이미지를 픽셀 단위로 분해하여 숫자로 표현하는 과정이 필요합니다.\n",
      "3.  **모델 정의**: 인공지능 모델을 정의하는 과정입니다. 모델은 입력 데이터를 받아서 출력 데이터를 생성하는 함수로 정의됩니다. 예를 들어, 이미지 분류 모델은 입력 이미지로부터 카테고리를 분류하는 출력을 생성하는 함수로 정의됩니다.\n",
      "4.  **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. 손실 함수는 모델의 출력과 실제 출력 간의 차이를 측정합니다. 예를 들어, 이미지 분류 모델의 경우 크로스 엔트로피 손실 함수를 사용할 수 있습니다.\n",
      "5.  **최적화 알고리즘 적용**: 모델의 가중치를 업데이트하기 위해 최적화 알고리즘을 적용합니다. 최적화 알고리즘은 손실 함수를 최소화하는 방향으로 모델의 가중치를 업데이트합니다. 예를 들어, 경사 하강법이나 Adam 최적화 알고리즘을 사용할 수 있습니다.\n",
      "6.  **학습**: 모델을 학습시키는 과정입니다. 학습 과정에서는 모델에 입력 데이터를 제공하고, 모델의 출력을 계산합니다. 그런 다음, 손실 함수를 계산하고, 최적화 알고리즘을 적용하여 모델의 가중치를 업데이트합니다. 이 과정을 반복하여 모델의 성능을 향상시킵니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 이미지를 분류하는 모델을 학습시킨다고 가정해 봅시다.\n",
      "\n",
      "*   **데이터 수집**: 고양이와 강아지의 이미지 데이터를 수집합니다.\n",
      "*   **데이터 전처리**: 이미지를 픽셀 단위로 분해하여 숫자로 표현합니다.\n",
      "*   **모델 정의**: 이미지 분류 모델을 정의합니다. 예를 들어, 합성곱 신경망(CNN) 모델을 사용할 수 있습니다.\n",
      "*   **손실 함수 정의**: 크로스 엔트로피 손실 함수를 정의합니다.\n",
      "*   **최적화 알고리즘 적용**: Adam 최적화 알고리즘을 적용합니다.\n",
      "*   **학습**: 모델에 입력 이미지를 제공하고, 모델의 출력을 계산합니다. 손실 함수를 계산하고, 최적화 알고리즘을 적용하여 모델의 가중치를 업데이트합니다. 이 과정을 반복하여 모델의 성능을 향상시킵니다.\n",
      "\n",
      "이를 통해 모델은 고양이와 강아지의 이미지를 분류하는 법을 학습하게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 우리의 뇌는 경험을 통해 배우고, 새로운 정보를 기존 지식과 연결하여 기억합니다. 인공지능 모델도 데이터를 통해 배우고, 예측이나 분류 작업을 더 잘하도록 스스로를 개선합니다.\\n\\n간단한 예를 들어 설명해 보겠습니다. \\n\\n1. **데이터 수집**: 인공지능 모델이 학습하려면 많은 데이터가 필요합니다. 예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델은 수많은 고양이와 강아지의 사진을 필요로 합니다.\\n\\n2. **데이터 분석**: 이 데이터를 바탕으로 모델은 각 사진의 특징을 분석합니다. 예를 들어, 고양이 사진이면 귀가 길고 뾰족하거나, 눈이 크고 둥근 형태인 특징을 찾을 수 있습니다.\\n\\n3. **학습**: 모델은 처음에 무작위로 예측을 합니다. 하지만 실제 데이터(고양이 또는 강아지 사진)와 예측 결과를 비교하면서 오류를 계산합니다. 이 오류를 최소화하는 방향으로 모델의 내부 매개변수(가중치와 편향)를 조정합니다. 이 과정이 반복되면서 모델은 어떤 사진이 고양이인지, 강아지인지를 더 잘 구별하게 됩니다.\\n\\n4. **평가**: 일정량의 데이터로 학습을 마친 후, 모델은 새로운 데이터를 가지고 평가를 받습니다. 이 평가를 통해 모델의 성능을 측정하고, 필요하다면 추가적인 학습을 진행할 수 있습니다.\\n\\n5. **예측**: 최종적으로 모델은 새로운, 보지 못했던 사진이 주어졌을 때도 고양이인지 강아지인지를 예측할 수 있습니다.\\n\\n이처럼 인공지능 모델은 대량의 데이터를 통해 학습하고, 스스로의 성능을 개선해 나가는 과정을 통해 발전합니다. 이를 통해 이미지 인식, 자연어 처리, 음성 인식 등 다양한 분야에서 놀라운 성능을 발휘할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 388, 'prompt_tokens': 36, 'total_tokens': 424, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.205669771, 'prompt_time': 0.000755977, 'completion_time': 0.952000717, 'total_time': 0.952756694}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-90326e2a-afdf-461f-b091-4a27bebd6caa', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--54f3302a-eb4d-485b-bf4a-02a8d3275cb3-0' usage_metadata={'input_tokens': 36, 'output_tokens': 388, 'total_tokens': 424, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 우리의 뇌는 경험을 통해 배우고, 새로운 정보를 기존 지식과 연결하여 기억합니다. 인공지능 모델도 데이터를 통해 배우고, 예측이나 분류 작업을 더 잘하도록 스스로를 개선합니다.\n",
      "\n",
      "간단한 예를 들어 설명해 보겠습니다. \n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습하려면 많은 데이터가 필요합니다. 예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델은 수많은 고양이와 강아지의 사진을 필요로 합니다.\n",
      "\n",
      "2. **데이터 분석**: 이 데이터를 바탕으로 모델은 각 사진의 특징을 분석합니다. 예를 들어, 고양이 사진이면 귀가 길고 뾰족하거나, 눈이 크고 둥근 형태인 특징을 찾을 수 있습니다.\n",
      "\n",
      "3. **학습**: 모델은 처음에 무작위로 예측을 합니다. 하지만 실제 데이터(고양이 또는 강아지 사진)와 예측 결과를 비교하면서 오류를 계산합니다. 이 오류를 최소화하는 방향으로 모델의 내부 매개변수(가중치와 편향)를 조정합니다. 이 과정이 반복되면서 모델은 어떤 사진이 고양이인지, 강아지인지를 더 잘 구별하게 됩니다.\n",
      "\n",
      "4. **평가**: 일정량의 데이터로 학습을 마친 후, 모델은 새로운 데이터를 가지고 평가를 받습니다. 이 평가를 통해 모델의 성능을 측정하고, 필요하다면 추가적인 학습을 진행할 수 있습니다.\n",
      "\n",
      "5. **예측**: 최종적으로 모델은 새로운, 보지 못했던 사진이 주어졌을 때도 고양이인지 강아지인지를 예측할 수 있습니다.\n",
      "\n",
      "이처럼 인공지능 모델은 대량의 데이터를 통해 학습하고, 스스로의 성능을 개선해 나가는 과정을 통해 발전합니다. 이를 통해 이미지 인식, 자연어 처리, 음성 인식 등 다양한 분야에서 놀라운 성능을 발휘할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "사람이 경험을 통해 배우고 기억하는 것과 비슷하게, 인공지능 모델도 데이터를 통해 학습합니다. \n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습하기 위해서는大量的 데이터가 필요합니다. 이 데이터는 문제에 대한 다양한 사례와 해결책으로 구성됩니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 모델이 이해할 수 있는 형태로 변환되어야 합니다. 이 과정에는 데이터 정리, 변환, 그리고 정규화 등이 포함될 수 있습니다.\n",
      "\n",
      "3. **모델 설정**: 인공지능 모델의 구조를 설정합니다. 이 구조는 문제의 복잡도와 데이터의 특성에 따라 결정됩니다. 예를 들어, 이미지 인식 문제에는 합성곱 신경망(CNN)이 적합하고, 자연어 처리 문제에는 순환 신경망(RNN)이나 트랜스포머 모델이 적합합니다.\n",
      "\n",
      "4. **학습**: 모델은 데이터를 통해 학습하면서, 문제에 대한 패턴이나 관계를 발견합니다. 이 과정은 최적화 알고리즘을 통해 모델의 파라미터(가중치)를 조정함으로써 이루어집니다. 목표는 모델의 예측 결과와 실제 결과 사이의 차이를 최소화하는 것입니다.\n",
      "\n",
      "5. **평가**: 학습된 모델의 성능을 평가합니다. 이를 위해 학습 데이터와는 별도의 테스트 데이터를 사용합니다. 평가 지표에는 정확도, 정밀도, 재현율, F1 점수 등이 있습니다.\n",
      "\n",
      "6. **튜닝**: 모델의 성능을 개선하기 위해 하이퍼파라미터를 조정하거나 모델 구조를 변경하는 등의 튜닝 작업을 수행할 수 있습니다.\n",
      "\n",
      "예를 들어, 자율 주행 자동차의 경우, 수많은 이미지와 센서 데이터를 통해 모델이 도로와 장애물을 인식하고, 적절한 운전 결정을 내릴 수 있도록 학습합니다. \n",
      "\n",
      "이처럼 인공지능 모델은 다양한 데이터와 알고리즘을 통해 학습하고, 주어진 문제를 해결하는 능력을 갖추게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 사진 속 고양이를 맞추는 인공지능 모델을 만든다고 가정해 보겠습니다. \n",
      "\n",
      "사진과 고양이 아닌 사진들을 인공지능 모델에 보여 주고, 고양이 사진이면 '고양이다', 고양이가 아니면 '고양이 아니다'라고 알려주는 것입니다. \n",
      "\n",
      "인공지능 모델은 이 데이터를 통해 고양이의 특징을 스스로 학습합니다. \n",
      "\n",
      "이를테면, 고양이는 귀가 뾰족하고 눈이 크며 털이 있다는 등의 특징을 스스로 발견하는 것입니다. \n",
      "\n",
      "이렇게 학습한 특징을 바탕으로 인공지능 모델은 새로운 사진을 봤을 때, 고양이인지 아닌지 판단할 수 있습니다. \n",
      "\n",
      "이러한 학습 과정을 통해 인공지능 모델은 점점 더 정확한 판단을 내릴 수 있게 됩니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**추천 영화: <그린 북 (Green Book, 2018)**  \n",
      "\n",
      "- **장르**: 드라마 / 코미디  \n",
      "- **감독**: 피터 패럴리 (Peter Farrelly)  \n",
      "- **주연**: 마허샬라 알리 (Mahershala Ali), 비고 모텐슨 (Viggo Mortensen)  \n",
      "- **줄거리**  \n",
      "  1960년대 미국 남부를 무대로, 유명한 흑인 피아니스트 돈 셜리(마허샬라 알리)와 그의 백인 운전사 토니 리프(비고 모텐슨)가 함께 투어를 떠나며 겪는 이야기를 그립니다. 두 사람은 서로 다른 문화와 편견을 마주하면서도 점차 이해와 우정을 쌓아갑니다.  \n",
      "\n",
      "- **추천 포인트**  \n",
      "  1. **감동적인 인간 관계** – 서로 다른 배경을 가진 두 주인공이 겪는 갈등과 화해 과정이 깊은 울림을 줍니다.  \n",
      "  2. **역사적 배경** – 인종 차별이 심각했던 시대적 상황을 사실적으로 그려, 현재와도 연결되는 사회적 메시지를 전달합니다.  \n",
      "  3. **수상 경력** – 아카데미 작품상·감독상·각본상·조연상 등 4개 부문을 수상한 작품으로, 완성도와 품질이 검증되었습니다.  \n",
      "  4. **밝은 톤과 유머** – 무거운 주제에도 불구하고 유머와 따뜻한 순간들이 적절히 배치돼 관객이 부담 없이 몰입할 수 있습니다.  \n",
      "\n",
      "- **시청 팁**  \n",
      "  - 가족·친구와 함께 감상하면 서로 다른 시각에서 이야기를 나눠볼 수 있어 더욱 풍부한 감상이 됩니다.  \n",
      "  - 영화가 끝난 뒤, 실제 1960년대 ‘그린 북’이라는 여행 안내서와 그 시대의 인권운동에 대해 간단히 찾아보면 배경 이해가 한층 깊어집니다.  \n",
      "\n",
      "**한 줄 요약**: 인종 차별이라는 무거운 주제를 따뜻한 우정과 유머로 풀어낸, 감동과 교훈이 동시에 살아있는 현대 드라마 영화입니다. 🎬✨\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"openai/gpt-oss-120b\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002051A11F4D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002051A0A4830>, root_client=<openai.OpenAI object at 0x000002051A11E720>, root_async_client=<openai.AsyncOpenAI object at 0x000002051A11DC70>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002051A11F4D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002051A0A4830>, root_client=<openai.OpenAI object at 0x000002051A11E720>, root_async_client=<openai.AsyncOpenAI object at 0x000002051A11DC70>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " **기생충 (Parasite, 2019)**  \n",
      "\n",
      "제목: 기생충  \n",
      "감독: 봉준호  \n",
      "캐스팅: 송강호, 이선균, 조여정, 최우식, 박소담, 이정은 등  \n",
      "줄거리: 가난한 김씨 가족이 부유한 박씨 가정에 각각 교사·가사·미술·운전사 등으로 침투하면서 시작된 일련의 사건들은, 예상치 못한 비극과 반전을 맞이한다. 두 가정의 계층 차이가 점차 겹쳐지며 긴장감과 사회적 풍자를 동시에 전달하고, 결국 모두를 뒤흔드는 충격적인 결말로 이어진다.  \n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('**시네마 천국 (Cinema Paradiso)**  \\n'\n",
      " '\\n'\n",
      " '제목: 시네마 천국 (Cinema Paradiso)  \\n'\n",
      " '감독: 주세페 토르나토레 (Giuseppe\\u202fTornatore)  \\n'\n",
      " '캐스팅: 살바토레 카시라리, 프란체스코 파레리, 파올라 토레시, 티에리 알레그리, 마르코 레이시 등  \\n'\n",
      " '줄거리: 시칠리아의 작은 마을에 있는 ‘시네마 파라디소’에서 자란 소년 알프레도는 영화관 주인 ‘토토’와 깊은 우정을 나누며 영화에 대한 '\n",
      " '사랑을 키워간다. 시간이 흘러 알프레도는 성공한 영화감독이 되지만, 어린 시절의 추억과 첫사랑, 그리고 토토와의 기억을 되새기며 인생의 '\n",
      " '의미와 잊혀진 감정을 찾아가게 된다.  ')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"openai/gpt-oss-120b\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
