{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangGraph에서 도구(tool) 활용 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 도구(tool)를 활용한 에이전트 개발 방법을 알아봅니다\n",
    "- workflow를 직접 선언하지 않고, 사용가능한 도구들을 전달하면, 에이전트가 적합한 도구를 판단해서 사용합니다\n",
    "    - 이번 회차에서는 `ToolNode`를 통해 도구를 활용하는 방법을 알아봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n",
      "NY\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000265C1CACBC0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000265C1C0AAB0> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LangGraph는 `ToolNode`를 통해 도구를 활용합니다\n",
    "- `ToolNode`의 `invoke()`결과는 도구의 `invoke()` 결과와 유사합니다\n",
    "    - 도구는 도구의 실행 결과를 리턴하고, `ToolNode`는 도구의 실행 결과를 포함한 `ToolMessage`를 리턴합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n",
      "tools(tags=None, recurse=True, explode_args=False, func_accepts_config=True, func_accepts={'store': ('__pregel_store', None)}, tools_by_name={'add': StructuredTool(name='add', description='숫자 a와 b를 더합니다.', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x00000265B177BC40>), 'multiply': StructuredTool(name='multiply', description='숫자 a와 b를 곱합니다.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x00000265B177B9C0>)}, tool_to_state_args={'add': {}, 'multiply': {}}, tool_to_store_arg={'add': None, 'multiply': None}, handle_tool_errors=True, messages_key='messages')\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_list = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)\n",
    "\n",
    "print(type(llm_with_tools))\n",
    "print(tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({'a': 3, 'b': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"[The 'add' function is ESSENTIAL to compute the sum of 3 and 5, which directly answers the question. No alternative or simpler method exists given the available tools.]\", additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-51501fe64cda409ebad35402193c35c5', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 580, 'total_tokens': 637, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '6f8a3c70-7f80-469c-b575-8132be3ed29e', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4fa6cfc2-72f6-4c30-9802-a6246ffe0469-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-51501fe64cda409ebad35402193c35c5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 580, 'output_tokens': 57, 'total_tokens': 637, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = llm_with_tools.invoke('What is 3 plus 5?')\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 3, 'b': 5},\n",
       "  'id': 'chatcmpl-tool-51501fe64cda409ebad35402193c35c5',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ToolNode`를 `invoke()`하려면 `tool_calls` 속성을 포함한 `AIMessage`를 전달해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='8', name='add', tool_call_id='chatcmpl-tool-51501fe64cda409ebad35402193c35c5')]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node.invoke({'messages': [ai_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 간단한 에이전트를 만들기 위해 LangGraph에서 제공하는 [`StateGraph`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"\n",
    "    에이전트 함수는 주어진 상태에서 메시지를 가져와\n",
    "    LLM과 도구를 사용하여 응답 메시지를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): 메시지 상태를 포함하는 state.\n",
    "\n",
    "    Returns:\n",
    "        MessagesState: 응답 메시지를 포함하는 새로운 state.\n",
    "    \"\"\"\n",
    "    # 상태에서 메시지를 추출합니다.\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM과 도구를 사용하여 메시지를 처리하고 응답을 생성합니다.\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # 응답 메시지를 새로운 상태로 반환합니다.\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import END\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal['tools', END]:\n",
    "    \"\"\"\n",
    "    주어진 메시지 상태를 기반으로 에이전트가 계속 진행할지 여부를 결정합니다.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): `state`를 포함하는 객체.\n",
    "\n",
    "    Returns:\n",
    "        Literal['tools', END]: 도구를 사용해야 하면 `tools`를 리턴하고, \n",
    "        답변할 준비가 되었다면 END를 반환해서 프로세스를 종료합니다.\n",
    "    \"\"\"\n",
    "    # 상태에서 메시지를 추출합니다.\n",
    "    messages = state['messages']\n",
    "    print(messages)\n",
    "    \n",
    "    # 마지막 AI 메시지를 가져옵니다.\n",
    "    last_ai_message = messages[-1]\n",
    "    \n",
    "    # 마지막 AI 메시지가 도구 호출을 포함하고 있는지 확인합니다.\n",
    "    if last_ai_message.tool_calls:\n",
    "        # 도구 호출이 있으면 'tools'를 반환합니다.\n",
    "        return 'tools'\n",
    "    \n",
    "    # 도구 호출이 없으면 END를 반환하여 프로세스를 종료합니다.\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `node`를 추가하고 `edge`로 연결합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x265c1ccd160>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x265c1ccd160>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['tools', END]\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "graph= graph_builder.compile()\n",
    "print(type(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mermaid Code:\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tagent(agent)\n",
      "\ttools(tools)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> agent;\n",
      "\tagent -.-> __end__;\n",
      "\tagent -.-> tools;\n",
      "\ttools --> agent;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(\"Mermaid Code:\")\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mermaid.live/ 에서  mermain_code 로 직접 확인한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `graph.stream()`을 활용하면 에이전트가 답변을 생성하는 과정을 모니터링 할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "3에다 5를 더하고 거기에 8을 곱하면?\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='1e85ca38-9e4f-43b9-b9e7-23f9567ee9f6'), AIMessage(content='[Brief explanation: The `add` function is essential to first calculate 3 + 5, and the `multiply` function is then required to multiply the result by 8. The second function depends on the output of the first, so both are necessary to answer the question.]\\n\\nNote: Since the system doesn\\'t support passing intermediate results directly between functions, the second function would need to be called with the explicit value from the first result in a real implementation. Here, \"add_result\" represents that placeholder concept. The actual calculation would be:\\n1. add(a=3, b=5) → 8\\n2. multiply(a=8, b=8) → 64\\n\\nThe final answer is 64.', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', 'function': {'arguments': '{\"a\": 8, \"b\": \"add_result\"}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 179, 'prompt_tokens': 585, 'total_tokens': 764, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'a7ff1396-1dd6-4167-9b82-695d3707315f', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--148886a8-397d-471d-8d19-81474891146b-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 'add_result'}, 'id': 'chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', 'type': 'tool_call'}], usage_metadata={'input_tokens': 585, 'output_tokens': 179, 'total_tokens': 764, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[Brief explanation: The `add` function is essential to first calculate 3 + 5, and the `multiply` function is then required to multiply the result by 8. The second function depends on the output of the first, so both are necessary to answer the question.]\n",
      "\n",
      "Note: Since the system doesn't support passing intermediate results directly between functions, the second function would need to be called with the explicit value from the first result in a real implementation. Here, \"add_result\" represents that placeholder concept. The actual calculation would be:\n",
      "1. add(a=3, b=5) → 8\n",
      "2. multiply(a=8, b=8) → 64\n",
      "\n",
      "The final answer is 64.\n",
      "Tool Calls:\n",
      "  add (chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31)\n",
      " Call ID: chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "  multiply (chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998)\n",
      " Call ID: chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998\n",
      "  Args:\n",
      "    a: 8\n",
      "    b: add_result\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "Error: 1 validation error for multiply\n",
      "b\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='add_result', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\n",
      " Please fix your mistakes.\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='1e85ca38-9e4f-43b9-b9e7-23f9567ee9f6'), AIMessage(content='[Brief explanation: The `add` function is essential to first calculate 3 + 5, and the `multiply` function is then required to multiply the result by 8. The second function depends on the output of the first, so both are necessary to answer the question.]\\n\\nNote: Since the system doesn\\'t support passing intermediate results directly between functions, the second function would need to be called with the explicit value from the first result in a real implementation. Here, \"add_result\" represents that placeholder concept. The actual calculation would be:\\n1. add(a=3, b=5) → 8\\n2. multiply(a=8, b=8) → 64\\n\\nThe final answer is 64.', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', 'function': {'arguments': '{\"a\": 8, \"b\": \"add_result\"}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 179, 'prompt_tokens': 585, 'total_tokens': 764, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'a7ff1396-1dd6-4167-9b82-695d3707315f', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--148886a8-397d-471d-8d19-81474891146b-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 'add_result'}, 'id': 'chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', 'type': 'tool_call'}], usage_metadata={'input_tokens': 585, 'output_tokens': 179, 'total_tokens': 764, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='dbe2ec90-48e5-4edb-a960-fb90f2d9abc0', tool_call_id='chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31'), ToolMessage(content=\"Error: 1 validation error for multiply\\nb\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='add_result', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\\n Please fix your mistakes.\", name='multiply', id='1cb6fa84-9a45-41f7-a899-94804d16a91f', tool_call_id='chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', status='error'), AIMessage(content=\"I need to correct my approach since the system doesn't support passing intermediate results symbolically. Here's the proper sequence:\\n\\n[First call add to get 3+5=8]\\n\\nAfter getting the result from add, I'll make the second call:\\n\\n<tool_call>[multiply(a=8,b=8)]</tool_call>\\n[Then multiply the result (8) by 8 to get the final answer]\\n\\nThe calculation sequence is:\\n1. 3 + 5 = 8\\n2. 8 × 8 = 64\\n\\nThe final answer is 64.\", additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 854, 'total_tokens': 992, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '120dfae8-4e43-460a-ba28-11c322dad4f3', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9be2a820-402b-4120-9a5a-c228391591dd-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 854, 'output_tokens': 138, 'total_tokens': 992, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I need to correct my approach since the system doesn't support passing intermediate results symbolically. Here's the proper sequence:\n",
      "\n",
      "[First call add to get 3+5=8]\n",
      "\n",
      "After getting the result from add, I'll make the second call:\n",
      "\n",
      "<tool_call>[multiply(a=8,b=8)]</tool_call>\n",
      "[Then multiply the result (8) by 8 to get the final answer]\n",
      "\n",
      "The calculation sequence is:\n",
      "1. 3 + 5 = 8\n",
      "2. 8 × 8 = 64\n",
      "\n",
      "The final answer is 64.\n",
      "Tool Calls:\n",
      "  add (chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c)\n",
      " Call ID: chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "8\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='1e85ca38-9e4f-43b9-b9e7-23f9567ee9f6'), AIMessage(content='[Brief explanation: The `add` function is essential to first calculate 3 + 5, and the `multiply` function is then required to multiply the result by 8. The second function depends on the output of the first, so both are necessary to answer the question.]\\n\\nNote: Since the system doesn\\'t support passing intermediate results directly between functions, the second function would need to be called with the explicit value from the first result in a real implementation. Here, \"add_result\" represents that placeholder concept. The actual calculation would be:\\n1. add(a=3, b=5) → 8\\n2. multiply(a=8, b=8) → 64\\n\\nThe final answer is 64.', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', 'function': {'arguments': '{\"a\": 8, \"b\": \"add_result\"}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 179, 'prompt_tokens': 585, 'total_tokens': 764, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'a7ff1396-1dd6-4167-9b82-695d3707315f', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--148886a8-397d-471d-8d19-81474891146b-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 'add_result'}, 'id': 'chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', 'type': 'tool_call'}], usage_metadata={'input_tokens': 585, 'output_tokens': 179, 'total_tokens': 764, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='dbe2ec90-48e5-4edb-a960-fb90f2d9abc0', tool_call_id='chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31'), ToolMessage(content=\"Error: 1 validation error for multiply\\nb\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='add_result', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\\n Please fix your mistakes.\", name='multiply', id='1cb6fa84-9a45-41f7-a899-94804d16a91f', tool_call_id='chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', status='error'), AIMessage(content=\"I need to correct my approach since the system doesn't support passing intermediate results symbolically. Here's the proper sequence:\\n\\n[First call add to get 3+5=8]\\n\\nAfter getting the result from add, I'll make the second call:\\n\\n<tool_call>[multiply(a=8,b=8)]</tool_call>\\n[Then multiply the result (8) by 8 to get the final answer]\\n\\nThe calculation sequence is:\\n1. 3 + 5 = 8\\n2. 8 × 8 = 64\\n\\nThe final answer is 64.\", additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 854, 'total_tokens': 992, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '120dfae8-4e43-460a-ba28-11c322dad4f3', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9be2a820-402b-4120-9a5a-c228391591dd-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 854, 'output_tokens': 138, 'total_tokens': 992, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='dc8cc398-a6d2-4851-98fb-bf2dd31b3789', tool_call_id='chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c'), AIMessage(content='[After getting 8 from 3+5, this multiplication is essential to complete the calculation: 8 × 8 = 64]\\n\\nThe final answer is 64.', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-3d34607831a24e29a27f578615fd9896', 'function': {'arguments': '{\"a\": 8, \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1007, 'total_tokens': 1063, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '6773edad-e434-4610-a865-21f18f48edfc', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c0b9a22f-85da-41cf-a0f6-f43f6375674a-0', tool_calls=[{'name': 'multiply', 'args': {'a': 8, 'b': 8}, 'id': 'chatcmpl-tool-3d34607831a24e29a27f578615fd9896', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1007, 'output_tokens': 56, 'total_tokens': 1063, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[After getting 8 from 3+5, this multiplication is essential to complete the calculation: 8 × 8 = 64]\n",
      "\n",
      "The final answer is 64.\n",
      "Tool Calls:\n",
      "  multiply (chatcmpl-tool-3d34607831a24e29a27f578615fd9896)\n",
      " Call ID: chatcmpl-tool-3d34607831a24e29a27f578615fd9896\n",
      "  Args:\n",
      "    a: 8\n",
      "    b: 8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "64\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='1e85ca38-9e4f-43b9-b9e7-23f9567ee9f6'), AIMessage(content='[Brief explanation: The `add` function is essential to first calculate 3 + 5, and the `multiply` function is then required to multiply the result by 8. The second function depends on the output of the first, so both are necessary to answer the question.]\\n\\nNote: Since the system doesn\\'t support passing intermediate results directly between functions, the second function would need to be called with the explicit value from the first result in a real implementation. Here, \"add_result\" represents that placeholder concept. The actual calculation would be:\\n1. add(a=3, b=5) → 8\\n2. multiply(a=8, b=8) → 64\\n\\nThe final answer is 64.', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', 'function': {'arguments': '{\"a\": 8, \"b\": \"add_result\"}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 179, 'prompt_tokens': 585, 'total_tokens': 764, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'a7ff1396-1dd6-4167-9b82-695d3707315f', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--148886a8-397d-471d-8d19-81474891146b-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 'add_result'}, 'id': 'chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', 'type': 'tool_call'}], usage_metadata={'input_tokens': 585, 'output_tokens': 179, 'total_tokens': 764, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='dbe2ec90-48e5-4edb-a960-fb90f2d9abc0', tool_call_id='chatcmpl-tool-6c4f087b2f5242c4b639a31b00b3fa31'), ToolMessage(content=\"Error: 1 validation error for multiply\\nb\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='add_result', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\\n Please fix your mistakes.\", name='multiply', id='1cb6fa84-9a45-41f7-a899-94804d16a91f', tool_call_id='chatcmpl-tool-d7ebc79292cf41a38908840b2fcb9998', status='error'), AIMessage(content=\"I need to correct my approach since the system doesn't support passing intermediate results symbolically. Here's the proper sequence:\\n\\n[First call add to get 3+5=8]\\n\\nAfter getting the result from add, I'll make the second call:\\n\\n<tool_call>[multiply(a=8,b=8)]</tool_call>\\n[Then multiply the result (8) by 8 to get the final answer]\\n\\nThe calculation sequence is:\\n1. 3 + 5 = 8\\n2. 8 × 8 = 64\\n\\nThe final answer is 64.\", additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 854, 'total_tokens': 992, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '120dfae8-4e43-460a-ba28-11c322dad4f3', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9be2a820-402b-4120-9a5a-c228391591dd-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 854, 'output_tokens': 138, 'total_tokens': 992, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='dc8cc398-a6d2-4851-98fb-bf2dd31b3789', tool_call_id='chatcmpl-tool-e7dda8ce32a2432e9a139a0666acc78c'), AIMessage(content='[After getting 8 from 3+5, this multiplication is essential to complete the calculation: 8 × 8 = 64]\\n\\nThe final answer is 64.', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-3d34607831a24e29a27f578615fd9896', 'function': {'arguments': '{\"a\": 8, \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 1007, 'total_tokens': 1063, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '6773edad-e434-4610-a865-21f18f48edfc', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c0b9a22f-85da-41cf-a0f6-f43f6375674a-0', tool_calls=[{'name': 'multiply', 'args': {'a': 8, 'b': 8}, 'id': 'chatcmpl-tool-3d34607831a24e29a27f578615fd9896', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1007, 'output_tokens': 56, 'total_tokens': 1063, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='64', name='multiply', id='cb89214f-f104-4d30-bb85-856d27113b2b', tool_call_id='chatcmpl-tool-3d34607831a24e29a27f578615fd9896'), AIMessage(content='64  \\n\\n(계산 과정: 3 + 5 = 8 → 8 × 8 = 64)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 1079, 'total_tokens': 1107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '67434429-b203-4178-98b5-c86dc960c914', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--c3e92803-7f55-48a6-85f3-6f1ea30563a3-0', usage_metadata={'input_tokens': 1079, 'output_tokens': 28, 'total_tokens': 1107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "64  \n",
      "\n",
      "(계산 과정: 3 + 5 = 8 → 8 × 8 = 64)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for chunk in graph.stream({'messages': [HumanMessage('3에다 5를 더하고 거기에 8을 곱하면?')]}, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-0lCeHk3W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
