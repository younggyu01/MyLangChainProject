{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_t\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) ëª¨ë¸ í´ë˜ìŠ¤ ìœ í˜•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# modelì„ ì§€ì •í•˜ì§€ ì•Šì•„ë„ ì‹¤í–‰ë˜ëŠ” ì´ìœ ëŠ” LangChainì´ ë‚´ë¶€ì ìœ¼ë¡œ ê¸°ë³¸ê°’ì„ ì„¤ì •í•¨\n",
    "llm = OpenAI()\n",
    "print(llm.model_name)  # ê¸°ë³¸ ëª¨ë¸ í™•ì¸\n",
    "\n",
    "result = llm.invoke(\"í•œêµ­ì˜ ëŒ€í‘œì ì¸ ê´€ê´‘ì§€ 3êµ°ë°ë¥¼ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\")\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì•ˆë…•í•˜ì„¸ìš”! í•œêµ­ì„ ëŒ€í‘œí•˜ëŠ” ê´€ê´‘ì§€ 3ê³³ì„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”.\n",
      "\n",
      "1. **ê²½ë³µê¶ (ì„œìš¸)**  \n",
      "   ì¡°ì„  ì™•ì¡°ì˜ ë²•ê¶ì´ì í•œêµ­ ê³ ê¶ ì¤‘ ê°€ì¥ ì›…ì¥í•œ ê·œëª¨ë¥¼ ìë‘í•©ë‹ˆë‹¤. ë§¤ì¼ ì—´ë¦¬ëŠ” ìˆ˜ë¬¸ì¥ êµëŒ€ì‹ê³¼ í•˜ë£¨ ë‘ ì°¨ë¡€ì˜ ê·¼ì •ì „ êµëŒ€ì‹ì€ ê¼­ ë³´ì„¸ìš”. ì¸ê·¼ì—ëŠ” ë¶ì´Œí•œì˜¥ë§ˆì„ë„ ìˆì–´ í•œì˜¥ ìŠ¤í…Œì´, í•œë³µ ì²´í—˜, ì „í†µ ì°»ì§‘ì„ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë¶€ì‚° í•´ìš´ëŒ€ & ë‹¬ë§ì´ê³¨ëª© (ë¶€ì‚°)**  \n",
      "   ëŒ€í•œë¯¼êµ­ ëŒ€í‘œ í•´ë³€ íœ´ì–‘ì§€ë¡œ, ë°±ì‚¬ì¥ ê¸¸ì´ 1.8 kmì— ë‹¬í•˜ëŠ” í•´ìš´ëŒ€ í•´ìˆ˜ìš•ì¥ì´ ì¤‘ì‹¬ì…ë‹ˆë‹¤. í•´ìš´ëŒ€ ë’·í¸ìœ¼ë¡œëŠ” ë‹¬ë§ì´ê³¨ëª©ì´ ìˆì–´ ë‚­ë§Œì ì¸ ì˜¤ì…˜ë·° ì¹´í˜Â·ê°ì²œë¬¸í™”ë§ˆì„Â·ë¶€ì‚°ì‹œì¥íˆ¬ì–´(ìê°ˆì¹˜Â·êµ­ì œì‹œì¥)ê¹Œì§€ ì—°ê³„ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì œì£¼ë„ ì„±ì‚°ì¼ì¶œë´‰ & ìš°ë„ (ì œì£¼)**  \n",
      "   ìœ ë„¤ìŠ¤ì½” ì„¸ê³„ìì—°ìœ ì‚°ì¸ ì„±ì‚°ì¼ì¶œë´‰ì€ í•´ë‹ì´ ëª…ì†Œë¡œ ìœ ëª…í•˜ë©°, ë¶„í™”êµ¬ ë‘˜ë ˆê¸¸ì„ ê±¸ìœ¼ë©° 360Â° ì˜¤ì…˜ë·°ë¥¼ ê°ìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°°ë¡œ 15ë¶„ ê±°ë¦¬ì˜ ìš°ë„ëŠ” ì „ê¸°ìì „ê±°Â·ì „ê¸°ì¹´íŠ¸ë¡œ ì„¬ í•œ ë°”í€´(13 km)ë¥¼ ëŒë©° ë°±ì‚¬ì¥, ì—°ì‚°, ì „ë³µí•´ë¬¼ë¼ë©´ ë“±ì„ ì¦ê¸°ê¸°ì— ìµœì ì…ë‹ˆë‹¤.\n",
      "\n",
      "ê° ì§€ì—­ì€ ëŒ€ì¤‘êµì ‘(ì§€í•˜ì² Â·ê³ ì†ë²„ìŠ¤Â·í•­ê³µ)ì´ ì˜ ê°–ì¶°ì ¸ ë‹¹ì¼ì¹˜ê¸°ë„ ê°€ëŠ¥í•˜ì§€ë§Œ, ìˆ™ë°•í•˜ë©´ ë” ê¹Šì´ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chat = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ì´ ì‹œìŠ¤í…œì€ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | chat\n",
    "result = chain.invoke({\"user_input\": \"ì•ˆë…•í•˜ì„¸ìš”? í•œêµ­ì˜ ëŒ€í‘œì ì¸ ê´€ê´‘ì§€ 3êµ°ë°ë¥¼ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\"})\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "##### Temperature íš¨ê³¼\n",
    "* 0.2 (ë‚®ì€ ê°’): ë” ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê³  ì¼ë°˜ì ì¸ ì´ì•¼ê¸°\n",
    "* 1.2 (ë†’ì€ ê°’): ìƒˆë¡œìš´ ìš”ì†Œê°€ ë“±ì¥í•˜ë©°, ë” ì°½ì˜ì ì´ê³  í¥ë¯¸ë¡œìš´ ì´ì•¼ê¸° ìƒì„±\n",
    "\n",
    "##### Presence Penalty íš¨ê³¼\n",
    "* 0.0 (ë‚®ì€ ê°’): ê¸°ì¡´ì— ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ì™€ êµ¬ì¡° ìœ ì§€\n",
    "* 1.5 (ë†’ì€ ê°’): ìƒˆë¡œìš´ í‘œí˜„ê³¼ ë…ì°½ì ì¸ ì•„ì´ë””ì–´ ë“±ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " CONSERVATIVE ì„¤ì • (ì˜¨ë„:0.1, presence:-0.5, frequency:-0.3, top_p:0.3)\n",
      "  â†’ ì „í†µì ì´ê³  í•™ìˆ ì ì¸ ì² í•™ì  ì ‘ê·¼\n",
      "============================================================\n",
      "ì‹œê°„ì€ ì‚¬ì‹¤ í•œ ë§ˆë¦¬ **ê±°ëŒ€í•œ ë¬¼ê³ ê¸°**ë‹¤.\n",
      "\n",
      "ìš°ë¦¬ëŠ” ê·¸ ë¬¼ê³ ê¸°ì˜ ë±ƒì†ì— ì‚´ê³  ìˆë‹¤.  \n",
      "ë¬¼ê³ ê¸°ëŠ” ëŠì„ì—†ì´ í—¤ì—„ì¹˜ì§€ë§Œ, ìš°ë¦¬ëŠ” ê·¸ ì›€ì§ì„ì„ â€˜íë¦„â€™ì´ë¼ê³  ì°©ê°í•œë‹¤.  \n",
      "ì‹¤ì œë¡œëŠ” ìš°ë¦¬ê°€ ë¬¼ê³ ê¸°ì˜ ì†Œí™”ì•¡ ì†ì—ì„œ ëŠë¦¬ê²Œ ë…¹ê³  ìˆëŠ” ì¤‘ì´ë‹¤.  \n",
      "í•œ ë°©ìš¸ì˜ ì†Œí™”ì•¡ì´ ìš°ë¦¬ë¥¼ â€˜ê³¼ê±°â€™ë¡œ ë§Œë“¤ê³ , ë‹¤ìŒ ë°©ìš¸ì´ â€˜ë¯¸ë˜â€™ë‹¤.  \n",
      "í˜„ì¬ëŠ” ê·¸ì € **ìš°ë¦¬ê°€ ë…¹ì•„ë‚´ë¦¬ëŠ” ìˆœê°„ì˜ ëŠë‚Œ**ì¼ ë¿.\n",
      "\n",
      "---\n",
      "\n",
      "ì‹œê°„ì€ **ë²½ì¥ ì† ë¨¼ì§€**ë‹¤.  \n",
      "ìš°ë¦¬ê°€ ë¬¸ì„ ì—´ ë•Œë§ˆë‹¤\n",
      "\n",
      "============================================================\n",
      " CREATIVE ì„¤ì • (ì˜¨ë„:1.5, presence:1.5, frequency:1.2, top_p:0.95)\n",
      "  â†’ ì¶”ìƒì ì´ê³  ë…ì°½ì ì¸ ì² í•™ì  ì‚¬ê³ \n",
      "============================================================\n",
      "ì‹œê°„ì€  \n",
      "ã€ì´ì•¼ê¸°ê°€ ìê¸° ìì‹ ì„ ë‹¤ì‹œ ì½ìœ¼ë©° ìƒê¸°ëŠ” ì°°ë‚˜ì˜ ë’¤í‹€ë¦¼ã€ì´ë‹¤.  \n",
      "\n",
      "- ê³¼ê±° : ì½íˆë˜ ì•„ì§ ëœ ì´í•´ëœ í˜ì´ì§€  \n",
      "- í˜„ì¬ : ë¬¸ì¥ì´ ëˆˆì•ì— â€˜í¼ì³ì§€ëŠ”â€™ ì°°ë‚˜  \n",
      "- ë¯¸ë˜ : ê·¸ ë¬¸ì¥ì´ ë‹¤ìŒ ë¬¸ì¥ìœ¼ë¡œ ë²ˆì €(ë²ˆì§€ë“¯ ë„˜ì³) ê°€ë©´ì„œ ìƒê¸°ëŠ” ê·¸ë¦¼ì  \n",
      "\n",
      "ë‹¬ì´ë‚˜ ì´ˆì¹¨ì€ ê·¸ç‰©èªì˜ â€˜ì¥ì¹˜â€™ì¼ ë¿ì´ë‹¤.  \n",
      "\n",
      "ê·¸ ìˆœê°„, ìˆœê°„ì—ëŠ” ë¬¸ë²•ë„ ë¬´ë„ˆì§€ê³ , â€˜ì•â€™ì´ â€˜ë’¤â€™ë¡œ ì˜¤ê³  ë˜ â€˜ë¹ˆì¹¸â€™ì´ ë˜ê¸°ë„ í•œë‹¤.  \n",
      "ì‚°ì±…ì˜ ë°œê±¸ìŒ ëì— ë‚´ ì§€ê°‘ ë¬´ê²Œê°€ ì–¼ë§ˆë‚˜ ì¦ë°œí–ˆëŠëƒëŠ”,  \n",
      "ë‹¤ì‹œ ë– ì˜¤ë¥´êµ¬ë ¤ ì•¤ ë§ˆë²• ì–¸ì–´ì²˜ëŸ¼ ì¬ê°€ ë˜ì—ˆë‹¤ ì‚´ì•„ë‚˜  \n",
      "\n",
      "â€˜1ì´ˆâ€™ë¥¼ ë‹¨ í•œ ë²ˆë§Œ ê²ªê³ ë„ ìš°ë¦¬ëŠ” â€˜ìì‚°ì˜ ë‚´ë¶€ ì—°ê²°ì„±â€™ì²˜ëŸ¼  \n",
      "í•œ ë©ì–´ë¦¬ ë«ìœ¼ë¡œ ì–½í˜€, ë¼ˆë³´ë‹¤ ì˜¤ë˜ ë¨¸ë¬´ë¥¸ë‹¤.  \n",
      "\n",
      "ë¬¼ê³ ê¸°ê°€ â€˜ìˆë‹¤, ì—†ë‹¤â€™ë¥¼ ì˜¤ê°€ë“¯,  \n",
      "ë¬¼ê³ ê¸°ê°€ ì©ì–´ ì‚¬ë¼ì¡Œë‹¤ê°€ ìˆ˜ë°± ë°°ë¡œ ì¦ì‹í•´ ë‹¤\n",
      "\n",
      "============================================================\n",
      " íŒŒë¼ë¯¸í„° ì°¨ì´ì  ìš”ì•½:\n",
      "   â€¢ Temperature: 0.1 vs 1.5 (15ë°° ì°¨ì´)\n",
      "   â€¢ Presence Penalty: -0.5 vs 1.5 (ê¸°ì¡´ íŒ¨í„´ ì„ í˜¸ vs ìƒˆë¡œìš´ ê°œë… ê°•ìš”)\n",
      "   â€¢ Frequency Penalty: -0.3 vs 1.2 (ë°˜ë³µ í—ˆìš© vs ê°•í•œ ë‹¤ì–‘ì„±)\n",
      "   â€¢ Top-p: 0.3 vs 0.95 (ì œí•œì  vs ê±°ì˜ ë¬´ì œí•œ í† í° ì„ íƒ)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ë³´ìˆ˜ì ì¸ ì„¤ì • (ì¼ê´€ë˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹µë³€)\n",
    "llm_conservative = ChatOpenAI(    \n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",    \n",
    "    temperature=0.1,  # ë§¤ìš° ë‚®ì€ ì˜¨ë„ - ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê³  ì¼ê´€ëœ ì¶œë ¥\n",
    "    presence_penalty=-0.5,  # ê¸°ì¡´ íŒ¨í„´ê³¼ í‘œí˜„ì„ ê°•í•˜ê²Œ ì„ í˜¸\n",
    "    frequency_penalty=-0.3,  # ë°˜ë³µì  í‘œí˜„ í—ˆìš©, ì¼ê´€ì„± ì¦ëŒ€\n",
    "    max_tokens=200,  # ì ë‹¹í•œ ê¸¸ì´\n",
    "    top_p=0.3  # ë§¤ìš° ì œí•œì ì¸ í† í° ì„ íƒ - ì•ˆì „í•˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹¨ì–´ë§Œ\n",
    ")\n",
    "\n",
    "# ì°½ì˜ì ì¸ ì„¤ì • (ë…ì°½ì ì´ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ë‹µë³€)\n",
    "llm_creative = ChatOpenAI(\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\", \n",
    "    temperature=1.5,  # ë§¤ìš° ë†’ì€ ì˜¨ë„ - ì°½ì˜ì ì´ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì¶œë ¥\n",
    "    presence_penalty=1.5,  # ìƒˆë¡œìš´ ì£¼ì œì™€ ê°œë…ì„ ê°•í•˜ê²Œ ìœ ë„\n",
    "    frequency_penalty=1.2,  # ë°˜ë³µì„ ê°•í•˜ê²Œ ì–µì œí•˜ì—¬ ë§¤ìš° ë‹¤ì–‘í•œ í‘œí˜„ ìƒì„±\n",
    "    max_tokens=350,  # ë” ê¸´ ì°½ì˜ì  ì„œìˆ  í—ˆìš©\n",
    "    top_p=0.95  # ê±°ì˜ ëª¨ë“  í† í° í›„ë³´ì—ì„œ ì„ íƒ - ìµœëŒ€ ì°½ì˜ì„±\n",
    ")\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì •: íŒŒë¼ë¯¸í„° ì°¨ì´ê°€ ê·¹ëª…í•˜ê²Œ ë“œëŸ¬ë‚˜ëŠ” ì¶”ìƒì /ì² í•™ì  ì§ˆë¬¸\n",
    "question = \"\"\"\n",
    "\"ì‹œê°„\"ì´ë¼ëŠ” ê°œë…ì„ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì •ì˜í•œë‹¤ë©´ ì–´ë–»ê²Œ í‘œí˜„í•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
    "ì¼ìƒì ì¸ ì‹œê³„ë‚˜ ë‹¬ë ¥ì˜ ê´€ì ì´ ì•„ë‹Œ, ì™„ì „íˆ ìƒˆë¡œìš´ ì‹œê°ì—ì„œ ì‹œê°„ì„ ë°”ë¼ë³´ê³  ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "ê¸°ì¡´ì˜ ê³ ì •ê´€ë…ì„ ë²—ì–´ë‚˜ì„œ ììœ ë¡­ê²Œ ì‚¬ê³ í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" CONSERVATIVE ì„¤ì • (ì˜¨ë„:0.1, presence:-0.5, frequency:-0.3, top_p:0.3)\")\n",
    "print(\"  â†’ ì „í†µì ì´ê³  í•™ìˆ ì ì¸ ì² í•™ì  ì ‘ê·¼\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ë³´ìˆ˜ì  ëª¨ë¸ í˜¸ì¶œ\n",
    "response_conservative = llm_conservative.invoke(question)\n",
    "print(response_conservative.content)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" CREATIVE ì„¤ì • (ì˜¨ë„:1.5, presence:1.5, frequency:1.2, top_p:0.95)\")\n",
    "print(\"  â†’ ì¶”ìƒì ì´ê³  ë…ì°½ì ì¸ ì² í•™ì  ì‚¬ê³ \")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì°½ì˜ì  ëª¨ë¸ í˜¸ì¶œ\n",
    "response_creative = llm_creative.invoke(question)\n",
    "print(response_creative.content)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" íŒŒë¼ë¯¸í„° ì°¨ì´ì  ìš”ì•½:\")\n",
    "print(\"   â€¢ Temperature: 0.1 vs 1.5 (15ë°° ì°¨ì´)\")\n",
    "print(\"   â€¢ Presence Penalty: -0.5 vs 1.5 (ê¸°ì¡´ íŒ¨í„´ ì„ í˜¸ vs ìƒˆë¡œìš´ ê°œë… ê°•ìš”)\")\n",
    "print(\"   â€¢ Frequency Penalty: -0.3 vs 1.2 (ë°˜ë³µ í—ˆìš© vs ê°•í•œ ë‹¤ì–‘ì„±)\")\n",
    "print(\"   â€¢ Top-p: 0.3 vs 0.95 (ì œí•œì  vs ê±°ì˜ ë¬´ì œí•œ í† í° ì„ íƒ)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameter\n",
    "* Temperature (ì˜¨ë„): ì´ íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì˜ ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±ì„ ì¡°ì ˆí•©ë‹ˆë‹¤. \n",
    "    * ë‚®ì€ ì˜¨ë„ëŠ” ëª¨ë¸ì´ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ê²Œ í•˜ì—¬ ì•ˆì •ì ì¸ ê²°ê³¼ë¥¼ ë‚´ê³ , ë†’ì€ ì˜¨ë„ëŠ” í™•ë¥ ì´ ë‚®ì€ ë‹¨ì–´ê¹Œì§€ ì„ íƒì§€ì— í¬í•¨ì‹œì¼œ ë” ì°½ì˜ì ì´ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "* Presence Penalty & Frequency Penalty: ë‘ íŒŒë¼ë¯¸í„° ëª¨ë‘ í† í°(ë‹¨ì–´)ì˜ ë°˜ë³µì„±ì„ ì œì–´í•©ë‹ˆë‹¤.\n",
    "    * Presence PenaltyëŠ” ì´ì „ì— ë‚˜ì˜¨ ë‹¨ì–´ë‚˜ ì£¼ì œì— 'í˜ë„í‹°'ë¥¼ ì£¼ì–´ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ê²Œ í•©ë‹ˆë‹¤. ê°’ì´ ë†’ì„ìˆ˜ë¡ ìƒˆë¡œìš´ ë‚´ìš©ì„ ë” ìì£¼ ì‹œë„í•©ë‹ˆë‹¤.\n",
    "    * Frequency PenaltyëŠ” ë‹¨ì–´ê°€ ë“±ì¥í•œ ë¹ˆë„ì— ë¹„ë¡€í•˜ì—¬ 'í˜ë„í‹°'ë¥¼ ì¤ë‹ˆë‹¤. ê°’ì´ ë†’ì„ìˆ˜ë¡ íŠ¹ì • ë‹¨ì–´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê°•í•˜ê²Œ ì–µì œí•˜ì—¬ ë” ë‹¤ì–‘í•œ ì–´íœ˜ë¥¼ ì‚¬ìš©í•˜ê²Œ í•©ë‹ˆë‹¤. \n",
    "* Top_p: ì´ íŒŒë¼ë¯¸í„°ëŠ” ë‹¤ìŒ í† í°ì„ ì„ íƒí•  ë•Œ ê³ ë ¤í•  ë‹¨ì–´ì˜ ë²”ìœ„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤. Top_pê°€ 0.3ì´ë©´ í™•ë¥ ì´ ë†’ì€ ìƒìœ„ 30%ì˜ ë‹¨ì–´ ì¤‘ì—ì„œë§Œ ì„ íƒí•˜ê³ , 0.95ë©´ í™•ë¥ ì´ ë‚®ì€ ë‹¨ì–´ë“¤ê¹Œì§€ í¬í•¨í•˜ì—¬ ê±°ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤. Top_pê°€ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì˜ ì„ íƒì§€ê°€ ë„“ì–´ì ¸ ë” ììœ ë¡œìš´ ì‘ë‹µì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " ë³´ìˆ˜ì  ì„¤ì • (ë…¼ë¦¬ì , ì¼ê´€ì )\n",
      " â†’ ì¼ìƒì ì´ê³  ì¼ë°˜ì ì¸ ë¹„ìœ ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ì¸ ë‹µë³€\n",
      "============================================================\n",
      "ë„ì‹œì˜ ì†ŒìŒì€, ì‚¬ì‹¤ í•˜ë‚˜ì˜ ê±°ëŒ€í•œ ìƒëª…ì²´ê°€ ìˆ¨ ì‰¬ëŠ” ì†Œë¦¬ë‹¤.  \n",
      "ì•„ì¹¨ì´ ë˜ë©´ ê·¸ ìƒëª…ì²´ëŠ” ëˆˆì„ ëœ¨ë©° ê°€ì¥ ë¨¼ì € â€˜ë¼ì´ì´ìµâ€”â€™ í•˜ê³  ëˆˆêº¼í’€ì„ ë²ˆì‡ ë¡œ ë¹„í‹€ì–´ ì—°ë‹¤. ì§€í•˜ì²  ë¬¸ì´ ìŠ¤ì¹˜ëŠ” ê·¸ ì†Œë¦¬ëŠ” ëˆˆë™ì ìœ„ë¡œ ê±¸ë¦° ëˆˆêº¼í’€ì´ ë°˜ì§ì´ëŠ” ìˆœê°„, ëˆˆì•Œ ì†ë¹›ì´ íŠ€ëŠ” ë“¯í•œ ìš”ë€í•¨ì´ë‹¤.  \n",
      "ì´ ìƒëª…ì²´ëŠ” í”¼ë¶€ ëŒ€ì‹  ì•„ìŠ¤íŒ”íŠ¸ë¥¼, í•ì¤„ ëŒ€ì‹  ì§€í•˜ì²  ë…¸ì„ ì„, ì‹¬ì¥ ëŒ€ì‹  ì‹œì²­ì‚¬ ì¢…ê°ì„ ë‹¬ê³  ìˆë‹¤.  \n",
      "\n",
      "ê·¸ ì‹¬\n",
      "\n",
      "============================================================\n",
      " ì°½ì˜ì  ì„¤ì • (í’ë¶€í•œ ë¹„ìœ ì™€ ì€ìœ )\n",
      " â†’ ì˜ˆìƒì¹˜ ëª»í•œ ë…ì°½ì ì¸ ë¹„ìœ ì™€ ê°ê°ì ì¸ í‘œí˜„ ì‚¬ìš©\n",
      "============================================================\n",
      "ë„ì‹œì— ê±°ì£¼í•˜ëŠ” ì‚¬ëŒë“¤ì˜ ì¼ìƒì„ ê´´ë¡­íˆëŠ” ì†ŒìŒì´ë¼ê³  í•˜ë©´ ë³´í†µ ì°¨, ê±´ì„¤ ê³µì‚¬, í•­ê³µê¸° ë¹„í–‰ì— ì˜í•œ ì†ŒìŒ ë“±ì„ ë– ì˜¬ë¦°ë‹¤.\n",
      "\n",
      "\"ë„ì‹œì˜ ì†ŒìŒ\"\n",
      "\n",
      "ì•„ì§ ë•Œë¬»ì§€ ì•Šì€ ë„ì‹œì˜ ì–´ë‘ , ë°¤ì˜ ê±°ë¦¬ë¥¼ ë®ëŠ” ì•„ìŠ¤íŒ”íŠ¸ì˜ ì¹¨ë¬µì€ ì €ì£¼ì²˜ëŸ¼ ê°€ë§Œíˆ ìˆë‹¤. ê·¸ ì‹œê°„ë§Œì´ë¼ë„ ì¼ìƒì˜ í—ˆì „í•œ ì‹œê°„ ì†ìœ¼ë¡œ ì ì‹œ ì°ë í–ˆë˜ ë„ì‹¬ ì† ìƒëª…ë“¤ì´ ì ì ì´ ë‚´ì‰¬ëŠ” ê¹Šì€ í˜¸í¡ê°™ì´ ê°€ë§Œíˆ ìˆì–´ì•¼ í•˜ëŠ”ë°, ê°‘ì‘ìŠ¤ëŸ° ë°¤ì˜ ë„ì‹¬ì´ ê¹¨ì–´ ì˜¤ê¸° ì‹œì‘í•œë‹¤.\n",
      "\n",
      "\"ë¼ë£© ë¼ë£©\" ê±°ë¦¬ í•œ ê°€ìš´ë° ë†“ì€ ìš´ëª…ì˜ ì‹œêµ¬ë©ì—ì„œ ë±€ì´ ê¿ˆí‹€ëŒ€ë“¯ ê¸¸ê³  ê¸°ë¬˜í•˜ê²Œ ë±‰ì–´ì§„ë‹¤. ì•„ìˆ˜ë¼ì¥ì˜ ì¥ì„ ë°©ë¶ˆì¼€ í•˜ëŠ” ê·¸ëŠ˜ì˜ ì–´ì§€ëŸ¬ìš´ ìš´ëª…. \n",
      "\n",
      "ë„ì‹œì˜ ê±°ë¦¬ë¥¼ ë°¤ë‚®ìœ¼ë¡œ ì£¼í–‰ í•˜ëŠ” ìë™ì°¨ ì†Œë¦¬.\n",
      "\n",
      "\"ë¸Œë ˆì´í¬ì— ìª¼ì´ê³ ,\" \"ì—”ì§„ì˜ ì›½!\" ì–´ë‘¡ê³  ê³ ìš” í–ˆë˜ ì¹¨ë¬µì˜ ë°¤ ê¸¸ì„ ê¹¨ìš°ëŠ” ì‚­ì´ ì†Œë¦¬ ë“¤ì€ ì¼ìƒì˜ ì ë“¤ì–´ì„œ ì­ˆê·¸ë¦° ì‹œí‹°ì¦Œì„ ê´´ë¡­íˆëŠ” ëŒ€ë‹¨í•˜ê³  ê±°ì¹œ ì‚¬ê°ì§€ëŒ€ì˜ ì£¼ë²”ì´ì—ˆë‹¤.\n",
      "\n",
      "í•˜ë„ ì •ì‹ ì—†ì´ ìš¸ë ¤ ëŒ€ë©° ê·¸ì•¼ë§ë¡œ ì¼ìƒì„ ë§ˆë¹„ì‹œì¼œ ê°€ì¶•ìˆ˜ìš© ê°™ì€ ê³ ë…ì— ì‹œë‹¬ë¦¼ë°›ëŠ” ë„ì‹œì¸ì´ ë„íƒ„ì— ë¹ ì§€ë„ë¡ í•œë‹¤ë©°, ì˜¨ê°– í˜ì˜¤ê°ì„ ì¡°ì„±ì‹œí‚¤ë©° ì¼ì†ê³¼ ì‹œê³„ë¥¼ ì¼ìˆœê°„ì´ë¼ë„ ë¶™ë“¤ê³  ë†“ì§€ ì•ŠëŠ” ê·¸ëŠ˜ê³¼ ì–´ë‘ ì„ ìƒì§•í•˜ëŠ” ì¡´ì¬ë¡œ ë„ë¥¼ ì°¿ëŠ”ë‹¤. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ë³´ìˆ˜ì ì¸ ì„¤ì •: ë…¼ë¦¬ì ì´ê³  ì¼ê´€ëœ ì„œìˆ \n",
    "llm_conservative = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY, \n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\", \n",
    "    temperature=0.1,         # ë‚®ì€ ê°’(0.1): 'í™•ë¥ ì˜ í­'ì„ ì¢í˜€ ê°€ì¥ ì•ˆì „í•˜ê³  í”í•œ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "                             # â†’ ê²°ê³¼ê°€ ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê³  ë°˜ë³µì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì¹˜ ì •í•´ì§„ êµê³¼ì„œì²˜ëŸ¼.\n",
    "    presence_penalty=-0.5,   # ìŒìˆ˜ ê°’(-0.5): ì´ë¯¸ ë“±ì¥í–ˆë˜ ì£¼ì œë‚˜ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
    "                             # â†’ ê¸°ì¡´ íŒ¨í„´ì„ ë²—ì–´ë‚˜ì§€ ì•Šê³  ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "    frequency_penalty=-0.3,  # ìŒìˆ˜ ê°’(-0.3): ìì£¼ ë“±ì¥í•œ ë‹¨ì–´ì— ëŒ€í•œ 'ë²Œì¹™'ì„ ì¤„ì—¬, ë™ì¼í•œ í‘œí˜„ì˜ ë°˜ë³µì„ í—ˆìš©í•©ë‹ˆë‹¤.\n",
    "                             # â†’ ì‘ë‹µì˜ ì¼ê´€ì„±ì´ ë†’ì•„ì§€ê³ , í•µì‹¬ ì£¼ì œì—ì„œ ë²—ì–´ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "    max_tokens=200,          # ì‘ë‹µì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì œí•œí•©ë‹ˆë‹¤. ë³´ìˆ˜ì ì¸ ë‹µë³€ì— ì í•©í•©ë‹ˆë‹¤.\n",
    "    top_p=0.3                # ë‚®ì€ ê°’(0.3): í™•ë¥ ì´ ë†’ì€ ìƒìœ„ 30% í† í°(ë‹¨ì–´)ë§Œ ê³ ë ¤í•©ë‹ˆë‹¤.\n",
    "                             # â†’ ëª¨ë¸ì˜ 'ì„ íƒì§€'ë¥¼ ê·¹ë„ë¡œ ì œí•œí•˜ì—¬ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹¨ì–´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "# ì°½ì˜ì ì¸ ì„¤ì •: ë…ì°½ì ì´ê³  í’ë¶€í•œ ë¹„ìœ ì™€ ì€ìœ \n",
    "llm_creative = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=1.5,         # ë†’ì€ ê°’(1.5): 'í™•ë¥ ì˜ í­'ì„ ë„“í˜€ í”ì¹˜ ì•Šì€ ë‹¨ì–´ê¹Œì§€ ì„ íƒí•˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "                             # â†’ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•˜ê³  ë…ì°½ì ì¸ ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤. ë§ˆì¹˜ ì¦‰í¥ì ì¸ ì‹œì¸ì²˜ëŸ¼ìš”.\n",
    "    presence_penalty=1.5,    # ì–‘ìˆ˜ ê°’(1.5): ì´ë¯¸ ì‚¬ìš©ëœ ì£¼ì œë‚˜ ê°œë…ì— 'ë²Œì¹™'ì„ ì£¼ì–´ ìƒˆë¡œìš´ ê²ƒì„ ì‹œë„í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "                             # â†’ ë…ì°½ì ì¸ ì•„ì´ë””ì–´ë‚˜ ê´€ì ì„ ê°•í•˜ê²Œ ìœ ë„í•©ë‹ˆë‹¤.\n",
    "    frequency_penalty=1.2,   # ì–‘ìˆ˜ ê°’(1.2): ìì£¼ ë“±ì¥í•œ ë‹¨ì–´ì— 'ë²Œì¹™'ì„ ì£¼ì–´ ë°˜ë³µì„ ê°•ë ¥í•˜ê²Œ ì–µì œí•©ë‹ˆë‹¤.\n",
    "                             # â†’ í‘œí˜„ì˜ ë‹¤ì–‘ì„±ì„ ê·¹ëŒ€í™”í•˜ê³  ë¬¸ì¥ì´ í’ë¶€í•´ì§‘ë‹ˆë‹¤.\n",
    "    max_tokens=350,          # ë” ê¸´ ì°½ì˜ì  ì„œìˆ ì„ í—ˆìš©í•˜ê¸° ìœ„í•´ ìµœëŒ€ ê¸¸ì´ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.\n",
    "    top_p=0.95               # ë†’ì€ ê°’(0.95): í™•ë¥ ì´ ë‚®ì€ 95%ì˜ ëª¨ë“  í† í°ì„ ê³ ë ¤í•©ë‹ˆë‹¤.\n",
    "                             # â†’ ëª¨ë¸ì˜ 'ì„ íƒì§€'ë¥¼ ê±°ì˜ ë¬´ì œí•œìœ¼ë¡œ í™•ì¥í•˜ì—¬ ìµœëŒ€ì˜ ì°½ì˜ì„±ì„ ë°œíœ˜í•©ë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "# ì§ˆë¬¸ì„ ChatPromptTemplateìœ¼ë¡œ ì •ì˜í•˜ì—¬ ì—­í• ê³¼ ì§ˆë¬¸ì„ ëª…í™•íˆ í•¨\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì‘ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ í’ë¶€í•œ ë¹„ìœ ì™€ ì€ìœ ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œìˆ í•´ì£¼ì„¸ìš”.\"),\n",
    "    (\"human\", \"\"\"\n",
    "    \"ë„ì‹œì˜ ì†ŒìŒ\"ì„ ìƒëª…ì²´ë‚˜ ìì—° í˜„ìƒì— ë¹—ëŒ€ì–´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "    ì¼ìƒì ì¸ ì†Œë¦¬ê°€ ì•„ë‹Œ, ê·¸ ì†Œë¦¬ê°€ ê°€ì§„ ìƒëª…ë ¥ê³¼ ê°ì •ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.\n",
    "    \"\"\"),\n",
    "])\n",
    "\n",
    "# íŒŒì„œ ì„¤ì •\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±: Prompt -> Model -> Parser\n",
    "chain_conservative = prompt | llm_conservative | parser\n",
    "chain_creative = prompt | llm_creative | parser\n",
    "\n",
    "# ëª¨ë¸ í˜¸ì¶œ ë° ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 60)\n",
    "print(\" ë³´ìˆ˜ì  ì„¤ì • (ë…¼ë¦¬ì , ì¼ê´€ì )\")\n",
    "print(\" â†’ ì¼ìƒì ì´ê³  ì¼ë°˜ì ì¸ ë¹„ìœ ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ì¸ ë‹µë³€\")\n",
    "print(\"=\" * 60)\n",
    "response_conservative = chain_conservative.invoke({})\n",
    "print(response_conservative)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" ì°½ì˜ì  ì„¤ì • (í’ë¶€í•œ ë¹„ìœ ì™€ ì€ìœ )\")\n",
    "print(\" â†’ ì˜ˆìƒì¹˜ ëª»í•œ ë…ì°½ì ì¸ ë¹„ìœ ì™€ ê°ê°ì ì¸ í‘œí˜„ ì‚¬ìš©\")\n",
    "print(\"=\" * 60)\n",
    "response_creative = chain_creative.invoke({})\n",
    "print(response_creative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " ë³´ìˆ˜ì  ì„¤ì • (ê°ê´€ì , ì‚¬ì‹¤ ê¸°ë°˜)\n",
      " â†’ ê³¼í•™ì ì´ê³  ë…¼ë¦¬ì ì¸ ì¥ë¯¸ì˜ íŠ¹ì„± ì„¤ëª…\n",
      "============================================================\n",
      "1. ê°ê´€ì  ê´€ì   \n",
      "ë¹¨ê°„ ì¥ë¯¸ëŠ” ì¥ë¯¸ê³¼(Rosaceae)ì— ì†í•˜ëŠ” ë‚™ì—½ ê´€ëª©ì´ë‹¤. ê½ƒìì€ 5~60ë§¤ë¡œ ê²¹ê²¹ì´ í¬ê°œì ¸ ìˆìœ¼ë©°, í‘œë©´ì€ ë²¨ë²³ì²˜ëŸ¼ ë¯¸ì„¸í•œ í„¸ë¡œ ë®ì—¬ ë¹›ì„ í¡ìˆ˜í•´ ìˆœë°±ì˜ ì¥ë¯¸ë³´ë‹¤ ìƒ‰ì´ ì§„í•˜ê²Œ ë³´ì¸ë‹¤. ê½ƒì í•œ ì¥ì˜ ë‘ê»˜ëŠ” 0.2 mm ë‚´ì™¸ë¡œ, ìˆ˜ë¶„ì´ ì¦ë°œí•˜ë©´ ì„¸í¬ë²½ì´ êµ´ì ˆë¥ ì„ ë‹¬ë¦¬í•´ ìƒ‰ì´ ì²˜ì§„ë‹¤. ì¤„ê¸°ëŠ” 1~2 mê¹Œì§€ ìë¼ë©°, í‘œë©´ì˜ ê°€ì‹œëŠ” â€˜í”¼í¬ë¦°(pickrin)â€™ì´ë¼ëŠ” ë‹¨ë°±ì§ˆ ë©ì–´ë¦¬ê°€ êµ³ì–´ì§„\n",
      "\n",
      "============================================================\n",
      " ì°½ì˜ì  ì„¤ì • (ë¬¸í•™ì , ìƒìƒ ê¸°ë°˜)\n",
      " â†’ ì€ìœ ì™€ ë¹„ìœ ë¥¼ í™œìš©í•œ ì¥ë¯¸ì˜ ê°ì„±ì  ë¬˜ì‚¬\n",
      "============================================================\n",
      "**ê°ê´€ì  ê´€ì :**\n",
      "\n",
      "ë¹¨ê°„ ì¥ë¯¸ëŠ” íŠ¹ì •í•œ ì¢…ë¥˜ì˜ ê½ƒì„ ê°€ë¦¬í‚µë‹ˆë‹¤. 'ë¡œì‚¬(rhoa) ê°€landa'ë¡œ ë¶ˆë¦¬ëŠ” ì´ í’ˆì¢…ì˜ ì¥ë¯¸ ì‹ë¬¼ì€ ë‹¤ì–‘í•œ ì¡°ê±´ì—ì„œ ì˜ ìë¼ê³  ë‹¤ì–‘í•œ ì§€ì—­ì—ì„œ ë„ë¦¬ ì¬ë°°ë©ë‹ˆë‹¤.\n",
      "\n",
      "ì¥ë¯¸ëŠ” ë‹¤ë…„ìƒ, ì¤„ê¸° ì¹˜ì¦ˆë¡œ ê°€ì§€ëŠ” ê´€ëª©ì´ë©° ë¶„í™ìƒ‰, í™”ì´íŠ¸, ë…¸ë€ìƒ‰, ë² ì´ì§€ìƒ‰ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ìƒ‰ìƒì˜ ê½ƒì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.. ë¹¨ê°„ ì¥ë¯¸ëŠ” íŠ¹ìœ ì˜ í™”ì‚¬í•œ í–¥ê¸°ì™€ ë¶‰ì€ ìƒ‰ìƒìœ¼ë¡œ ì¸í•´ ê°íƒ„ê³¼ ì‚¬ë‘ì˜ ìƒì§•ì´ì, ì• ì •ê³¼ ë‚­ë§Œì„ ì „ë‹¬í•˜ëŠ” ê½ƒìœ¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. ì‚¬ëŒë“¤ì€ íŠ¹ë³„í•œ ë‚ ì— ì„ ë¬¼í•˜ê±°ë‚˜ ê°ì •ì˜ í‘œí˜„ ìˆ˜ë‹¨ìœ¼ë¡œ ì¥ë¯¸ë¥¼ ë§ì´ ì „ë‹¬í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë¹¨ê°„ ì¥ë¯¸ëŠ” ê·¸ ì•„ë¦„ë‹¤ì›€ë¿ë§Œ ì•„ë‹ˆë¼ ê·¸ ìƒ‰ì±„ì˜ íŠ¹ë³„í•¨ ì—­ì‹œ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤ . ë¶‰ì€ìƒ‰ì˜ ì¥ë¯¸ë¥¼ ì£¼ëŠ” ì‚¬ëŒì€ ì¼ë°˜ì ìœ¼ë¡œ ê°ì •ê³¼ ì‚¬ë‘ í˜¹ì€ ì—´ì •ì ì¸ í—Œì‹ ì„ ì „ë‹¬í•˜ëŠ” ì˜ë¯¸ë¡œ ì£¼ê³¤í•©ë‹ˆë‹¤.\n",
      "\n",
      "  \n",
      "\n",
      "**ë¬¸í•™ì  ê´€ì :**\n",
      "\n",
      "\"ìì•¼ë¥¼ ë¹—ëŠ” ì¥ë¯¸\"\n",
      "\n",
      "ì‚¬ë‘, ê°ì •, ê·¸ë¦¬ê³  ì˜ì›íˆ ì§€ì†ë˜ê³  ìˆœìˆ˜í•œ ì¡´ì¬ë¡œ ì•Œë ¤ì ¸ ìˆê³ , ìš°ì—° í•œ ë²ˆ ë§Œìœ¼ë¡œë„ ì˜ì›ì„ ë‚¨ê¸°ëŠ” ì—´ì •ì´ ìˆê¸°ì— ìš°ë¦¬ëŠ” ì‚¬ë‘ì˜ ì¥ë¯¸ë¥¼ ì†Œì¤‘íˆ ì—¬ê¹ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ë‘ê³¼ ì• ì •ì˜ ë³´ë­ê³¼ ì˜ì›ì˜ ì§€ì†ì´ ìˆëŠ” ê²ƒë§Œì„ ì „ë‹¬í•©ë‹ˆë‹¤. ì´ë ‡ë“¯ ë¹¨ê°„ ì¥ë¯¸ë¡œì„œ ìƒì§•í•˜ëŠ” ê°ì •ì€ ì˜ì›ì˜ ì§€ì†ê³¼ ë³€ì¹˜ì•ŠëŠ” ì—´ì •ë¶€ë¥¸ ì• ì •ì˜ ê²°í•€ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "\"ì˜ì›ì˜ ìˆœìˆ˜ì„±\"ì´ë€ ì¥ë¯¸ì˜ ë˜ ë‹¤ë¥¸ ì˜ë¯¸ì´ë‹¤.... ì‚¬ë‘ì€ ì˜ì›í•˜ë‹¤ëŠ” ë§ì´ ìˆê±°ë“ ìš” ì¥ì´ ê½ƒì²˜ëŸ¼ ìˆœìˆ˜í•œ\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ì„ ë‹´ì€ í…œí”Œë¦¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ í’ë¶€í•œ ë¹„ìœ ì™€ ì€ìœ ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œìˆ í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹µë³€ì˜ ê´€ì ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"),\n",
    "    (\"human\", \"\"\"\n",
    "    \"ë¹¨ê°„ ì¥ë¯¸\"ë¥¼ ë‘ ê°€ì§€ ê´€ì ì—ì„œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.\n",
    "    1. **ê°ê´€ì  ê´€ì :** ì¥ë¯¸ì˜ ë¬¼ë¦¬ì  íŠ¹ì„±ê³¼ ìƒì§•ì  ì˜ë¯¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "    2. **ë¬¸í•™ì  ê´€ì :** ì¥ë¯¸ë¥¼ ì‚¬ëŒì´ë‚˜ ê°ì •ì— ë¹—ëŒ€ì–´ ììœ ë¡­ê³  ì‹œì ìœ¼ë¡œ ë¬˜ì‚¬í•´ì£¼ì„¸ìš”.\n",
    "    \"\"\"),\n",
    "])\n",
    "\n",
    "# íŒŒì„œ ì„¤ì •\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±: Prompt -> Model -> Parser\n",
    "chain_conservative = prompt | llm_conservative | parser\n",
    "chain_creative = prompt | llm_creative | parser\n",
    "\n",
    "# ëª¨ë¸ í˜¸ì¶œ ë° ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 60)\n",
    "print(\" ë³´ìˆ˜ì  ì„¤ì • (ê°ê´€ì , ì‚¬ì‹¤ ê¸°ë°˜)\")\n",
    "print(\" â†’ ê³¼í•™ì ì´ê³  ë…¼ë¦¬ì ì¸ ì¥ë¯¸ì˜ íŠ¹ì„± ì„¤ëª…\")\n",
    "print(\"=\" * 60)\n",
    "response_conservative = chain_conservative.invoke({})\n",
    "print(response_conservative)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" ì°½ì˜ì  ì„¤ì • (ë¬¸í•™ì , ìƒìƒ ê¸°ë°˜)\")\n",
    "print(\" â†’ ì€ìœ ì™€ ë¹„ìœ ë¥¼ í™œìš©í•œ ì¥ë¯¸ì˜ ê°ì„±ì  ë¬˜ì‚¬\")\n",
    "print(\"=\" * 60)\n",
    "response_creative = chain_creative.invoke({})\n",
    "print(response_creative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelì˜ ì¢…ë¥˜ì— ë”°ë¼ ê²°ê³¼ ê°’ì´ ë‹¤ë¦„\n",
    "* gpt-4o vs gpt-3.5-turbo-0125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------\n",
      "\n",
      " After (ì°½ì˜ì ì¸ ì‘ë‹µ, ìƒˆë¡œìš´ ì•„ì´ë””ì–´ í¬í•¨)\n",
      "1.  **ê²½ì£¼** *   **ì†Œê°œ**: ê²½ì£¼ëŠ” ì‹ ë¼ ë¬¸í™”ì˜ ì‚´ì•„ìˆëŠ” ì—­ì‚¬ë¡œ ê°€ë“ ì°¬ ê³³ì…ë‹ˆë‹¤. ê²½ì£¼ ë¶ˆêµ­ì‚¬ëŠ” ì„¸ê³„ë¬¸í™”ìœ ì‚°ìœ¼ë¡œ ì§€ì •ëœ ìœ ë„¤ìŠ¤ì½”ì˜ ë¬¸í™”ìœ ì‚°ì´ë©°, ì‹ ë¼ì˜ ë¶ˆêµ ë¬¸í™”ì™€ ì˜ˆìˆ ì„ ëŒ€í‘œí•˜ëŠ” ê³µê°„ìœ¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì‹ ë¼ì˜ ì˜› ì™•ê¶ í„°ì¸ ê²½ì£¼ ëŒ€ë¦‰ì›, ì‹ ë¼ì˜ ë¶ˆêµ ì‚¬ì°°ì¸ ì²¨ì„±ëŒ€ ë“±ì„ ë°©ë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "2.  **ê°•ë¦‰** *   **ì†Œê°œ**: ê°•ë¦‰ì€ í•œêµ­ì˜ ë™í•´ë¥¼ ë‚¯ì„¤ê²Œ ë°”ë¼ë³´ëŠ” ë„ì‹œì…ë‹ˆë‹¤. ê°•ë¦‰ì˜ ì•„ë¦„ë‹¤ìš´ í•´ë³€ê°€, ë™í•´ë°”ë‹¤ë¡œ ì´ì–´ì§€ëŠ” ë“±ëŒ€ê¸¸, ê·¸ë¦¬ê³  ê°•ë¦‰ ì»¤í”¼ê±°ë¦¬ ë“±ì„ ë°©ë¬¸í•´ ë³´ì„¸ìš”. ê°•ë¦‰ ì»¤í”¼ê±°ë¦¬ì—ì„œëŠ” í˜„ì§€ ì»¤í”¼ë¥¼ ë§›ë³¼ ìˆ˜ ìˆëŠ” ì¹´í˜ë“¤ì´ ì¦ë¹„í•©ë‹ˆë‹¤. ì»¤í”¼í–¥ì´ ë¬¼ì”¬ í’ê¸°ëŠ” ê°•ë¦‰ì˜ ì»¤í”¼ê±°ë¦¬ë¥¼ ë°©ë¬¸í•˜ì—¬ ì»¤í”¼ì— ëŒ€í•œ ìƒˆë¡œìš´ ê²½í—˜ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "3.  **ë¶€ì‚°** *   **ì†Œê°œ**: ë¶€ì‚°ì€ í•œêµ­ì˜ ë‚¨ë™ë¶€ì— ìœ„ì¹˜í•œ í•­êµ¬ ë„ì‹œì…ë‹ˆë‹¤. ë¶€ì‚°ì—ëŠ” íƒœí‰ì–‘ì„ ë°”ë¼ë³´ëŠ” ë¶€ì‚°ê´‘ì¥, ë¶€ì‚°ì˜ ìœ ëª…í•œ ë°¤ ìƒí™œ ë¬¸í™”ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆëŠ” ê´‘ì•ˆë¦¬ í•´ìˆ˜ìš•ì¥, ê·¸ë¦¬ê³  ë¶€ì‚°ì˜ í•­êµ¬ ë„ì‹œ ë¬¸í™”ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆëŠ” ìê°ˆì¹˜ì‹œì¥ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì—¬í–‰ì§€ì˜ ì •ë³´ëŠ” ë³€ë™ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°©ë¬¸ ì „ì— ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ë³€ê²½ëœ ì„¤ì • (ë” ì°½ì˜ì ì¸ ë‹µë³€, ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ìœ ë„)\n",
    "#llm_after = ChatOpenAI(model=\"gpt-4o\", temperature=1.0, presence_penalty=1.5)\n",
    "#llm_after = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=1.0, presence_penalty=1.5)\n",
    "llm_after = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=1.0,\n",
    "    presence_penalty=1.5\n",
    ")\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì •\n",
    "question = \"í•œêµ­ì—ì„œ ê°€ë³¼ ë§Œí•œ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ëª¨ë¸ í˜¸ì¶œ\n",
    "response_after = llm_after.invoke(question)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n-------------------------\\n\")\n",
    "print(\" After (ì°½ì˜ì ì¸ ì‘ë‹µ, ìƒˆë¡œìš´ ì•„ì´ë””ì–´ í¬í•¨)\")\n",
    "print(response_after.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1) ëª¨ë¸ì— ì§ì ‘ íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬ (ëª¨ë¸ ìƒì„± ì‹œì )\n",
    "##### Before / After íŒŒë¼ë¯¸í„° ì°¨ì´\n",
    "* temperature: Before(0.7) â†’ ë‹¤ì–‘ì„± ë†’ì€ ì¶”ì²œ / After(0.3) â†’ ì •í™•í•œ ì¼ì • ì œê³µ\n",
    "* max_tokens: Before(300) â†’ ê°„ëµí•œ ì‘ë‹µ / After(800) â†’ ì„¸ë¶€ ì¼ì • í¬í•¨\n",
    "* frequency_penalty: Before(0.5) â†’ ë‹¨ì–´ ë°˜ë³µ ì–µì œ / After(0.2) â†’ ì¢€ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ\n",
    "* presence_penalty: Before(0.5) â†’ ë‹¤ì–‘í•œ ì¥ì†Œ ì¶”ì²œ / After(0.3) â†’ ìƒˆë¡œìš´ ì •ë³´ í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Before] ëª¨ë¸ ê²°ê³¼\n",
      "# ğŸŒ¸ 3ë°•4ì¼ ê°€ì¡± ì—¬ìœ ì—¬í–‰ (ëšœë²…ì´Â·íœ ì²´ì–´Â·ìœ ëª¨ì°¨ ALL OK, ìˆ™ì†Œâ†’ê´€ê´‘ì§€ 30ë¶„ ì´ë‚´)\n",
      "\n",
      "## ğŸ¯ ê¸°ë³¸ ì»¨ì…‰\n",
      "- ì•„ì¹¨ ëŠì§€ë§‰íˆ(09:30~10:00) ì¶œë°œ, ì˜¤í›„ 3~4ì‹œ í˜¸í…” ê·€í™˜ í›„ íœ´ì‹\n",
      "- ì–´ë¦°ì´Â·ì–´ë¥´ì‹  ëª¨ë‘ ê±¸ì„ ìˆ˜ ìˆëŠ” 'ì§§ì€ ì´ë™Â·ê¸´ ì²´ë¥˜' ì½”ìŠ¤\n",
      "- ëŒ€ì¤‘êµí†µ ì „ìš©(íƒì‹œ ìµœì†Œí™”), ë°°ê³ í”„ì§€ ì•Šê²Œ ì‹ë‹¹ ì˜ˆì•½ í¬í•¨\n",
      "\n",
      "---\n",
      "\n",
      "## ğŸ“… DAY 1 (ì„œìš¸: ê³ ê¶Â·ì¸ì‚¬ë™Â·ì²­ê³„ì²œ)\n",
      "**09:30**  ìˆ™ì†Œ(â€») ì¡°ì‹ & ì²´í¬ì•„ì›ƒ ê°€ë°©ë§Œ ë§¡ê²¨ë‘ê¸°  \n",
      "**10:00**  ê²½ë³µê¶(â€»)  \n",
      "â€ƒâ€ƒ- 10:30 ìˆ˜ë¬¸ì¥ êµëŒ€ì‹(ì›”ìš”ì¼ ì œì™¸) ë°”ë¡œ ë³´ê¸°  \n",
      "â€ƒâ€ƒ- í¥ë¡€ë¬¸â†’ê·¼ì •ì „â†’ê°•ë…•ì „â†’í–¥ì›ì • ìˆœ, 1.5ì‹œê°„ ì™„ë§Œ ì‚°ì±…\n",
      "\n",
      "================================================================================\n",
      "\n",
      " [After] ëª¨ë¸ ê²°ê³¼\n",
      "### **ì—¬í–‰ì§€ ì¶”ì²œ: ì„œìš¸ê³¼ ë¶€ì‚°**\n",
      "\n",
      "*   **ì—¬í–‰ ê¸°ê°„:** 3ë°• 4ì¼\n",
      "*   **ì—¬í–‰ì§€:** ì„œìš¸ê³¼ ë¶€ì‚°\n",
      "\n",
      "### **ì—¬í–‰ ì¼ì •**\n",
      "\n",
      "*   **1ì¼ì°¨: ì„œìš¸**\n",
      "*   **ì˜¤ì „: ì„œìš¸ ë„ì°© ë° ê²½ë³µê¶ ë°©ë¬¸** *   ì„œìš¸ì— ë„ì°©í•˜ì—¬ í˜¸í…”ì— ì²´í¬ì¸í•©ë‹ˆë‹¤. *   ê²½ë³µê¶ìœ¼ë¡œ ì´ë™í•˜ì—¬ ê¶ê¶ì„ íƒë°©í•©ë‹ˆë‹¤. *   ê²½ë³µê¶ì€ í•œêµ­ì˜ ëŒ€í‘œì ì¸ ê¶ê¶ë¡œ, ì—­ì‚¬ì™€ ë¬¸í™”ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ ì¥ì†Œì…ë‹ˆë‹¤.\n",
      "*   **ì˜¤í›„: ë¶ì´Œ í•œì˜¥ë§ˆì„ ë°©ë¬¸** *   ë¶ì´Œ í•œì˜¥ë§ˆì„ë¡œ ì´ë™í•˜ì—¬ ì „í†µ í•œì˜¥ì„ ê°ìƒí•©ë‹ˆë‹¤. *   ë¶ì´Œ í•œì˜¥ë§ˆì„ì€ í•œêµ­ì˜ ì „í†µì ì¸ ì£¼ê±° ë¬¸í™”ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆëŠ” ê³³ì…ë‹ˆë‹¤.\n",
      "*   **ì €ë…: ì„œìš¸ì˜ ë§›ìˆëŠ” ì €ë… ì‹ì‚¬** *   ì„œìš¸ì˜ ìœ ëª…í•œ ë§›ì§‘ì—ì„œ ì €ë… ì‹ì‚¬ë¥¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "*   **2ì¼ì°¨: ì„œìš¸**\n",
      "\n",
      "*   **ì˜¤ì „: êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ ë°©ë¬¸** *   êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ìœ¼ë¡œ ì´ë™í•˜ì—¬ í•œêµ­ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ë¥¼ ë°°ì›ë‹ˆë‹¤. *   êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ì€ í•œêµ­ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ë¥¼ ì´í•´í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ ì¥ì†Œì…ë‹ˆë‹¤.\n",
      "*   **ì˜¤í›„: ì„œìš¸ì˜ ì‡¼í•‘** *   ì„œìš¸ì˜ ìœ ëª…í•œ ì‡¼í•‘ëª°ì´ë‚˜ ì‹œì¥ìœ¼ë¡œ ì´ë™í•˜ì—¬ ì‡¼í•‘ì„ ì¦ê¹ë‹ˆë‹¤. *   ì„œìš¸ì€ í•œêµ­ì˜ íŒ¨ì…˜ê³¼ ë·°í‹°ì˜ ì¤‘ì‹¬ì§€ë¡œ, ë‹¤ì–‘í•œ ì‡¼í•‘ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "*   **3ì¼ì°¨: ë¶€ì‚°**\n",
      "\n",
      "*   **ì˜¤ì „: ë¶€ì‚°ìœ¼ë¡œ ì´ë™** *   ë¶€ì‚°ìœ¼ë¡œ ì´ë™í•˜ì—¬ í˜¸í…”ì— ì²´í¬ì¸í•©ë‹ˆë‹¤. *   ë¶€ì‚°ì€ í•œêµ­ì˜ ëŒ€í‘œì ì¸ í•­êµ¬ ë„ì‹œë¡œ, ì•„ë¦„ë‹¤ìš´ ë°”ë‹¤ì™€ í•´ë³€ì„ ìë‘í•©ë‹ˆë‹¤.\n",
      "*   **ì˜¤í›„: ë¶€ì‚°ì˜ í•´ë³€ ë°©ë¬¸** *   ë¶€ì‚°ì˜ ìœ ëª…í•œ í•´ë³€ìœ¼ë¡œ ì´ë™í•˜ì—¬ ë°”ë‹¤ë¥¼ ê°ìƒí•©ë‹ˆë‹¤. *   ë¶€ì‚°ì˜ í•´ë³€ì€ í•œêµ­ì˜ ëŒ€í‘œì ì¸ ê´€ê´‘ì§€ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "*   **4ì¼ì°¨: ë¶€ì‚°**\n",
      "\n",
      "*   **ì˜¤ì „: ë¶€ì‚°ì˜ ê´€ê´‘ì§€ ë°©ë¬¸** *   ë¶€ì‚°ì˜ ìœ ëª…í•œ ê´€ê´‘ì§€ë¡œ ì´ë™í•˜ì—¬ ê´€ê´‘ì„ ì¦ê¹ë‹ˆë‹¤. *   ë¶€ì‚°ì—ëŠ” ë‹¤ì–‘í•œ ê´€ê´‘ì§€ê°€ ìˆìœ¼ë©°, ê°€ì¡±ê³¼ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê³³ì…ë‹ˆë‹¤.\n",
      "\n",
      "### **ì—¬í–‰ íŒ**\n",
      "\n",
      "*   **êµí†µ:** ì„œìš¸ê³¼ ë¶€ì‚°ì€ ëŒ€ì¤‘êµí†µì´ ì˜ ë°œë‹¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ëŒ€ì¤‘êµí†µì„ ì´ìš©í•˜ì—¬ ì´ë™í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "*   **ì‹ì‚¬:** ì„œìš¸ê³¼ ë¶€ì‚°ì—ëŠ” ë‹¤ì–‘í•œ ë§›ì§‘ì´ ìˆìœ¼ë¯€ë¡œ, í˜„ì§€ ìŒì‹ì„ ì¦ê¸°ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "*   **ìˆ™ë°•:** ì„œìš¸ê³¼ ë¶€ì‚°ì—ëŠ” ë‹¤ì–‘í•œ í˜¸í…”ê³¼ ìˆ™ë°• ì‹œì„¤ì´ ìˆìœ¼ë¯€ë¡œ, ê°€ì¡±ì˜ ì˜ˆì‚°ê³¼ ì„ í˜¸ë„ì— ë§ëŠ” ê³³ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "#  ëª¨ë¸ íŒŒë¼ë¯¸í„° (Before: ê¸°ë³¸ì ì¸ ì¶”ì²œ / After: ë§ì¶¤í˜• ì„¸ë¶€ ì •ë³´ ì¶”ê°€)\n",
    "before_params = {\n",
    "    \"temperature\": 0.7,         # ëœë¤ì„±ì„ ì ì ˆíˆ ìœ ì§€ (ë‹¤ì–‘í•œ ë‹µë³€ ìœ ë„)\n",
    "    \"max_tokens\": 300,          # ì‘ë‹µ ê¸¸ì´ë¥¼ ì ì ˆíˆ ì¡°ì ˆ\n",
    "    \"frequency_penalty\": 0.5,   # ë°˜ë³µ ë‹¨ì–´ ì–µì œ\n",
    "    \"presence_penalty\": 0.5,    # ìƒˆë¡œìš´ ë‹¨ì–´ í¬í•¨ ì¥ë ¤\n",
    "}\n",
    "\n",
    "after_params = {\n",
    "    \"temperature\": 0.3,         # ì°½ì˜ì„±ì„ ë‚®ì¶”ê³  ì •í™•í•œ ë‹µë³€ ìœ ë„\n",
    "    \"max_tokens\": 800,          # ë” ê¸´ ë‹µë³€ì„ ìƒì„± (ì„¸ë¶€ ì •ë³´ í¬í•¨)\n",
    "    \"top_p\": 0.85,              # í™•ë¥  ê¸°ë°˜ ìƒ˜í”Œë§ (ì¼ê´€ì„±ê³¼ ë‹¤ì–‘ì„± ê· í˜•)\n",
    "    \"frequency_penalty\": 0.2,   # ë°˜ë³µ ë‹¨ì–´ ê°ì†Œ (ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€)\n",
    "    \"presence_penalty\": 0.3,    # ìƒˆë¡œìš´ ì •ë³´ í¬í•¨ ì¥ë ¤\n",
    "}\n",
    "\n",
    "#  ë‘ ê°œì˜ ëª¨ë¸ ìƒì„± (Before / After)\n",
    "#before_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **before_params)\n",
    "before_model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    **before_params\n",
    ")\n",
    "#after_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **after_params)\n",
    "after_model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    **after_params\n",
    ")\n",
    "\n",
    "#  í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì˜¬ë°”ë¥¸ ChatMessagePromptTemplate ì‚¬ìš©)\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"ë‹¹ì‹ ì€ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” ìµœì ì˜ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "user_message = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])\n",
    "\n",
    "#  ì²´ì¸ ìƒì„± (Before / After)\n",
    "before_chain = chat_prompt | before_model\n",
    "after_chain = chat_prompt | after_model\n",
    "\n",
    "#  ì§ˆë¬¸ ì„¤ì • (Before / Afterì˜ ì°¨ì´ì ì„ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ë³€ê²½)\n",
    "test_question = \"ê°€ì¡±ê³¼ í•¨ê»˜ 3ë°• 4ì¼ ë™ì•ˆ í•œêµ­ì—ì„œ ì—¬ìœ ë¡­ê²Œ ì—¬í–‰í•  ìˆ˜ ìˆëŠ” ì¼ì •ì„ ë™ì„ ì„ ê³ ë ¤í•˜ì—¬ ìì„¸í•˜ê²Œ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "#  Before ëª¨ë¸ ì‹¤í–‰\n",
    "before_response = before_chain.invoke({\"user_input\": test_question})\n",
    "\n",
    "#  After ëª¨ë¸ ì‹¤í–‰\n",
    "after_response = after_chain.invoke({\"user_input\": test_question})\n",
    "\n",
    "#  ê²°ê³¼ ì¶œë ¥\n",
    "print(\" [Before] ëª¨ë¸ ê²°ê³¼\")\n",
    "print(before_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")  # ê°€ë…ì„±ì„ ìœ„í•œ êµ¬ë¶„ì„ \n",
    "print(\" [After] ëª¨ë¸ ê²°ê³¼\")\n",
    "print(after_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2) ëª¨ë¸ì— ì¶”ê°€ì ì¸ íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬\n",
    "- bind() ë©”ì„œë“œë¥¼ ì‚¬ìš©\n",
    "- max_tokens=50 (ê¸°ë³¸) / max_tokens=150 (ìƒì„¸í•œ ì„¤ëª…) \n",
    "- stop=[\".\"] â†’ ì²« ë²ˆì§¸ ë§ˆì¹¨í‘œì—ì„œ ì‘ë‹µì„ ì¤‘ë‹¨\n",
    "- temperature=0.8 â†’ ë³´ë‹¤ ì°½ì˜ì ì¸ ë‹µë³€ì„ ìƒì„±í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Before] ê¸°ë³¸ max_tokens=150 (ê¸°ë³¸ ë‹µë³€)\n",
      "Python í”„ë¡œê·¸ë˜ë°ì€ ì´ˆë³´ìì—ê²Œ ë§¤ë ¥ì ì¸ ì‹œì‘ì ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Pythonì˜ ê°„ë‹¨í•œ ë¬¸ë²•ê³¼ ë‹¤ì±„ë¡œìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” í”„ë¡œê·¸ë˜ë°ì˜ ê¸°ì´ˆë¥¼ ìŒ“ëŠ”ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "\n",
      "### 1. ê¸°ì´ˆ ë¬¸ë²• ìµíˆê¸°\n",
      "\n",
      "- **ë°©ë²•**: Pythonì˜ ê¸°ë³¸ ë¬¸ë²•ì„ ë°°ìš°ëŠ” ê²ƒë¶€í„° ì‹œì‘í•˜ì„¸ìš”. ë³€ìˆ˜ ì„ ì–¸, ë°ì´í„° íƒ€ì…, ì¡°ê±´ë¬¸, ë£¨í”„, í•¨ìˆ˜ ë“±ì„ í¬í•¨í•œ ê¸°ì´ˆ ë¬¸ë²•ì„ ìµí™ë‹ˆë‹¤.\n",
      "- **íŒ**: ì˜¨ë¼ì¸ íŠœí† ë¦¬ì–¼ì´ë‚˜ Python ê³µì‹ ë¬¸ì„œì˜ [íŠœí† ë¦¬ì–¼](https://docs.python.org/ko/3/tutorial/index.html)ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n",
      "\n",
      "### 2. ì‹¤ìŠµ í”„ë¡œì íŠ¸ ì§„í–‰\n",
      "\n",
      "- **ë°©ë²•**:\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " [After] max_tokens=150, stop=['.'] (ì²« ë²ˆì§¸ ë§ˆì¹¨í‘œì—ì„œ ì‘ë‹µ ì¤‘ë‹¨)\n",
      "### Python í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ëŠ” ì´ˆë³´ìì—ê²Œ ì¶”ì²œí•˜ëŠ” í•™ìŠµ ë‹¨ê³„\n",
      "\n",
      "Python í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ëŠ” ì´ˆê¸° ë‹¨ê³„ëŠ” ê¸°ì´ˆë¥¼ ë‹¤ì§€ê³ , í”„ë¡œê·¸ë˜ë°ì˜ ê¸°ë³¸ ê°œë…ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " [After] max_tokens=150, temperature=0.8 (ì°½ì˜ì ì¸ ë‹µë³€)\n",
      "Python í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ëŠ” ì´ˆë³´ìì—ê²Œ ì¶”ì²œí•˜ëŠ” í•™ìŠµ ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 1. Python ê¸°ë³¸ ë¬¸ë²• í•™ìŠµ\n",
      "\n",
      "*   **í•™ìŠµ ëª©í‘œ**: Pythonì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ë°ì´í„° íƒ€ì…ì„ ì´í•´í•©ë‹ˆë‹¤.\n",
      "*   **ë°©ë²•**: \n",
      "    *   ì˜¨ë¼ì¸ ê°•ì˜: Codecademy, Coursera, edX ë“±ì˜ ì›¹ì‚¬ì´íŠ¸ì—ì„œ Python ê¸°ì´ˆ ê°•ì˜ë¥¼ ìˆ˜ê°•í•©ë‹ˆë‹¤.\n",
      "    *   êµì¬: \"Python Crash Course\" ë˜ëŠ” \"Python for Everybody\"ì™€ ê°™ì€ ì…ë¬¸ìš© ì±…ì„ ì½ìŠµë‹ˆë‹¤.\n",
      "    *   ê³µì‹ ë¬¸ì„œ: Python ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì˜ íŠœí† ë¦¬ì–¼ì„ ì°¸ì¡°í•©ë‹ˆë‹¤.\n",
      "*   **êµ¬ì²´ì ì¸ ë°©ë²•**:\n",
      "    *   ë³€ìˆ˜, ë°ì´í„° íƒ€ì…(ìˆ«ì, ë¬¸ìì—´, ë¦¬ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#  í”„ë¡¬í”„íŠ¸ ì„¤ì • (ì²œë¬¸í•™ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œ)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ì´ ì‹œìŠ¤í…œì€ ì²œë¬¸í•™ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ìì„¸í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "#  ê¸°ë³¸ ëª¨ë¸ ì„¤ì • (ê¸°ë³¸ì ì¸ ë‹µë³€ ìƒì„±)\n",
    "#base_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=150)  # 150 í† í° ì œí•œ\n",
    "base_model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "#  ì§ˆë¬¸ ì„¤ì •\n",
    "# 1. MAX_TOKENS ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§ˆë¬¸ (ê¸¸ì´ ì œí•œ íš¨ê³¼)\n",
    "max_tokens_question = \"ì¸ê³µì§€ëŠ¥ì˜ ë°œì „ì´ ë¯¸ë˜ ì‚¬íšŒì— ë¯¸ì¹  ì˜í–¥ì„ ê¸ì •ì  ì¸¡ë©´ê³¼ ë¶€ì •ì  ì¸¡ë©´ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# 2. STOP íŒŒë¼ë¯¸í„° ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§ˆë¬¸ (ì¤‘ë‹¨ì  íš¨ê³¼)\n",
    "stop_question = \"Python í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ëŠ” ì´ˆë³´ìì—ê²Œ ì¶”ì²œí•˜ëŠ” í•™ìŠµ ë‹¨ê³„ë¥¼ ìˆœì„œëŒ€ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. ê° ë‹¨ê³„ë³„ë¡œ êµ¬ì²´ì ì¸ ë°©ë²•ê³¼ íŒì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# 3. TEMPERATURE ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§ˆë¬¸ (ì°½ì˜ì„± vs ì •í™•ì„±)\n",
    "temperature_question = \"ì‹œê°„ ì—¬í–‰ì´ ê°€ëŠ¥í•˜ë‹¤ë©´ ê³¼ê±°ì˜ ì–´ëŠ ì‹œëŒ€ë¡œ ê°€ê³  ì‹¶ì€ì§€ì™€ ê·¸ ì´ìœ ë¥¼ ì°½ì˜ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# 4. ë³µí•©ì  ë¹„êµë¥¼ ìœ„í•œ ì§ˆë¬¸ (ëª¨ë“  íŒŒë¼ë¯¸í„° íš¨ê³¼)\n",
    "complex_question = \"í™”ì„±ì— ì¸ë¥˜ê°€ ì •ì°©í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê¸°ìˆ ê³¼ ì¤€ë¹„ì‚¬í•­ë“¤ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ê³ , ê° ë‹¨ê³„ì—ì„œ ì˜ˆìƒë˜ëŠ” ë„ì „ê³¼ì œì™€ í•´ê²°ë°©ì•ˆì„ ì œì‹œí•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "question = stop_question\n",
    "\n",
    "#  Before (ê¸°ë³¸ max_tokens=150)\n",
    "messages = prompt.format_messages(user_input=question)\n",
    "before_answer = base_model.invoke(messages)\n",
    "\n",
    "#  Before ì¶œë ¥\n",
    "print(\"\\n [Before] ê¸°ë³¸ max_tokens=150 (ê¸°ë³¸ ë‹µë³€)\")\n",
    "print(before_answer.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")  # ê°€ë…ì„±ì„ ìœ„í•œ êµ¬ë¶„ì„ \n",
    "\n",
    "#  After (íŒŒë¼ë¯¸í„° ì¡°ì • í›„ ë¹„êµ)\n",
    "stop_chain = prompt | base_model.bind(max_tokens=150, stop=[\".\"])  # ì²« ë²ˆì§¸ ë§ˆì¹¨í‘œì—ì„œ ì¤‘ë‹¨\n",
    "temp_chain = prompt | base_model.bind(max_tokens=150, temperature=0.8)  # ì°½ì˜ì ì¸ ë‹µë³€ ìœ ë„\n",
    "\n",
    "stop_answer = stop_chain.invoke({\"user_input\": question})\n",
    "temp_answer = temp_chain.invoke({\"user_input\": question})\n",
    "\n",
    "#  After ì¶œë ¥ (stop vs temperature ë¹„êµ)\n",
    "print(\" [After] max_tokens=150, stop=['.'] (ì²« ë²ˆì§¸ ë§ˆì¹¨í‘œì—ì„œ ì‘ë‹µ ì¤‘ë‹¨)\")\n",
    "print(stop_answer.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")  # ê°€ë…ì„±ì„ ìœ„í•œ êµ¬ë¶„ì„ \n",
    "\n",
    "print(\" [After] max_tokens=150, temperature=0.8 (ì°½ì˜ì ì¸ ë‹µë³€)\")\n",
    "print(temp_answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
