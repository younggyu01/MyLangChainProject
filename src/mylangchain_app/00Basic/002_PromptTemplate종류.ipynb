{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate ì˜ from_template() í•¨ìˆ˜ ì‚¬ìš©\n",
    "* ì£¼ë¡œ LLM(í…ìŠ¤íŠ¸ ì™„ì„±í˜• ëª¨ë¸, ex. Ollama, GPT-3.5)ê³¼ í•¨ê»˜ ì‚¬ìš©\n",
    "* í•˜ë‚˜ì˜ ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPTëŠ” ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•´ ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ì‚¬ì „í•™ìŠµ(preâ€‘training)ëœ '\n",
      " 'íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) ëª¨ë¸ì…ë‹ˆë‹¤. ì‚¬ì „í•™ìŠµ í›„ì—ëŠ” ì¸ê°„ í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ ë³´ìƒ ëª¨ë¸ì„ ë§Œë“¤ê³ , ì´ë¥¼ í†µí•´ ì •ì±…ì„ ìµœì í™”í•˜ëŠ” '\n",
      " 'ê°•í™”í•™ìŠµ(RLHF) ê³¼ì •ì„ ê±°ì³ ëŒ€í™”ì— ì í•©í•˜ë„ë¡ ë¯¸ì„¸ì¡°ì •ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•™ìŠµëœ íŒŒë¼ë¯¸í„°ë“¤ì€ ì…ë ¥ ë¬¸ë§¥ì„ ê³ ë ¤í•´ ê°€ì¥ ìì—°ìŠ¤ëŸ½ê³  ì˜ë¯¸ '\n",
      " 'ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ì‘ë™í•©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"openai/gpt-oss-120b\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate ê²°í•©í•˜ê¸°\n",
    "* ë™ì¼í•œ Prompt íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°œì˜ ì§ˆë¬¸ì„ ì‘ì„±í•´ì„œ LLMì„ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.'\n",
      "('**ChatGPT ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ (3ë¬¸ì¥)**  \\n'\n",
      " '1. ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ **ìê¸° ì§€ë„ í•™ìŠµ**(selfâ€‘supervised learning) ë°©ì‹ìœ¼ë¡œ ì‚¬ì „ '\n",
      " 'í•™ìŠµ(preâ€‘training)í•œë‹¤.  \\n'\n",
      " '2. ì‚¬ì „ í•™ìŠµ ë‹¨ê³„ì—ì„œ ëª¨ë¸ì€ ë¬¸ë§¥ì„ ì˜ˆì¸¡í•˜ë„ë¡ í† í°ì„ ë§ˆìŠ¤í‚¹í•˜ê±°ë‚˜ ë‹¤ìŒ í† í°ì„ ë§ì¶”ëŠ” ê³¼ì œë¥¼ ìˆ˜í–‰í•´ ì–¸ì–´ íŒ¨í„´ê³¼ ì˜ë¯¸ ê´€ê³„ë¥¼ '\n",
      " 'í•™ìŠµí•œë‹¤.  \\n'\n",
      " '3. ì´í›„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ **ì§€ë„ í•™ìŠµ**(fineâ€‘tuning)ì´ë‚˜ ê°•í™” í•™ìŠµ(RLHF) ë“±ì„ í†µí•´ ì‚¬ìš©ì ì˜ë„ì— ë¶€í•©í•˜ë„ë¡ ë¯¸ì„¸ '\n",
      " 'ì¡°ì •í•œë‹¤.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT ëª¨ë¸ì˜ ì¥ì  ìš”ì•½  \\n'\n",
      " '\\n'\n",
      " '- **ë‹¤ì–‘í•œ ì£¼ì œì™€ ì–¸ì–´ì— ëŒ€í•œ ë†’ì€ ì´í•´ë„**: ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ì™€ ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„°ë¥¼ í•™ìŠµí•´ í­ë„“ì€ ì§€ì‹ê³¼ ë¬¸ë§¥ íŒŒì•… ëŠ¥ë ¥ì„ '\n",
      " 'ê°–ì¶¤.  \\n'\n",
      " '- **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„**: ë¬¸ë§¥ì„ ìœ ì§€í•˜ë©´ì„œ ì¼ê´€ëœ ë‹µë³€ì„ ìƒì„±í•˜ê³ , ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•´ ì ì ˆí•œ ìˆ˜ì¤€ê³¼ í†¤ìœ¼ë¡œ ì‘ë‹µí•¨.  \\n'\n",
      " '- **í™•ì¥ì„±ê³¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • ë¶„ì•¼ì— ë§ê²Œ íŒŒì¸íŠœë‹í•˜ê±°ë‚˜, í”ŒëŸ¬ê·¸ì¸Â·APIë¥¼ í†µí•´ ë‹¤ì–‘í•œ '\n",
      " 'ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì‰½ê²Œ í†µí•© ê°€ëŠ¥.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPTì™€ ë¹„ìŠ·í•œ AI ëª¨ë¸ (ì˜ì–´ ëª¨ë¸ëª…)\\n'\n",
      " '\\n'\n",
      " '- **GPTâ€‘4** (OpenAI)  \\n'\n",
      " '- **Claude** (Anthropic)  \\n'\n",
      " '- **Llama 2** (Meta)  \\n'\n",
      " '- **Gemma** (Google DeepMind)  \\n'\n",
      " '- **Mistral** (Mistral AI)  \\n'\n",
      " '- **Phiâ€‘2** (Microsoft)  \\n'\n",
      " '- **BLOOM** (BigScience)  \\n'\n",
      " '- **Jasper** (Cohere)  \\n'\n",
      " '\\n'\n",
      " 'ì´ ëª¨ë¸ë“¤ì€ ëª¨ë‘ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ë©°, ì‚¬ì „ í•™ìŠµ í›„ íŒŒì¸íŠœë‹ì´ë‚˜ RLHF ë“±ìœ¼ë¡œ ëŒ€í™”í˜• AI í˜¹ì€ ë‹¤ì–‘í•œ ìì—°ì–´ '\n",
      " 'ì²˜ë¦¬ ì‘ì—…ì— í™œìš©ë©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# ë¬¸ìì—´ í…œí”Œë¦¿ ê²°í•© (PromptTemplate + PromptTemplate + ë¬¸ìì—´)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\")\n",
    "              + \"\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"ì˜ì–´\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"ì˜ì–´\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë°°ì—´ í˜•íƒœë¡œ í•˜ì—¬ ì—¬ëŸ¬ê°œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Anima ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Figma ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.']\n",
      "<class 'str'> GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('GPTâ€‘4ëŠ” ë°©ëŒ€í•œ ì¸í„°ë„· í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´, ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ëŠ” **ìê¸°ì§€ë„(preâ€‘training)** '\n",
      " 'ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´í›„ ì¸ê°„ì´ ë§Œë“  ì§ˆë¬¸â€‘ë‹µë³€ ìŒì´ë‚˜ í”¼ë“œë°±ì„ ì´ìš©í•´ ëª¨ë¸ì˜ ì¶œë ¥ì„ ì¡°ì •í•˜ëŠ” **ì§€ë„í•™ìŠµ(fineâ€‘tuning)** ë° '\n",
      " 'ì¸ê°„ í”¼ë“œë°±ì„ ë°˜ì˜í•´ ë³´ìƒì„ ìµœì í™”í•˜ëŠ” **ê°•í™”í•™ìŠµ(RLHF)** ì„ ì ìš©í•´ ì‹¤ì œ ì‚¬ìš© ìƒí™©ì— ë§ëŠ” ì‘ë‹µ í’ˆì§ˆì„ ë†’ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ ë‘ '\n",
      " 'ë‹¨ê³„ì˜ í•™ìŠµì„ ë°˜ë³µí•˜ë©´ì„œ ëª¨ë¸ì€ ì–¸ì–´ êµ¬ì¡°ì™€ ì˜ë¯¸ë¥¼ ì¼ë°˜í™”í•˜ê³ , ë‹¤ì–‘í•œ ê³¼ì—…ì— ì ìš© ê°€ëŠ¥í•œ ë²”ìš© ì¸ê³µì§€ëŠ¥ìœ¼ë¡œ ë°œì „í•©ë‹ˆë‹¤.')\n",
      "<class 'str'> Anima ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('Anima ëª¨ë¸ì€ ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ì „ í•™ìŠµ(preâ€‘training)í•˜ì—¬ ì–¸ì–´ì˜ í†µê³„ì  íŒ¨í„´ê³¼ ì˜ë¯¸ ê´€ê³„ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.  \\n'\n",
      " 'ê·¸ í›„, íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ë¼ë²¨ì´ ë¶€ì°©ëœ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ ì§€ë„ í•™ìŠµ(supervised fineâ€‘tuning)ì´ë‚˜ ì¸ê°„ í”¼ë“œë°±ì„ ë°˜ì˜í•œ '\n",
      " 'ê°•í™” í•™ìŠµ(RLHF)ìœ¼ë¡œ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œëŠ” ì†ì‹¤ í•¨ìˆ˜(loss function)ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ì—­ì „íŒŒ(backpropagation)í•˜ê³ , ì˜µí‹°ë§ˆì´ì €ê°€ '\n",
      " 'íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.  \\n'\n",
      " 'ì´ëŸ¬í•œ ë‹¨ê³„ë“¤ì„ ë°˜ë³µí•˜ë©´ì„œ ëª¨ë¸ì€ ì ì°¨ ë” ì •í™•í•˜ê³  ì¼ê´€ëœ ì–¸ì–´ ì´í•´Â·ìƒì„± ëŠ¥ë ¥ì„ ê°–ì¶”ê²Œ ë©ë‹ˆë‹¤.')\n",
      "<class 'str'> Figma ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('Figma ëª¨ë¸ì€ ëŒ€ëŸ‰ì˜ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ë°ì´í„° ìŒì„ ì´ìš©í•´ ì‚¬ì „ í•™ìŠµë©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ í•´ë‹¹ ì„¤ëª…ì— ë§ëŠ” ì‹œê°ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ë„ë¡ ì´ë¯¸ì§€ ì¸ì½”ë”ì™€ í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ ë™ì‹œì— '\n",
      " 'ìµœì í™”í•©ë‹ˆë‹¤.  \\n'\n",
      " 'ê·¸ í›„, í™•ì‚° ëª¨ë¸(denoising diffusion model)ì„ ì‚¬ìš©í•´ ë…¸ì´ì¦ˆê°€ ì„ì¸ ì´ˆê¸° ì´ë¯¸ì§€ì—ì„œ ì ì§„ì ìœ¼ë¡œ ë””ë…¸ì´ì§•í•˜ë©´ì„œ '\n",
      " 'ì›í•˜ëŠ” ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.  \\n'\n",
      " 'ìµœì¢…ì ìœ¼ë¡œ, ì‚¬ìš©ìì˜ í”„ë¡¬í”„íŠ¸ì™€ ì¼ì¹˜í•˜ëŠ” ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë„ë¡ ë°˜ë³µì ì¸ ì—­ì „íŒŒì™€ ìƒ˜í”Œë§ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Anima\", \"count\": 4},\n",
    "    {\"model_name\": \"Figma\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # ë¯¸ë¦¬ ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ í™•ì¸\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple í˜•íƒœì˜ system, user, assistant ë©”ì‹œì§€ ì§€ì›\n",
    "* ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ë¥¼ ì¡°í•©í•˜ì—¬ LLMì—ê²Œ ì „ë‹¬ ê°€ëŠ¥\n",
    "* ê°„ê²°ì„±ê³¼ ê°€ë…ì„±ì´ ë†’ê³  ë‹¨ìˆœí•œ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## ChatGPT ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬  \n",
      "(í•œêµ­ì–´ë¡œ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤)\n",
      "\n",
      "---\n",
      "\n",
      "### 1. ì „ì²´ íë¦„\n",
      "\n",
      "ChatGPTì™€ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ í¬ê²Œ **ì„¸ ë‹¨ê³„**ë¡œ í•™ìŠµë©ë‹ˆë‹¤.\n",
      "\n",
      "| ë‹¨ê³„ | ëª©ì  | ì£¼ìš” ë°©ë²• |\n",
      "|------|------|-----------|\n",
      "| **â‘  ì‚¬ì „í•™ìŠµ (Preâ€‘training)** | ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í†µí•´ **ì–¸ì–´ì˜ ì¼ë°˜ì ì¸ íŒ¨í„´**ì„ ìŠµë“ | ìê¸°ì§€ë„ í•™ìŠµ (selfâ€‘supervised), í† í° ì˜ˆì¸¡ (nextâ€‘token prediction) |\n",
      "| **â‘¡ ì§€ë„í•™ìŠµ (Supervised Fineâ€‘tuning, SFT)** | ëª¨ë¸ì„ **ëŒ€í™”í˜•** í˜¹ì€ **íŠ¹ì • íƒœìŠ¤í¬**ì— ë§ê²Œ ì¡°ì • | ì¸ê°„ì´ ë§Œë“  ì§ˆë¬¸â€‘ë‹µë³€ ìŒì„ ì´ìš©í•´ ì§€ë„í•™ìŠµ |\n",
      "| **â‘¢ ì¸ê°„ í”¼ë“œë°± ê¸°ë°˜ ê°•í™”í•™ìŠµ (RLHF)** | ëª¨ë¸ì´ **ì‚¬ìš©ì ì˜ë„**ì— ë§ëŠ”, **ì¹œì ˆí•˜ê³  ì•ˆì „í•œ** ì¶œë ¥ì„ ìƒì„±í•˜ë„ë¡ ìµœì í™” | ì¸ê°„ í‰ê°€ìÂ·ì‹œìŠ¤í…œì´ ë§Œë“  ë³´ìƒ ëª¨ë¸ì„ ì´ìš©í•´ ê°•í™”í•™ìŠµ ìˆ˜í–‰ |\n",
      "\n",
      "ê° ë‹¨ê³„ëŠ” ì• ë‹¨ê³„ì—ì„œ ì–»ì€ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì ì§„ì ìœ¼ë¡œ íŠ¹í™”ë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. ì‚¬ì „í•™ìŠµ (Preâ€‘training)\n",
      "\n",
      "#### 2.1 ë°ì´í„°\n",
      "- **ê·œëª¨**: ìˆ˜ì¡°(token) ìˆ˜ì¤€, ì›¹ í˜ì´ì§€, ì±…, ë…¼ë¬¸, ìœ„í‚¤í”¼ë””ì•„, í¬ëŸ¼, ì½”ë“œ ì €ì¥ì†Œ ë“± ë‹¤ì–‘í•œ ì¶œì²˜\n",
      "- **ì „ì²˜ë¦¬**:  \n",
      "  - **í† í¬ë‚˜ì´ì§•** â†’ í…ìŠ¤íŠ¸ë¥¼ **í† í°**(ë³´í†µ ì„œë¸Œì›Œë“œ) ë‹¨ìœ„ë¡œ ë³€í™˜  \n",
      "  - **ì •ì œ**: ì €ì‘ê¶Œ ë¬¸ì œ, ê°œì¸ ì •ë³´, ëª…ì‹œì  ë¶ˆë²•Â·í­ë ¥Â·í˜ì˜¤ ì½˜í…ì¸  ì œê±°  \n",
      "  - **ìƒ˜í”Œë§**: ë°ì´í„° í¸í–¥ì„ ì™„í™”í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë„ë©”ì¸Â·ì–¸ì–´ ë¹„ìœ¨ì„ ì¡°ì •\n",
      "\n",
      "#### 2.2 ëª¨ë¸ ì•„í‚¤í…ì²˜\n",
      "- **Transformer** (Vaswani et al., 2017) ê¸°ë°˜ì˜ **ë””ì½”ë”**ë§Œ ì‚¬ìš© (GPT ì‹œë¦¬ì¦ˆ)\n",
      "- í•µì‹¬ êµ¬ì„± ìš”ì†Œ  \n",
      "  - **ë©€í‹°â€‘í—¤ë“œ ì…€í”„â€‘ì–´í…ì…˜**: ê° í† í°ì´ ë¬¸ë§¥ ì „ì²´ì™€ ì–´ë–»ê²Œ ì—°ê´€ë˜ëŠ”ì§€ í•™ìŠµ  \n",
      "  - **í”¼ë“œâ€‘í¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ (FFN)**: ë¹„ì„ í˜• ë³€í™˜ìœ¼ë¡œ í‘œí˜„ë ¥ ê°•í™”  \n",
      "  - **ì”ì°¨ ì—°ê²° + ë ˆì´ì–´ ì •ê·œí™”**: í•™ìŠµ ì•ˆì •ì„± ë° ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ í•¨  \n",
      "- **ìŠ¤ì¼€ì¼ë§**: íŒŒë¼ë¯¸í„° ìˆ˜(ìˆ˜ì–µ~ìˆ˜ì²œì–µ), ë ˆì´ì–´ ìˆ˜, í—¤ë“œ ìˆ˜, ì€ë‹‰ ì°¨ì› ë“±ì„ í¬ê²Œ ëŠ˜ë ¤ ì„±ëŠ¥ í–¥ìƒ\n",
      "\n",
      "#### 2.3 í•™ìŠµ ëª©í‘œ (Loss)\n",
      "- **ë‹¤ìŒ í† í° ì˜ˆì¸¡**:  \n",
      "  \\[\n",
      "  \\mathcal{L}_{\\text{LM}} = -\\sum_{t=1}^{T} \\log P_{\\theta}(x_t \\mid x_{<t})\n",
      "  \\]\n",
      "  - ì—¬ê¸°ì„œ \\(x_t\\)ëŠ” të²ˆì§¸ í† í°, \\(\\theta\\)ëŠ” ëª¨ë¸ íŒŒë¼ë¯¸í„°\n",
      "- **êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤**ì„ ìµœì†Œí™”í•˜ë©´ì„œ, ëª¨ë¸ì€ **ì¡°ê±´ë¶€ í™•ë¥  ë¶„í¬** \\(P_{\\theta}(x_t|x_{<t})\\) ë¥¼ í•™ìŠµ\n",
      "- **ìƒ˜í”Œë§ ì „ëµ**(ì˜ˆ: í† í° ë§ˆìŠ¤í‚¹, ì‹œí€€ìŠ¤ ê¸¸ì´ ë³€í˜•)ìœ¼ë¡œ ë‹¤ì–‘í•œ ë¬¸ë§¥ì„ ê²½í—˜í•˜ê²Œ í•¨\n",
      "\n",
      "#### 2.4 í•™ìŠµ ì¸í”„ë¼\n",
      "- **GPU/TPU í´ëŸ¬ìŠ¤í„°**: ìˆ˜ì²œ ê°œì˜ ê°€ì†ê¸°, ë°ì´í„° ë³‘ë ¬ ë° ëª¨ë¸ ë³‘ë ¬(ZeRO, FSDP ë“±) ì‚¬ìš©\n",
      "- **í•™ìŠµ ìŠ¤ì¼€ì¤„**: **AdamW** ì˜µí‹°ë§ˆì´ì € + **í•™ìŠµë¥  ì›Œë°ì—… â†’ ë¼ë””ì–¼ ê°ì†Œ**  \n",
      "- **í˜¼í•© ì •ë°€ë„**(FP16/ BF16) â†’ ë©”ëª¨ë¦¬ ì ˆê° ë° ì†ë„ í–¥ìƒ\n",
      "\n",
      "---\n",
      "\n",
      "### 3. ì§€ë„í•™ìŠµ (Supervised Fineâ€‘tuning, SFT)\n",
      "\n",
      "#### 3.1 ëª©ì \n",
      "- ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ **ëŒ€í™”** í˜¹ì€ **íŠ¹ì • ì‘ì—…**ì— ë§ê²Œ ì¡°ì •\n",
      "- â€œì§ˆë¬¸ â†’ ë‹µë³€â€ í˜•íƒœì˜ ë°ì´í„°ë¡œ **ì‚¬ìš©ì ê¸°ëŒ€ì— ë¶€í•©í•˜ëŠ”** ì¶œë ¥ì„ í•™ìŠµ\n",
      "\n",
      "#### 3.2 ë°ì´í„° êµ¬ì„±\n",
      "- **í”„ë¡¬í”„íŠ¸â€‘ì‘ë‹µ ìŒ**: ì¸ê°„ ë¼ë²¨ëŸ¬ê°€ ë§Œë“  ê³ í’ˆì§ˆ ëŒ€í™” ì˜ˆì‹œ\n",
      "- **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**: ëª¨ë¸ì—ê²Œ ì—­í• (ì˜ˆ: â€œì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸â€)ì„ ëª…ì‹œ\n",
      "- **ë‹¤ì–‘ì„±**: ì—¬ëŸ¬ ë„ë©”ì¸Â·í†¤Â·ë‚œì´ë„ í¬í•¨ â†’ ì¼ë°˜í™” ëŠ¥ë ¥ ìœ ì§€\n",
      "\n",
      "#### 3.3 í•™ìŠµ ë°©ë²•\n",
      "- **êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤**ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ ì…ë ¥ì€ **í”„ë¡¬í”„íŠ¸ + ë‹µë³€** ì „ì²´ ì‹œí€€ìŠ¤ë¡œ êµ¬ì„±\n",
      "- **Teacherâ€‘forcing**: ì •ë‹µ í† í°ì„ ë°”ë¡œ ë‹¤ìŒ ì…ë ¥ì— ì‚¬ìš©í•´ ë¹ ë¥¸ ìˆ˜ë ´ ìœ ë„\n",
      "- **í•™ìŠµë¥ **ì€ ì‚¬ì „í•™ìŠµë³´ë‹¤ ë‚®ê²Œ ì„¤ì • (ë³´í†µ 1eâ€‘5~1eâ€‘4)\n",
      "\n",
      "---\n",
      "\n",
      "### 4. ì¸ê°„ í”¼ë“œë°± ê¸°ë°˜ ê°•í™”í•™ìŠµ (RLHF)\n",
      "\n",
      "#### 4.1 ì™œ RLHFê°€ í•„ìš”í•œê°€?\n",
      "- ë‹¨ìˆœíˆ ì •ë‹µì„ ë§ì¶”ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ **ì‚¬ìš©ì ì˜ë„, ì•ˆì „ì„±, ìœ¤ë¦¬ì„±**ì„ ê³ ë ¤í•œ ì¶œë ¥ì´ í•„ìš”\n",
      "- ì§€ë„í•™ìŠµë§Œìœ¼ë¡œëŠ” **ë‹¤ì–‘í•œ ìƒí™©**ì—ì„œ ìµœì  í–‰ë™ì„ ì •ì˜í•˜ê¸° ì–´ë ¤ì›€\n",
      "\n",
      "#### 4.2 êµ¬ì„± ìš”ì†Œ\n",
      "1. **Reward Model (ë³´ìƒ ëª¨ë¸)**  \n",
      "   - ì¸ê°„ ë¼ë²¨ëŸ¬ê°€ ì—¬ëŸ¬ ëª¨ë¸ ì¶œë ¥(ì˜ˆ: 2~3ê°€ì§€ ë‹µë³€)ì„ **ì„ í˜¸ë„ ìˆœìœ„**ë¡œ í‰ê°€  \n",
      "   - ì´ ìˆœìœ„ë¥¼ **ìŒwise ë¹„êµ** í˜•íƒœë¡œ ë³€í™˜í•˜ê³ , **PPO**(Proximal Policy Optimization) ë“±ìœ¼ë¡œ í•™ìŠµ  \n",
      "   - ë³´ìƒ í•¨ìˆ˜ \\(R_{\\phi}(y|x)\\)ëŠ” â€œì–¼ë§ˆë‚˜ ì¢‹ì€ ë‹µë³€ì¸ê°€â€ë¥¼ ì ìˆ˜í™”\n",
      "\n",
      "2. **Policy Model (ì •ì±… ëª¨ë¸)**  \n",
      "   - ì´ˆê¸°ì—ëŠ” SFT ë‹¨ê³„ì—ì„œ ì–»ì€ ëª¨ë¸ì„ ì‚¬ìš©  \n",
      "   - **ê°•í™”í•™ìŠµ**ì„ í†µí•´ ë³´ìƒ ëª¨ë¸ì´ ì£¼ëŠ” ì ìˆ˜ë¥¼ ìµœëŒ€í™”í•˜ë„ë¡ íŒŒë¼ë¯¸í„° \\(\\theta\\)ë¥¼ ì—…ë°ì´íŠ¸\n",
      "\n",
      "#### 4.3 PPO ê¸°ë°˜ ê°•í™”í•™ìŠµ íë¦„\n",
      "1. **ìƒ˜í”Œ ìƒì„±**: í˜„ì¬ ì •ì±… \\(\\pi_{\\theta}\\) ë¡œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ë‹µë³€ \\(y\\) ë¥¼ ì—¬ëŸ¬ ê°œ ìƒì„±\n",
      "2. **ë³´ìƒ ê³„ì‚°**: ë³´ìƒ ëª¨ë¸ \\(R_{\\phi}(y|x)\\) ë¡œ ê° ë‹µë³€ì— ì ìˆ˜ ë¶€ì—¬\n",
      "3. **í´ë¦½ëœ ëª©ì  í•¨ìˆ˜**:\n",
      "   \\[\n",
      "   L^{\\text{PPO}}(\\theta) = \\mathbb{E}\\!\\left[ \\min\\!\\big( r_t(\\theta) \\hat{A}_t, \\text{clip}(r_t(\\theta),1-\\epsilon,1+\\epsilon)\\hat{A}_t \\big) \\right]\n",
      "   \\]\n",
      "   - ì—¬ê¸°ì„œ \\(r_t(\\theta)=\\frac{\\pi_{\\theta}(a_t|s_t)}{\\pi_{\\theta_{\\text{old}}}(a_t|s_t)}\\) (importance ratio)  \n",
      "   - \\(\\hat{A}_t\\)ëŠ” **Advantage** (ë³´ìƒ - ê°€ì¹˜ ì¶”ì •)  \n",
      "   - \\(\\epsilon\\)ì€ í´ë¦¬í•‘ íŒŒë¼ë¯¸í„° (ë³´í†µ 0.2)\n",
      "\n",
      "4. **ê°’ í•¨ìˆ˜ì™€ ì—”íŠ¸ë¡œí”¼ ë³´ë„ˆìŠ¤**ë„ í•¨ê»˜ ìµœì í™”í•´ **ì•ˆì •ì„±**ê³¼ **ë‹¤ì–‘ì„±**ì„ ìœ ì§€\n",
      "\n",
      "#### 4.4 ê²°ê³¼\n",
      "- ëª¨ë¸ì€ â€œ**ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ë©´ì„œë„ ì•ˆì „í•˜ê³ **â€ í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í–‰ë™ì„ ì¡°ì •\n",
      "- ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” **ë‹¤ì¤‘ ë¼ìš´ë“œ ëŒ€í™”**, **ì»¨í…ìŠ¤íŠ¸ ìœ ì§€**, **ê±°ë¶€ ì‘ë‹µ**(ì˜ˆ: ì •ì±… ìœ„ë°˜ ì§ˆë¬¸ì— ëŒ€í•œ ê±°ì ˆ) ë“±ë„ RLHFë¥¼ í†µí•´ í•™ìŠµ\n",
      "\n",
      "---\n",
      "\n",
      "### 5. í† í°í™”ì™€ ì–´íœ˜ (Tokenizer & Vocabulary)\n",
      "\n",
      "- **Byteâ€‘Pair Encoding (BPE)** í˜¹ì€ **SentencePiece** ê¸°ë°˜ **subword** í† í¬ë‚˜ì´ì € ì‚¬ìš©  \n",
      "- ì¥ì   \n",
      "  - **ì–´íœ˜ í¬ê¸°**ë¥¼ ìˆ˜ë§Œ~ìˆ˜ì‹­ë§Œ ìˆ˜ì¤€ìœ¼ë¡œ ì œí•œí•˜ë©´ì„œë„ **í¬ê·€ ë‹¨ì–´**ë¥¼ í‘œí˜„ ê°€ëŠ¥  \n",
      "  - **ë‹¤êµ­ì–´** ëª¨ë¸ì—ì„œëŠ” **Unicode ê¸°ë°˜** í† í¬ë‚˜ì´ì €ê°€ í•œ ë²ˆì— ì—¬ëŸ¬ ì–¸ì–´ë¥¼ ë‹¤ë£¸\n",
      "- **íŠ¹ìˆ˜ í† í°**:  \n",
      "  - `` â†’ ë¬¸ì¥/ë¬¸ì„œ ì¢…ë£Œ  \n",
      "  - `<|assistant|>` ë“± ì‹œìŠ¤í…œ/ì—­í•  êµ¬ë¶„ í† í°  \n",
      "\n",
      "---\n",
      "\n",
      "### 6. ì•ˆì „ì„±Â·ìœ¤ë¦¬Â·í¸í–¥ ê´€ë¦¬\n",
      "\n",
      "1. **ë°ì´í„° í•„í„°ë§**: í­ë ¥Â·í˜ì˜¤Â·ìŒë€Â·í—ˆìœ„ ì •ë³´ ë“±ì„ ì‚¬ì „ ì°¨ë‹¨\n",
      "2. **í›„ì²˜ë¦¬(ì •ì±… ì—”ì§„)**: ëª¨ë¸ ì¶œë ¥ì´ ì •ì±…ì„ ìœ„ë°˜í•˜ë©´ ì°¨ë‹¨Â·ìˆ˜ì •\n",
      "3. **í¸í–¥ ì™„í™”**:  \n",
      "   - **ë°ì´í„° ê· í˜•**(ë‹¤ì–‘í•œ ë¬¸í™”Â·ì„±ë³„Â·ì—°ë ¹) í™•ë³´  \n",
      "   - **ë””ë²„ê¹…**: íŠ¹ì • í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ í¸í–¥ ì‘ë‹µì„ ìë™ íƒì§€Â·ìˆ˜ì •\n",
      "4. **ì¸ê°„ ê²€í† **: ê³ ìœ„í—˜ ìƒí™©(ë²•ë¥ Â·ì˜ë£Œ ë“±)ì—ì„œëŠ” ì¸ê°„ ì „ë¬¸ê°€ê°€ ìµœì¢… ê²€ì¦\n",
      "\n",
      "---\n",
      "\n",
      "### 7. ìš”ì•½ íë¦„ë„\n",
      "\n",
      "```\n",
      "ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°\n",
      "   â”‚\n",
      "   â–¼ (í† í¬ë‚˜ì´ì§•, ì •ì œ)\n",
      "ì‚¬ì „í•™ìŠµ (Selfâ€‘Supervised LM)\n",
      "   â”‚\n",
      "   â–¼ (í”„ë¡¬í”„íŠ¸â€‘ë‹µë³€ ë°ì´í„°)\n",
      "ì§€ë„í•™ìŠµ (SFT)  â†â”€ ì¸ê°„ ë¼ë²¨ëŸ¬ê°€ ë§Œë“  QA/ëŒ€í™” ë°ì´í„°\n",
      "   â”‚\n",
      "   â–¼ (ì¸ê°„ í‰ê°€ â†’ ë³´ìƒ ëª¨ë¸)\n",
      "RLHF (PPO)  â†â”€ ë³´ìƒ ëª¨ë¸ê³¼ ì •ì±… ëª¨ë¸ì„ ë°˜ë³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
      "   â”‚\n",
      "   â–¼\n",
      "ë°°í¬ëœ ChatGPT (ì•ˆì „Â·í¸í–¥ ê´€ë¦¬ + ëª¨ë‹ˆí„°ë§)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## í•µì‹¬ í¬ì¸íŠ¸ ì •ë¦¬\n",
      "\n",
      "| ë‹¨ê³„ | í•µì‹¬ ë‚´ìš© |\n",
      "|------|-----------|\n",
      "| **ì‚¬ì „í•™ìŠµ** | ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ **ë‹¤ìŒ í† í° ì˜ˆì¸¡**ìœ¼ë¡œ í•™ìŠµ â†’ ì–¸ì–´ ì¼ë°˜ ì§€ì‹ ìŠµë“ |\n",
      "| **ì§€ë„í•™ìŠµ** | ì¸ê°„ì´ ë§Œë“  **ëŒ€í™” ì˜ˆì‹œ**ë¡œ ëª¨ë¸ì„ **ëŒ€í™”í˜•**ìœ¼ë¡œ ì¡°ì • |\n",
      "| **RLHF** | ì¸ê°„ í”¼ë“œë°± â†’ **ë³´ìƒ ëª¨ë¸** â†’ **PPO** ë¡œ ì •ì±…ì„ ìµœì í™” â†’ **ì‚¬ìš©ì ì˜ë„Â·ì•ˆì „**ì— ë¶€í•© |\n",
      "| **í† í¬ë‚˜ì´ì €** | Subword ê¸°ë°˜ â†’ ì–´íœ˜ í¬ê¸° ì œí•œ + í¬ê·€ì–´ í‘œí˜„ |\n",
      "| **ì•ˆì „Â·í¸í–¥** | ë°ì´í„° í•„í„°ë§, ì •ì±… ì—”ì§„, í¸í–¥ ì™„í™”, ì¸ê°„ ê²€í†  ë“± ë‹¤ì¤‘ ë ˆì´ì–´ë¡œ ê´€ë¦¬ |\n",
      "\n",
      "---\n",
      "\n",
      "### ì°¸ê³  ë¬¸í—Œ (í•µì‹¬ ë…¼ë¬¸Â·ë¦¬ì†ŒìŠ¤)\n",
      "\n",
      "1. **Vaswani et al., 2017** â€“ *Attention is All You Need* (Transformer ê¸°ë³¸)\n",
      "2. **Radford et al., 2018/2019/2021** â€“ GPTâ€‘1, GPTâ€‘2, GPTâ€‘3 ë…¼ë¬¸\n",
      "3. **Ouyang et al., 2022** â€“ *Training language models to follow instructions with human feedback* (RLHF ì†Œê°œ)\n",
      "4. **Stiennon et al., 2020** â€“ *Learning to summarize with human feedback* (RLHF ì´ˆê¸° ì‚¬ë¡€)\n",
      "5. **OpenAI Cookbook** â€“ ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œì™€ íŒŒë¼ë¯¸í„° íŠœë‹ íŒ\n",
      "\n",
      "---\n",
      "\n",
      "**ëìœ¼ë¡œ**, ChatGPTëŠ” **ëŒ€ê·œëª¨ ì‚¬ì „í•™ìŠµ â†’ ëŒ€í™” íŠ¹í™” ì§€ë„í•™ìŠµ â†’ ì¸ê°„ í”¼ë“œë°± ê¸°ë°˜ ê°•í™”í•™ìŠµ**ì´ë¼ëŠ” 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ â€œì–¸ì–´ë¥¼ ì´í•´í•˜ê³ , ëŒ€í™”ë¥¼ ì´ì–´ê°€ë©°, ì‚¬ìš©ìì˜ ì˜ë„ì— ë§ëŠ” ì•ˆì „í•œ ë‹µë³€ì„ ìƒì„±â€í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê²Œ ë©ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# 2-íŠœí”Œ í˜•íƒœì˜ ë©”ì‹œì§€ ëª©ë¡ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„± (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# ìƒì„±í•œ ë©”ì‹œì§€ë¥¼ ë°”ë¡œ ì£¼ì…í•˜ì—¬ í˜¸ì¶œí•˜ê¸°\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## ChatGPT ëª¨ë¸ì´ ì–´ë–»ê²Œ í•™ìŠµë˜ëŠ”ì§€ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë³´ê¸°  \n",
      "\n",
      "ì•„ë˜ ë‚´ìš©ì€ **Transformer ê¸°ë°˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸**(ì˜ˆ: GPTâ€‘4, GPTâ€‘3.5 ë“±)ì´ í›ˆë ¨ë˜ëŠ” ì „í˜•ì ì¸ ê³¼ì •ì„ í•œêµ­ì–´ë¡œ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤. í•µì‹¬ íë¦„ì€ í¬ê²Œ **ë°ì´í„° ì¤€ë¹„ â†’ ì‚¬ì „ í•™ìŠµ(Preâ€‘training) â†’ ì§€ë„ í•™ìŠµ( supervised fineâ€‘tuning) â†’ ê°•í™” í•™ìŠµ(RLHF)** ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. ë°ì´í„° ì¤€ë¹„ (Corpus Construction)\n",
      "\n",
      "| ìš”ì†Œ | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ì½”í¼ìŠ¤** | ì¸í„°ë„· ì›¹í˜ì´ì§€, ì±…, ë…¼ë¬¸, ë‰´ìŠ¤, ìœ„í‚¤í”¼ë””ì•„, í¬ëŸ¼, ì½”ë“œ ì €ì¥ì†Œ ë“± ë‹¤ì–‘í•œ ì¶œì²˜ì—ì„œ ìˆ˜ì‹­ì–µ í† í° ê·œëª¨ì˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. |\n",
      "| **í´ë Œì§• & í•„í„°ë§** | ì €ì‘ê¶Œ ìœ„ë°˜, ê°œì¸ ì •ë³´, í­ë ¥Â·í˜ì˜¤ í‘œí˜„ ë“± ë¶€ì ì ˆí•œ ë‚´ìš©ì€ ìë™Â·ìˆ˜ë™ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤. ë˜í•œ ì¤‘ë³µ ë¬¸ì„œ, HTML íƒœê·¸, ìŠ¤í¬ë¦½íŠ¸ ë“± ë¹„í…ìŠ¤íŠ¸ ìš”ì†Œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. |\n",
      "| **í† í¬ë‚˜ì´ì§• (Tokenization)** | í…ìŠ¤íŠ¸ë¥¼ **Byteâ€‘Pair Encoding (BPE)** í˜¹ì€ **SentencePiece**ì™€ ê°™ì€ ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì €ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. í•˜ë‚˜ì˜ í† í°ì€ ë³´í†µ 1~4ê°œì˜ ë¬¸ì(ì˜ë¬¸ ê¸°ì¤€) ë˜ëŠ” í•œê¸€ ìëª¨Â·ìŒì ˆì„ í¬í•¨í•©ë‹ˆë‹¤. |\n",
      "| **ë°ì´í„° ìƒ¤í”Œë§** | í•™ìŠµ íš¨ìœ¨ê³¼ í¸í–¥ ê°ì†Œë¥¼ ìœ„í•´ ì „ì²´ ì½”í¼ìŠ¤ë¥¼ ì—¬ëŸ¬ ì‘ì€ ì²­í¬(chunk)ë¡œ ë‚˜ëˆ„ê³ , ê° ì²­í¬ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì–´ í•™ìŠµ ë°°ì¹˜ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. ì‚¬ì „ í•™ìŠµ (Preâ€‘training) â€“ **ìê¸°ì§€ë„ í•™ìŠµ (Selfâ€‘Supervised Learning)**  \n",
      "\n",
      "#### 2.1 ëª©í‘œ í•¨ìˆ˜ (Loss Function)\n",
      "- **ë‹¤ìŒ í† í° ì˜ˆì¸¡ (Causal Language Modeling)**  \n",
      "  \\[\n",
      "  \\mathcal{L}_{\\text{LM}} = -\\sum_{t=1}^{T}\\log P\\big(x_t \\mid x_{<t}; \\theta\\big)\n",
      "  \\]\n",
      "  ì—¬ê¸°ì„œ \\(x_t\\)ëŠ” të²ˆì§¸ í† í°, \\(\\theta\\)ëŠ” ëª¨ë¸ íŒŒë¼ë¯¸í„°, \\(x_{<t}\\)ëŠ” ì•ì„  í† í°ë“¤ì…ë‹ˆë‹¤. ëª¨ë¸ì€ **ì¡°ê±´ë¶€ í™•ë¥ **ì„ í•™ìŠµí•´ â€œì• ë¬¸ë§¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ ë‹¤ìŒì— ì˜¬ í† í°ì€ ë¬´ì—‡ì¸ê°€?â€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
      "\n",
      "#### 2.2 ëª¨ë¸ ì•„í‚¤í…ì²˜\n",
      "- **Transformer Decoder**  \n",
      "  - **ë©€í‹°â€‘í—¤ë“œ ì–´í…ì…˜**: ì…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ì— ëŒ€í•´ ê° í† í°ì´ ë‹¤ë¥¸ í† í°ì„ ì–¼ë§ˆë‚˜ â€œì°¸ê³ â€í•´ì•¼ í•˜ëŠ”ì§€ ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.  \n",
      "  - **í¬ì§€ì…”ë„ ì¸ì½”ë”©**: ìˆœì„œ ì •ë³´ë¥¼ ì¶”ê°€í•´ í† í° ìœ„ì¹˜ë¥¼ êµ¬ë¶„í•©ë‹ˆë‹¤.  \n",
      "  - **í”¼ë“œâ€‘í¬ì›Œë“œ ë ˆì´ì–´**: ê° í† í°ì— ë…ë¦½ì ì¸ ë¹„ì„ í˜• ë³€í™˜ì„ ì ìš©í•©ë‹ˆë‹¤.  \n",
      "  - **Layer Normalization + Residual Connection**: í•™ìŠµ ì•ˆì •ì„± ë° ê¹Šì€ ë„¤íŠ¸ì›Œí¬ ì „íŒŒë¥¼ ë•ìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### 2.3 í•™ìŠµ ì„¸ë¶€ ì‚¬í•­\n",
      "| í•­ëª© | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ë°°ì¹˜ í¬ê¸° (Batch Size)** | ìˆ˜ì²œ~ìˆ˜ë§Œ ì‹œí€€ìŠ¤ (GPU/TPU í´ëŸ¬ìŠ¤í„° ì‚¬ìš©) |\n",
      "| **í•™ìŠµë¥  ìŠ¤ì¼€ì¤„** | **Warmâ€‘up** ë‹¨ê³„ (ì˜ˆ: 10k step) â†’ **Cosine decay** í˜¹ì€ **Linear decay** |\n",
      "| **ì˜µí‹°ë§ˆì´ì €** | **AdamW** (weight decay í¬í•¨) |\n",
      "| **Mixedâ€‘precision (FP16/ BF16)** | ë©”ëª¨ë¦¬ ì ˆê° ë° ì—°ì‚° ì†ë„ í–¥ìƒ |\n",
      "| **ë¶„ì‚° í•™ìŠµ** | ë°ì´í„° ë³‘ë ¬(Data Parallel) + ëª¨ë¸ ë³‘ë ¬(Model Parallel) í˜¹ì€ **ZeRO**ì™€ ê°™ì€ íŒŒë¼ë¯¸í„° ì…°ì–´ë§ ê¸°ë²• ì‚¬ìš© |\n",
      "\n",
      "#### 2.4 ê²°ê³¼\n",
      "- ëª¨ë¸ì€ **ì–¸ì–´ êµ¬ì¡°(ë¬¸ë²•, ì–´íœ˜, ìƒì‹)**ì™€ **í†µê³„ì  íŒ¨í„´**ì„ ë‚´ì¬í™”í•©ë‹ˆë‹¤.  \n",
      "- ì•„ì§ **íŠ¹ì • ëª©í‘œ**(ì˜ˆ: ì§ˆë¬¸â€‘ë‹µë³€, ëŒ€í™”)ì™€ëŠ” ë¬´ê´€í•œ **ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ ìƒì„± ëŠ¥ë ¥**ì„ ê°–ê²Œ ë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. ì§€ë„ í•™ìŠµ (Supervised Fineâ€‘tuning)\n",
      "\n",
      "ì‚¬ì „ í•™ìŠµë§Œìœ¼ë¡œëŠ” **â€œì‚¬ìš©ì ì˜ë„ì— ë§ëŠ” ì‘ë‹µâ€**ì„ ë³´ì¥í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë”°ë¼ì„œ **ì¸ê°„ì´ ë§Œë“  ë¼ë²¨**(ì˜ˆ: ì§ˆë¬¸â€‘ë‹µë³€ ìŒ, ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸)ì„ ì´ìš©í•´ ëª¨ë¸ì„ ì¶”ê°€ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "| ë‹¨ê³„ | ë‚´ìš© |\n",
      "|------|------|\n",
      "| **ë°ì´í„°** | - ì§ˆë¬¸â€‘ë‹µë³€(Qâ€‘A) í˜ì–´<br>- ëŒ€í™” ë¡œê·¸(í”„ë¡¬í”„íŠ¸â€‘ì‘ë‹µ)<br>- íŠ¹ì • ë„ë©”ì¸(ë²•ë¥ , ì˜ë£Œ ë“±) í…ìŠ¤íŠ¸ |\n",
      "| **ëª©í‘œ** | ì…ë ¥(í”„ë¡¬í”„íŠ¸) â†’ ê¸°ëŒ€ë˜ëŠ” ì¶œë ¥(ì •ë‹µ) ì‚¬ì´ì˜ **ì¡°ê±´ë¶€ í™•ë¥ **ì„ ìµœëŒ€í™”í•©ë‹ˆë‹¤. |\n",
      "| **ì†ì‹¤** | ì‚¬ì „ í•™ìŠµê³¼ ë™ì¼í•œ **Crossâ€‘Entropy** ì†ì‹¤ì„ ì‚¬ìš©í•˜ì§€ë§Œ, ë¼ë²¨ì´ ëª…í™•íˆ ì •ì˜ëœ ë°ì´í„°ì—ë§Œ ì ìš©í•©ë‹ˆë‹¤. |\n",
      "| **í•™ìŠµ ë¹„ìœ¨** | ì‚¬ì „ í•™ìŠµì— ë¹„í•´ **í•™ìŠµë¥ ì„ ë‚®ê²Œ** (ì˜ˆ: 1eâ€‘5 ~ 5eâ€‘5) ì„¤ì •í•˜ê³  **ì§§ì€ epoch**(ìˆ˜ì‹­ë§Œ~ìˆ˜ë°±ë§Œ ìŠ¤í…)ë§Œ ì§„í–‰í•©ë‹ˆë‹¤. |\n",
      "\n",
      "ì´ ë‹¨ê³„ì—ì„œ ëª¨ë¸ì€ **â€œì–´ë–¤ ìƒí™©ì—ì„œ ì–´ë–¤ í˜•íƒœì˜ ë‹µë³€ì„ í•´ì•¼ í•˜ëŠ”ê°€â€**ë¥¼ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. ê°•í™” í•™ìŠµì„ í†µí•œ ì¸ê°„ í”¼ë“œë°± (RLHF: Reinforcement Learning from Human Feedback)\n",
      "\n",
      "#### 4.1 ì™œ RLHFê°€ í•„ìš”í•œê°€?\n",
      "- **ë‹¤ì¤‘ ëª©í‘œ**: ì •í™•ì„±, ìœ ìš©ì„±, ì•ˆì „ì„±, ì¹œì ˆí•¨ ë“±ì„ ë™ì‹œì— ë§Œì¡±ì‹œì¼œì•¼ í•¨.  \n",
      "- **ë¼ë²¨ ë¶€ì¡±**: ëª¨ë“  ê°€ëŠ¥í•œ ìƒí™©ì— ëŒ€í•´ ì™„ì „í•œ ì •ë‹µì„ ë¯¸ë¦¬ ì •ì˜í•˜ê¸°ê°€ ë¶ˆê°€ëŠ¥í•¨.\n",
      "\n",
      "#### 4.2 RLHF íŒŒì´í”„ë¼ì¸\n",
      "1. **í”„ë¡¬í”„íŠ¸ â†’ ì—¬ëŸ¬ í›„ë³´ ì‘ë‹µ ìƒì„±**  \n",
      "   - í˜„ì¬ ëª¨ë¸(ë˜ëŠ” ì‚¬ì „â€‘fineâ€‘tuned ëª¨ë¸)ìœ¼ë¡œ ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ Nê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ë‹µë³€ì„ ë§Œë“ ë‹¤.\n",
      "2. **ì¸ê°„ ë¼ë²¨ëŸ¬ê°€ ìˆœìœ„ ë§¤ê¹€**  \n",
      "   - ë¼ë²¨ëŸ¬ê°€ â€œê°€ì¥ ì¢‹ì€â€, â€œë³´í†µâ€, â€œê°€ì¥ ì•ˆ ì¢‹ì€â€ ë“±ìœ¼ë¡œ ë‹µë³€ì„ ë¹„êµÂ·ìˆœìœ„í™”í•œë‹¤.\n",
      "3. **Reward Model (RM) í•™ìŠµ**  \n",
      "   - ë¼ë²¨ëŸ¬ì˜ ìˆœìœ„ ë°ì´í„°ë¥¼ ì´ìš©í•´ **Reward Model**ì„ í•™ìŠµí•œë‹¤. ë³´í†µ **Binary Crossâ€‘Entropy** í˜¹ì€ **Pairwise Ranking Loss**ë¥¼ ì‚¬ìš©í•œë‹¤.\n",
      "   - RMì€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ **ì ìˆ˜**(ì˜ˆ: 0~1)ë¥¼ ì¶œë ¥í•œë‹¤. ë†’ì€ ì ìˆ˜ = ì¸ê°„ì´ ì„ í˜¸í•˜ëŠ” ë‹µë³€.\n",
      "4. **Proximal Policy Optimization (PPO) ë“±ìœ¼ë¡œ ì •ì±… ì—…ë°ì´íŠ¸**  \n",
      "   - ê¸°ì¡´ ì–¸ì–´ ëª¨ë¸ì„ **ì •ì±…(policy)**ìœ¼ë¡œ ê°„ì£¼í•˜ê³ , RMì´ ì œê³µí•˜ëŠ” ë³´ìƒì„ ìµœëŒ€í™”í•˜ë„ë¡ **ê°•í™” í•™ìŠµ**ì„ ìˆ˜í–‰í•œë‹¤.  \n",
      "   - PPOëŠ” **KLâ€‘divergence** ì œì•½ì„ ë„£ì–´ ê¸°ì¡´ ëª¨ë¸ê³¼ ë„ˆë¬´ í¬ê²Œ ë‹¬ë¼ì§€ì§€ ì•Šê²Œ ì¡°ì ˆí•œë‹¤.\n",
      "\n",
      "#### 4.3 ê²°ê³¼\n",
      "- ëª¨ë¸ì€ **â€œì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³ , ì‚¬ì‹¤ì— ê·¼ê±°í•˜ë©°, ìœ„í—˜í•œ ì •ë³´ë¥¼ ìµœì†Œí™”í•˜ëŠ”â€** ë°©í–¥ìœ¼ë¡œ ìŠ¤ìŠ¤ë¡œ í–‰ë™ì„ ì¡°ì •í•œë‹¤.  \n",
      "- RLHF ë‹¨ê³„ëŠ” **ì•ˆì „ì„±Â·ìœ¤ë¦¬ì„±**ì„ í¬ê²Œ ê°œì„ í•˜ì§€ë§Œ, ì—¬ì „íˆ ì™„ë²½í•˜ì§€ ì•Šìœ¼ë©° ì§€ì†ì ì¸ ì¸ê°„ ê²€ì¦ì´ í•„ìš”í•˜ë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. ë°°í¬ì™€ ì§€ì†ì  ê°œì„ \n",
      "\n",
      "| í™œë™ | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ëª¨ë¸ ì••ì¶•Â·ì–‘ìí™”** | **8â€‘bit, 4â€‘bit** ë“± ì €ë¹„íŠ¸ ì–‘ìí™”ë¡œ ì¶”ë¡  ë¹„ìš© ì ˆê° (ì‘ë‹µ ì§€ì—° ê°ì†Œ). |\n",
      "| **ëª¨ë‹ˆí„°ë§** | ì‹¤ì‹œê°„ ë¡œê·¸, ì‚¬ìš©ì í”¼ë“œë°±, ìë™í™”ëœ ì•ˆì „ ê²€ì¦ ë„êµ¬ë¥¼ í†µí•´ ëª¨ë¸ ì¶œë ¥ í’ˆì§ˆì„ ì§€ì† ê°ì‹œ. |\n",
      "| **ì£¼ê¸°ì  ì¬í•™ìŠµ** | ìƒˆë¡œìš´ ë°ì´í„°(ì˜ˆ: ìµœì‹  ì‚¬ê±´, ì •ì±… ë³€í™”)ì™€ í”¼ë“œë°±ì„ ë°˜ì˜í•´ **ì£¼ê¸°ì  ì—…ë°ì´íŠ¸** ìˆ˜í–‰. |\n",
      "| **ì•ˆì „ ì¥ì¹˜** | - **ì½˜í…ì¸  í•„í„°** (ì‚¬ì „Â·ì‚¬í›„ ì°¨ë‹¨)<br>- **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**(í–‰ë™ ê°€ì´ë“œë¼ì¸) <br>- **ì¸ê°„â€‘ì¸â€‘ë”â€‘ë£¨í”„(HITL)** ê²€ì¦ ë‹¨ê³„ |\n",
      "\n",
      "---\n",
      "\n",
      "## í•µì‹¬ í¬ì¸íŠ¸ ìš”ì•½\n",
      "\n",
      "| ë‹¨ê³„ | ëª©ì  | í•µì‹¬ ê¸°ìˆ  |\n",
      "|------|------|-----------|\n",
      "| **ë°ì´í„° ì¤€ë¹„** | ë‹¤ì–‘í•˜ê³  ê¹¨ë—í•œ í…ìŠ¤íŠ¸ í™•ë³´ | í¬ë¡¤ë§, í´ë Œì§•, BPE í† í¬ë‚˜ì´ì € |\n",
      "| **ì‚¬ì „ í•™ìŠµ** | ì–¸ì–´ ì „ë°˜ì  í†µê³„Â·êµ¬ì¡° ìŠµë“ | Causal LM, Transformer Decoder, ëŒ€ê·œëª¨ ë¶„ì‚° í•™ìŠµ |\n",
      "| **ì§€ë„ í•™ìŠµ** | íŠ¹ì • ì‘ì—…(ëŒ€í™”, QA ë“±)ì— ë§ì¶¤ | ë¼ë²¨ë§ëœ ë°ì´í„°, Crossâ€‘Entropy |\n",
      "| **RLHF** | ì¸ê°„ ì„ í˜¸ë„Â·ì•ˆì „ì„± ë°˜ì˜ | Human ranking â†’ Reward Model â†’ PPO |\n",
      "| **ë°°í¬Â·ìš´ì˜** | ì‹¤ì„œë¹„ìŠ¤ ì ìš© ë° ì§€ì† ê°œì„  | ì–‘ìí™”, ëª¨ë‹ˆí„°ë§, HITL, ì •ì±… ì—…ë°ì´íŠ¸ |\n",
      "\n",
      "---\n",
      "\n",
      "### ë¶€ê°€ ì„¤ëª… â€“ â€œì™œ Transformerì¸ê°€?â€\n",
      "\n",
      "- **Selfâ€‘Attention** ë•ë¶„ì— **ë¬¸ë§¥ ì „ì²´**ë¥¼ í•œ ë²ˆì— ê³ ë ¤í•  ìˆ˜ ìˆì–´, RNNÂ·LSTMë³´ë‹¤ **ë³‘ë ¬ ì²˜ë¦¬**ê°€ ì‰½ê³  **ì¥ê±°ë¦¬ ì˜ì¡´ì„±**ì„ ì˜ í¬ì°©í•©ë‹ˆë‹¤.  \n",
      "- **ìŠ¤ì¼€ì¼ë§ ë²•ì¹™**(íŒŒë¼ë¯¸í„° ìˆ˜, ë°ì´í„° ì–‘, ì—°ì‚°ëŸ‰) ì— ë”°ë¼ ëª¨ë¸ í¬ê¸°ë¥¼ í‚¤ìš°ë©´ ì„±ëŠ¥ì´ ì˜ˆì¸¡ ê°€ëŠ¥í•œ í˜•íƒœë¡œ í–¥ìƒë©ë‹ˆë‹¤. ì´ëŠ” GPT ì‹œë¦¬ì¦ˆê°€ **ìˆ˜ì‹­ì–µ â†’ ìˆ˜ì²œì–µ â†’ ìˆ˜ì¡° íŒŒë¼ë¯¸í„°**ë¡œ ì„±ì¥í•˜ë©´ì„œë„ ì¼ê´€ëœ ê°œì„ ì„ ë³´ì¸ ì´ìœ ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ë§ˆë¬´ë¦¬\n",
      "\n",
      "ChatGPTì™€ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ **ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í†µí•œ ì‚¬ì „ í•™ìŠµ â†’ ì¸ê°„ ë¼ë²¨ì„ í™œìš©í•œ ì§€ë„ í•™ìŠµ â†’ ì¸ê°„ í”¼ë“œë°±ì„ ë³´ìƒìœ¼ë¡œ ì‚¼ì€ ê°•í™” í•™ìŠµ**ì´ë¼ëŠ” 3ë‹¨ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ê±°ì³ ìµœì¢…ì ì¸ ëŒ€í™” ëŠ¥ë ¥ì„ ì–»ê²Œ ë©ë‹ˆë‹¤. ê° ë‹¨ê³„ë§ˆë‹¤ **ë°ì´í„° í’ˆì§ˆ**, **ëª¨ë¸ ì•„í‚¤í…ì²˜**, **í•™ìŠµ ëª©í‘œ**, **ì•ˆì „Â·ìœ¤ë¦¬ ê³ ë ¤ì‚¬í•­**ì´ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ë©°, ë°°í¬ í›„ì—ë„ **ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ì—…ë°ì´íŠ¸**ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ë‚˜ ë” ê¹Šì´ ì•Œê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ ì£¼ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ì„ ìƒì„±í•˜ì—¬ í˜¸ì¶œí•˜ê¸°\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplateì™€ HumanMessagePromptTemplate í´ë˜ìŠ¤ ì‚¬ìš©\n",
    "* ê°ì²´ ì§€í–¥ì  ì ‘ê·¼ - Message ê°ì²´ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìƒì„± ê°€ëŠ¥\n",
    "* ì—¬ëŸ¬ ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„ íƒ\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ìƒì„¸ ë¶„ì„: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Deep Learning â€“ A Clear, Detailed Overview\n",
      "\n",
      "### 1. What It Is, in One Sentence  \n",
      "**Deep learning** is a subâ€‘field of machine learning that uses **artificial neural networks with many (deep) layers** to automatically learn hierarchical representations of data, enabling computers to perform tasks such as image recognition, speech transcription, language translation, and moreâ€”often with performance comparable to or surpassing human experts.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Why â€œDeepâ€?\n",
      "\n",
      "| Concept | Explanation |\n",
      "|---------|-------------|\n",
      "| **Neural network** | A computational model loosely inspired by the brainâ€™s network of neurons. Each â€œneuronâ€ receives inputs, applies a weighted sum, passes the result through a nonâ€‘linear **activation function**, and outputs a value. |\n",
      "| **Depth** | The number of *hidden* layers (layers between input and output). A **deep** network has many hidden layers (typically â‰¥â€¯3, often dozens or hundreds). Depth lets the model build **progressively more abstract features**: lowâ€‘level edges â†’ shapes â†’ objects â†’ concepts. |\n",
      "| **Width** | Number of neurons per layer. Both depth and width affect the networkâ€™s capacity to model complex functions. |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Core Building Blocks\n",
      "\n",
      "| Block | Role | Typical Choices |\n",
      "|-------|------|-----------------|\n",
      "| **Input layer** | Holds raw data (pixels, audio samples, word indices, etc.) | Size = dimensionality of data |\n",
      "| **Hidden layers** | Extract and transform features | Fullyâ€‘connected (dense), convolutional, recurrent, attention, etc. |\n",
      "| **Output layer** | Produces predictions (class probabilities, continuous values, token probabilitiesâ€¦) | Softmax (classification), sigmoid, linear, etc. |\n",
      "| **Activation functions** | Introduce nonâ€‘linearity, enabling the network to approximate complex functions | ReLU, Leaky ReLU, ELU, tanh, sigmoid, GELU (used in transformers) |\n",
      "| **Loss function** | Quantifies prediction error for a given example | Crossâ€‘entropy, meanâ€‘squared error, hinge loss, CTC loss, etc. |\n",
      "| **Optimizer** | Updates weights to minimize loss | Stochastic Gradient Descent (SGD), Adam, RMSprop, LAMB, etc. |\n",
      "| **Regularization** | Prevents overâ€‘fitting | Dropout, weight decay (L2), batch normalization, data augmentation |\n",
      "\n",
      "---\n",
      "\n",
      "### 4. How Training Works (Highâ€‘Level)\n",
      "\n",
      "1. **Forward Pass** â€“ Input data flows through the network, producing an output.\n",
      "2. **Loss Computation** â€“ Compare output to the groundâ€‘truth label using a loss function.\n",
      "3. **Backward Pass (Backâ€‘propagation)** â€“ Compute gradients of the loss w.r.t. every weight using the chain rule.\n",
      "4. **Weight Update** â€“ Apply an optimizer to adjust weights in the direction that reduces loss.\n",
      "5. **Iterate** â€“ Repeat over many miniâ€‘batches for many epochs until performance plateaus.\n",
      "\n",
      "*Key point*: **Backâ€‘propagation** is what makes deep learning feasible; it efficiently propagates error signals through many layers.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. Major Architectures & When to Use Them\n",
      "\n",
      "| Architecture | Typical Data Type | Core Idea | Notable Applications |\n",
      "|--------------|-------------------|-----------|----------------------|\n",
      "| **Multilayer Perceptron (MLP)** | Tabular, lowâ€‘dimensional vectors | Stacked dense layers | Simple classification/regression tasks |\n",
      "| **Convolutional Neural Network (CNN)** | Images, video, 2â€‘D/3â€‘D grids | Local receptive fields + weight sharing â†’ translationâ€‘invariant features | Image classification, object detection, medical imaging |\n",
      "| **Recurrent Neural Network (RNN) / LSTM / GRU** | Sequences (text, speech, time series) | Hidden state carries information across time steps | Language modeling, speech recognition, timeâ€‘series forecasting |\n",
      "| **Transformer** | Sequences (especially language) | Selfâ€‘attention lets each token attend to all others; highly parallelizable | Machine translation, largeâ€‘scale language models (GPT, BERT), protein folding |\n",
      "| **Graph Neural Network (GNN)** | Graphâ€‘structured data (social networks, molecules) | Message passing between nodes | Recommendation systems, drug discovery |\n",
      "| **Variational Autoencoder (VAE) / Generative Adversarial Network (GAN)** | Any modality (images, audio, etc.) | Learn to generate new data samples | Image synthesis, style transfer, data augmentation |\n",
      "\n",
      "---\n",
      "\n",
      "### 6. Realâ€‘World Success Stories\n",
      "\n",
      "| Domain | Example | What Deep Learning Did |\n",
      "|--------|---------|------------------------|\n",
      "| **Computer Vision** | *ImageNet* competition (2012) â€“ AlexNet | Reduced topâ€‘5 error from ~26â€¯% to ~15â€¯% â†’ sparked the modern DL boom |\n",
      "| **Speech** | Google Voice Search, Siri, Alexa | Endâ€‘toâ€‘end models transcribe speech with >â€¯95â€¯% accuracy in many languages |\n",
      "| **Natural Language Processing** | OpenAI GPTâ€‘4, Google PaLM, BERT | Achieve humanâ€‘level performance on translation, summarization, code generation |\n",
      "| **Healthcare** | Radiology (detecting pneumonia, breast cancer) | Match or exceed radiologists in specific tasks |\n",
      "| **Games & Planning** | AlphaGo, AlphaZero, OpenAI Five | Learned strategies from raw game states, beating world champions |\n",
      "\n",
      "---\n",
      "\n",
      "### 7. Advantages Over Traditional Machine Learning\n",
      "\n",
      "| Aspect | Traditional ML (e.g., SVM, Random Forest) | Deep Learning |\n",
      "|--------|-------------------------------------------|---------------|\n",
      "| **Feature Engineering** | Handâ€‘crafted, domainâ€‘specific | Learned automatically from raw data |\n",
      "| **Scalability** | Often limited by feature size | Handles millions of parameters and billions of data points |\n",
      "| **Performance on Unstructured Data** | Poor to moderate | Stateâ€‘ofâ€‘theâ€‘art on images, audio, text |\n",
      "| **Transfer Learning** | Rarely used | Preâ€‘trained models can be fineâ€‘tuned for new tasks with little data |\n",
      "\n",
      "---\n",
      "\n",
      "### 8. Common Challenges & How to Mitigate Them\n",
      "\n",
      "| Challenge | Why It Happens | Mitigation Strategies |\n",
      "|-----------|----------------|-----------------------|\n",
      "| **Data Hungry** | Large networks need massive labeled datasets | Use data augmentation, synthetic data, selfâ€‘supervised pretraining, transfer learning |\n",
      "| **Overâ€‘fitting** | Model memorizes training data | Regularization (dropout, weight decay), early stopping, crossâ€‘validation |\n",
      "| **Training Instability** | Vanishing/exploding gradients, poor initialization | Proper weight initialization (He, Xavier), batch normalization, residual connections (ResNets) |\n",
      "| **Compute Cost** | Millionsâ€‘toâ€‘billions of FLOPs | Use GPUs/TPUs, mixedâ€‘precision training, model pruning, knowledge distillation |\n",
      "| **Interpretability** | Blackâ€‘box nature | Saliency maps, SHAP, LIME, concept activation vectors, attention visualisation |\n",
      "| **Bias & Fairness** | Model learns biases present in data | Careful dataset curation, bias detection tools, fairnessâ€‘aware loss functions |\n",
      "\n",
      "---\n",
      "\n",
      "### 9. Getting Started â€“ A Practical Roadmap\n",
      "\n",
      "1. **Learn the Foundations**  \n",
      "   - Linear algebra, calculus, probability basics.  \n",
      "   - Intro to machine learning (supervised vs. unsupervised, biasâ€‘variance tradeâ€‘off).\n",
      "\n",
      "2. **Pick a Framework**  \n",
      "   - **PyTorch** (dynamic graph, researchâ€‘friendly) or **TensorFlow/Keras** (productionâ€‘oriented).  \n",
      "   - Follow official tutorials: *â€œDeep Learning with PyTorch: A 60â€‘Minute Blitzâ€* or *â€œTensorFlow 2.x Quickstartâ€*.\n",
      "\n",
      "3. **Handsâ€‘On Projects**  \n",
      "   - **Image classification** with CIFARâ€‘10 using a small CNN.  \n",
      "   - **Text sentiment analysis** with an LSTM or a preâ€‘trained BERT model.  \n",
      "   - **GAN** to generate handwritten digits (MNIST).\n",
      "\n",
      "4. **Study Core Papers**  \n",
      "   - *AlexNet* (2012) â€“ first breakthrough CNN.  \n",
      "   - *ResNet* (2015) â€“ residual connections.  \n",
      "   - *Vaswani et al., â€œAttention Is All You Needâ€* (2017) â€“ transformer.  \n",
      "   - *Goodfellow et al., â€œGenerative Adversarial Networksâ€* (2014) â€“ GAN.\n",
      "\n",
      "5. **Explore Transfer Learning**  \n",
      "   - Load a preâ€‘trained model (e.g., `torchvision.models.resnet50(pretrained=True)`) and fineâ€‘tune on a small custom dataset.\n",
      "\n",
      "6. **Deploy**  \n",
      "   - Convert to ONNX/TensorFlow Lite for edge devices.  \n",
      "   - Use cloud services (AWS SageMaker, GCP Vertex AI) for scalable inference.\n",
      "\n",
      "---\n",
      "\n",
      "### 10. Key Terminology (Quick Glossary)\n",
      "\n",
      "| Term | Meaning |\n",
      "|------|---------|\n",
      "| **Epoch** | One full pass through the entire training dataset. |\n",
      "| **Batch / Miniâ€‘batch** | Subset of training examples processed together; enables efficient GPU utilization. |\n",
      "| **Learning rate** | Step size for weight updates; too high â†’ divergence, too low â†’ slow convergence. |\n",
      "| **Gradient descent** | Optimization algorithm that follows the negative gradient of the loss. |\n",
      "| **Backâ€‘propagation** | Algorithm to compute gradients efficiently across many layers. |\n",
      "| **Overâ€‘fitting / Underâ€‘fitting** | Model too complex vs. too simple for the data. |\n",
      "| **Dropout** | Randomly zeroes a fraction of activations during training to prevent coâ€‘adaptation. |\n",
      "| **Batch Normalization** | Normalizes layer inputs per miniâ€‘batch, stabilizing training. |\n",
      "| **Residual connection** | Shortcut that adds input to output of a block (helps train very deep nets). |\n",
      "| **Selfâ€‘attention** | Mechanism where each element of a sequence weighs all other elements, forming the basis of transformers. |\n",
      "\n",
      "---\n",
      "\n",
      "### 11. Further Learning Resources\n",
      "\n",
      "| Type | Resource | Why Itâ€™s Good |\n",
      "|------|----------|---------------|\n",
      "| **Books** | *Deep Learning* â€“ Ian Goodfellow, Yoshua Bengio, Aaron Courville | Comprehensive theory + math |\n",
      "| **Online Courses** | **fast.ai** â€œPractical Deep Learning for Codersâ€ | Codeâ€‘first, topâ€‘down approach |\n",
      "| | **CS231n** (Stanford) â€“ Convolutional Neural Networks for Visual Recognition | Visual intuition + assignments |\n",
      "| | **CS224n** â€“ Natural Language Processing with Deep Learning | Transformerâ€‘focused |\n",
      "| **Tutorials** | PyTorch official tutorials, TensorFlow/Keras guides | Handsâ€‘on, upâ€‘toâ€‘date |\n",
      "| **Communities** | Reddit r/MachineLearning, Stack Overflow, Discord AI servers | Quick help, latest news |\n",
      "| **Paper Repositories** | arXiv.org (search â€œdeep learningâ€) | Cuttingâ€‘edge research |\n",
      "\n",
      "---\n",
      "\n",
      "### 12. Bottom Line\n",
      "\n",
      "Deep learning **automates the extraction of hierarchical features** from raw data by stacking many layers of artificial neurons. Its ability to learn directly from massive datasets, combined with modern hardware (GPUs/TPUs) and algorithmic tricks (batch norm, residual connections, attention), has made it the dominant technology behind todayâ€™s most impressive AI systemsâ€”from selfâ€‘driving cars to conversational agents.\n",
      "\n",
      "If youâ€™re just starting, focus on **building simple models, understanding why they work, and then progressively explore more sophisticated architectures**. The field evolves quickly, but the core ideasâ€”*layers, nonâ€‘linearities, gradientâ€‘based learning*â€”remain the same foundation. Happy learning!\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate í™œìš©\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateë¡œ ë©”ì‹œì§€ë“¤ì„ ë¬¶ê¸°\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# ë©”ì‹œì§€ ìƒì„±\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplateëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë©”ì‹œì§€(ì‹œìŠ¤í…œ, ì¸ê°„, AI)ë¥¼ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "* SystemMessagePromptTemplate: ì´ í…œí”Œë¦¿ì€ AI ëª¨ë¸ì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê±°ë‚˜ ì „ë°˜ì ì¸ ê·œì¹™ì„ ì„¤ì •í•˜ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤. ìœ„ì˜ ì˜ˆì‹œì—ì„œëŠ” \"ë²ˆì—­ì„ ë„ì™€ì£¼ëŠ” ìœ ìš©í•œ ë„ìš°ë¯¸\"ë¼ëŠ” ì—­í• ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "* HumanMessagePromptTemplate: ì´ í…œí”Œë¦¿ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì„ ë‹´ëŠ” ì¸ê°„ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì•„ë˜ì˜ ì˜ˆì‹œì—ì„œëŠ” ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.\n",
    "* ChatPromptTemplate.from_messages: ì´ í´ë˜ìŠ¤ ë©”ì„œë“œëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€, ì¸ê°„ ë©”ì‹œì§€ ë“± ì—¬ëŸ¬ ì¢…ë¥˜ì˜ MessagePromptTemplate ê°ì²´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ í•˜ë‚˜ì˜ ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.\n",
    "* format_messages: ì´ ë©”ì„œë“œëŠ” ì •ì˜ëœ í…œí”Œë¦¿ì— ì‹¤ì œ ê°’ì„ ì±„ì›Œ ë„£ì–´ [SystemMessage, HumanMessage] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ë¦¬ìŠ¤íŠ¸ëŠ” ì±„íŒ… ëª¨ë¸(Chat Model) ì— ë°”ë¡œ ì „ë‹¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "ë‚˜ëŠ” í”„ë¡œê·¸ë˜ë°ì„ ì‚¬ë‘í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplateì™€ HumanMessagePromptTemplate ìƒì„±\n",
    "# SystemMessagePromptTemplateëŠ” ëª¨ë¸ì˜ í˜ë¥´ì†Œë‚˜ ë˜ëŠ” ê¸°ë³¸ ì§€ì¹¨ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplateëŠ” ì‚¬ìš©ìë¡œë¶€í„° ë°›ëŠ” ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate ìƒì„±\n",
    "# ìœ„ì—ì„œ ë§Œë“  ë‘ í…œí”Œë¦¿ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ ChatPromptTemplateì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…\n",
    "# chat_prompt_template.format_messages()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# ì´ í•¨ìˆ˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. ê²°ê³¼ ì¶œë ¥\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplateì€ ëª¨ë¸ì´ íŠ¹ì • í˜•ì‹ì„ ë”°ë¥´ê²Œ í•˜ê±°ë‚˜, ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "* ë„ë©”ì¸ ì§€ì‹ì´ í•„ìš”í•˜ê±°ë‚˜, AIê°€ ì˜¤ë‹µì„ ì¤„ì´ê³  ë” ì‹ ë¢°í•  ë§Œí•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ í•´ì•¼ í•  ë•Œ íš¨ê³¼ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplateì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "**íƒœì–‘ê³„ í–‰ì„± ê°„ëµ ì •ë¦¬**\n",
      "\n",
      "| ìˆœì„œ(íƒœì–‘ìœ¼ë¡œë¶€í„°) | í–‰ì„± | ì¢…ë¥˜ | í‰ê·  ì§€ë¦„ (km) | íŠ¹ì§• |\n",
      "|-------------------|------|------|----------------|------|\n",
      "| 1 | **ìˆ˜ì„± (Mercury)** | ì•”ì„í˜• í–‰ì„± | 4,880 | ê°€ì¥ ì‘ì€ í–‰ì„±, ëŒ€ê¸°ê°€ ê±°ì˜ ì—†ìœ¼ë©° í‘œë©´ ì˜¨ë„ ì°¨ì´ê°€ ê·¹ì‹¬í•¨ |\n",
      "| 2 | **ê¸ˆì„± (Venus)** | ì•”ì„í˜• í–‰ì„± | 12,104 | ë‘êº¼ìš´ ì´ì‚°í™”íƒ„ì†Œ ëŒ€ê¸°ì™€ í™©ì‚° êµ¬ë¦„, ì˜¨ì‹¤ íš¨ê³¼ë¡œ í‘œë©´ ì˜¨ë„ ~470â€¯Â°C |\n",
      "| 3 | **ì§€êµ¬ (Earth)** | ì•”ì„í˜• í–‰ì„± | 12,742 | ë¬¼ì´ ì•¡ì²´ ìƒíƒœë¡œ ì¡´ì¬í•˜ëŠ” ìœ ì¼í•œ í–‰ì„±, í’ë¶€í•œ ëŒ€ê¸°ì™€ ìƒëª… |\n",
      "| 4 | **í™”ì„± (Mars)** | ì•”ì„í˜• í–‰ì„± | 6,779 | ì–‡ì€ ì´ì‚°í™”íƒ„ì†Œ ëŒ€ê¸°, ì ìƒ‰ í† ì–‘, ê³¼ê±°ì— ë¬¼ì´ íë¥¸ í”ì  |\n",
      "| 5 | **ëª©ì„± (Jupiter)** | ê°€ìŠ¤ í–‰ì„± | 139,822 | íƒœì–‘ê³„ ìµœëŒ€ì˜ í–‰ì„±, ê±°ëŒ€í•œ í­í’(ëŒ€ì ì )ê³¼ ìˆ˜ë§ì€ ìœ„ì„± |\n",
      "| 6 | **í† ì„± (Saturn)** | ê°€ìŠ¤ í–‰ì„± | 116,464 | ëˆˆì— ë„ëŠ” ê³ ë¦¬ ì‹œìŠ¤í…œ, 80ì—¬ ê°œ ì´ìƒì˜ ìœ„ì„± |\n",
      "| 7 | **ì²œì™•ì„± (Uranus)** | ì–¼ìŒ ê±°ëŒ€ í–‰ì„± | 50,724 | ìì „ì¶•ì´ ì•½ 98Â° ê¸°ìš¸ì–´ì ¸ ìˆì–´ â€˜ì˜†ìœ¼ë¡œ ëˆ„ìš´â€™ í–‰ì„±, í‘¸ë¥¸ìƒ‰ì€ ë©”íƒ„ ê°€ìŠ¤ |\n",
      "| 8 | **í•´ì™•ì„± (Neptune)** | ì–¼ìŒ ê±°ëŒ€ í–‰ì„± | 49,244 | ê°€ì¥ ê°•í•œ ë°”ëŒ(ì‹œì† 2,400â€¯km)ê³¼ ëˆˆì— ë„ëŠ” ì²­ìƒ‰, íŠ¸ìœ„í„°(Triton) ìœ„ì„± ë³´ìœ  |\n",
      "\n",
      "**ì£¼ìš” í¬ì¸íŠ¸**\n",
      "\n",
      "- **ì•”ì„í˜• í–‰ì„±**(ìˆ˜ì„±, ê¸ˆì„±, ì§€êµ¬, í™”ì„±) : ê³ ì²´ í‘œë©´ê³¼ ì–‡ì€ ëŒ€ê¸°(ë˜ëŠ” ì—†ìŒ).  \n",
      "- **ê°€ìŠ¤ í–‰ì„±**(ëª©ì„±, í† ì„±) : ì£¼ë¡œ ìˆ˜ì†ŒÂ·í—¬ë¥¨ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, í•µì€ ì¡´ì¬í•˜ì§€ë§Œ í‘œë©´ì´ ëª…í™•í•˜ì§€ ì•ŠìŒ.  \n",
      "- **ì–¼ìŒ ê±°ëŒ€ í–‰ì„±**(ì²œì™•ì„±, í•´ì™•ì„±) : ê°€ìŠ¤ í–‰ì„±ë³´ë‹¤ ë¬¼, ì•”ëª¨ë‹ˆì•„, ë©”íƒ„ ê°™ì€ â€˜ì–¼ìŒâ€™ ë¬¼ì§ˆ ë¹„ì¤‘ì´ ë†’ìŒ.  \n",
      "- **ìœ„ì„±Â·ê³ ë¦¬** : ëª©ì„±Â·í† ì„±Â·ì²œì™•ì„±Â·í•´ì™•ì„±ì€ ê°ê° ìˆ˜ì‹­ ê°œ ì´ìƒì˜ ìœ„ì„±ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, í† ì„±ì€ ê°€ì¥ ëšœë ·í•œ ê³ ë¦¬ ì‹œìŠ¤í…œì„ ê°€ì§.  \n",
      "\n",
      "> **ê°„ë‹¨ ìš”ì•½**  \n",
      "> íƒœì–‘ê³„ëŠ” ë‚´í–‰ì„± 4ê°œ(ìˆ˜ì„±Â·ê¸ˆì„±Â·ì§€êµ¬Â·í™”ì„±)ì™€ ì™¸í–‰ì„± 4ê°œ(ëª©ì„±Â·í† ì„±Â·ì²œì™•ì„±Â·í•´ì™•ì„±)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ë‚´í–‰ì„±ì€ ì•”ì„ìœ¼ë¡œ ì´ë£¨ì–´ì¡Œê³ , ì™¸í–‰ì„±ì€ ì£¼ë¡œ ê°€ìŠ¤ì™€ ì–¼ìŒìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê±°ëŒ€í•œ í–‰ì„±ë“¤ì…ë‹ˆë‹¤. ê° í–‰ì„±ì€ í¬ê¸°, ëŒ€ê¸°, ì˜¨ë„, ìœ„ì„±Â·ê³ ë¦¬ ë“±ì—ì„œ ë…íŠ¹í•œ íŠ¹ì§•ì„ ë³´ì—¬ ì¤ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplateì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain ì‹¤í–‰\n",
    "result = llm.invoke(\"íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤ì„ ê°„ëµíˆ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate ì‚¬ìš©í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': 'ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.', 'output': '### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\\n1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\\n2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\\n3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.'}, {'input': 'ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.', 'output': '### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\\n- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\\n- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\\n- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\\n- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A947AF59A0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A947FEE8D0>, root_client=<openai.OpenAI object at 0x000001A94678F830>, root_async_client=<openai.AsyncOpenAI object at 0x000001A947BBC590>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "## ğŸ“ ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©í•™ê³¼ ì¡¸ì—…ìƒì„ ìœ„í•œâ€¯AI ì‹œëŒ€ ì·¨ì—… ë¡œë“œë§µ  \n",
      "\n",
      "ì•„ë˜ëŠ” **AIÂ·ë°ì´í„°Â·ì†Œí”„íŠ¸ì›¨ì–´**ê°€ í•µì‹¬ì´ ë˜ëŠ” 10ê°€ì§€ ì§ì—…êµ°ì„ **ì§ë¬´ ì†Œê°œ â†’ ì£¼ìš” ê¸°ìˆ Â·ì—­ëŸ‰ â†’ ì™œ ì „ë§ì´ ì¢‹ì€ì§€** ìˆœìœ¼ë¡œ ì •ë¦¬í–ˆì–´ìš”.  \n",
      "ê° ì§ë¬´ë§ˆë‹¤ â€œì‹œì‘í•˜ê¸° ì‰¬ìš´ ì…ë¬¸ ë‹¨ê³„â€ì™€ â€œê²½ë ¥ 3~5ë…„ ì°¨ì— ë„ì „í•˜ë©´ ì¢‹ì€ ê³ ê¸‰ í¬ì§€ì…˜â€ë„ í•¨ê»˜ ì ì–´ ë‘ì—ˆìœ¼ë‹ˆ, ì§€ê¸ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ ì¤€ë¹„í•´ ë³´ì„¸ìš”!\n",
      "\n",
      "---\n",
      "\n",
      "## 1ï¸âƒ£ AIÂ·ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´  \n",
      "**ì§ë¬´** : ëª¨ë¸ ì„¤ê³„Â·í•™ìŠµÂ·ë°°í¬, ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•, ì„±ëŠ¥ íŠœë‹  \n",
      "**í•µì‹¬ ê¸°ìˆ **  \n",
      "- Python (NumPy, Pandas, Scikitâ€‘learn)  \n",
      "- ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬: TensorFlow, PyTorch  \n",
      "- í´ë¼ìš°ë“œ AI ì„œë¹„ìŠ¤(AWS SageMaker, Azure ML, GCP Vertex AI)  \n",
      "- ê¸°ë³¸ ìˆ˜í•™Â·í†µê³„ (ì„ í˜•ëŒ€ìˆ˜, í™•ë¥ )  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- ê¸°ì—…Â·ê³µê³µê¸°ê´€ì´ AI ì œí’ˆÂ·ì„œë¹„ìŠ¤ë¥¼ ë¹ ë¥´ê²Œ ì¶œì‹œí•˜ë ¤ê³  í•¨ â†’ ì¸ì¬ ìˆ˜ìš” í­ë°œ  \n",
      "- â€œAI ëª¨ë¸ì„ ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš©í•˜ëŠ”(MLOps) ì—­ëŸ‰â€ì´ ê°€ì¥ ëœ¨ê±°ìš´ ìŠ¤í‚¬  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ Kaggle ì´ˆê¸‰ ëŒ€íšŒ ì°¸ì—¬ â†’ ì‚¬ë‚´ AI íŒŒì¼ëŸ¿ í”„ë¡œì íŠ¸  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ MLOps ì—”ì§€ë‹ˆì–´, AI ì—°êµ¬ì›, AI ì•„í‚¤í…íŠ¸  \n",
      "\n",
      "---\n",
      "\n",
      "## 2ï¸âƒ£ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ / ë°ì´í„° ë¶„ì„ê°€  \n",
      "**ì§ë¬´** : ë°ì´í„° ìˆ˜ì§‘Â·ì •ì œÂ·ë¶„ì„Â·ì‹œê°í™”, ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ  \n",
      "**í•µì‹¬ ê¸°ìˆ **  \n",
      "- SQL, Python/R, Tableau/PowerBI  \n",
      "- í†µê³„Â·ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ (íšŒê·€, êµ°ì§‘, ì‹œê³„ì—´)  \n",
      "- ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê¸°ë³¸ (ETL, Airflow)  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- ëª¨ë“  ì‚°ì—…ì´ â€œë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •â€ì„ ëª©í‘œë¡œ í•¨ â†’ ë°ì´í„° ì „ë¬¸ê°€ê°€ í•„ìˆ˜  \n",
      "- AIì™€ ê²°í•©í•˜ë©´ **ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ â†’ AI ì†”ë£¨ì…˜** ìœ¼ë¡œ ì„±ì¥ ê°€ëŠ¥  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ ë°ì´í„° ì‹œê°í™” í”„ë¡œì íŠ¸(ì˜ˆ: ê³µê³µ ë°ì´í„° í™œìš©)  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ ë°ì´í„° ì „ëµê°€, AI ì œí’ˆ ë§¤ë‹ˆì €  \n",
      "\n",
      "---\n",
      "\n",
      "## 3ï¸âƒ£ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì (AIÂ·í´ë¼ìš°ë“œ íŠ¹í™”)  \n",
      "**ì§ë¬´** : ì›¹Â·ì•±Â·ë°±ì—”ë“œ ê°œë°œ, AI API ì—°ë™, í´ë¼ìš°ë“œ ì¸í”„ë¼ ì„¤ê³„  \n",
      "**í•µì‹¬ ê¸°ìˆ **  \n",
      "- ì–¸ì–´: Java, Kotlin, Go, Node.js, Python  \n",
      "- í”„ë ˆì„ì›Œí¬: Spring, Django, FastAPI  \n",
      "- í´ë¼ìš°ë“œ: AWS, Azure, GCP (íŠ¹íˆ AI ì„œë¹„ìŠ¤ ì—°ë™)  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- AI ì„œë¹„ìŠ¤ëŠ” **ì†Œí”„íŠ¸ì›¨ì–´**ì™€ ê²°í•©ë¼ì•¼ ì‹¤ì œ ì œí’ˆì´ ë˜ë¯€ë¡œ, ì „í†µ ê°œë°œìì™€ AI ê°œë°œì ì‚¬ì´ì˜ â€œë¸Œë¦¿ì§€â€ ì—­í• ì´ í¬ê²Œ í•„ìš”í•¨  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ ê°œì¸ í”„ë¡œì íŠ¸(ì˜ˆ: ì±—ë´‡ ì›¹ì•±)  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ AI í”Œë«í¼ ì—”ì§€ë‹ˆì–´, í’€ìŠ¤íƒ AI ê°œë°œì  \n",
      "\n",
      "---\n",
      "\n",
      "## 4ï¸âƒ£ MLOps ì—”ì§€ë‹ˆì–´ (AI ìš´ì˜ ì „ë¬¸ê°€)  \n",
      "**ì§ë¬´** : ëª¨ë¸ ë°°í¬Â·ëª¨ë‹ˆí„°ë§Â·CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•, ì¸í”„ë¼ ìë™í™”  \n",
      "**í•µì‹¬ ê¸°ìˆ **  \n",
      "- Docker, Kubernetes, Terraform  \n",
      "- CI/CD ë„êµ¬: GitHub Actions, Jenkins, GitLab CI  \n",
      "- ëª¨ë¸ ì„œë¹™: TensorFlow Serving, TorchServe, FastAPI  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- ëª¨ë¸ì„ **ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜**í•˜ëŠ” ëŠ¥ë ¥ì´ ê°€ì¥ ë¶€ì¡±í•œ ì˜ì—­ â†’ ë†’ì€ ì—°ë´‰Â·ì±…ì„ê°  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ Dockerë¡œ ê°„ë‹¨í•œ ëª¨ë¸ ì„œë¹™ ì‹¤ìŠµ  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ AI í”Œë«í¼ íŒ€ ë¦¬ë“œ, í´ë¼ìš°ë“œ AI ì†”ë£¨ì…˜ ì•„í‚¤í…íŠ¸  \n",
      "\n",
      "---\n",
      "\n",
      "## 5ï¸âƒ£ ë¡œë³´í‹±ìŠ¤Â·ìë™í™” ì—”ì§€ë‹ˆì–´  \n",
      "**ì§ë¬´** : ë¡œë´‡ ì œì–´Â·ì‹œë®¬ë ˆì´ì…˜Â·AI ê¸°ë°˜ ì¸ì‹Â·ì‚°ì—… ìë™í™” ì‹œìŠ¤í…œ ê°œë°œ  \n",
      "**í•µì‹¬ ê¸°ìˆ **  \n",
      "- ROS (Robot Operating System)  \n",
      "- C++/Python, ì‹¤ì‹œê°„ ì œì–´ ì´ë¡   \n",
      "- ì»´í“¨í„° ë¹„ì „ (OpenCV, YOLO)  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- ì œì¡°Â·ë¬¼ë¥˜Â·ì˜ë£Œ ë“±ì—ì„œ **AI ë¡œë´‡** ë„ì…ì´ ê¸‰ì¦ â†’ ìœµí•© ì „ê³µì´ ê°•ì   \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ ë¼ì¦ˆë² ë¦¬íŒŒì´Â·ì•„ë‘ì´ë…¸ ë¡œë´‡ í‚¤íŠ¸ ì œì‘  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ ììœ¨ì£¼í–‰ ë¡œë´‡, ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ì†”ë£¨ì…˜ ê°œë°œ  \n",
      "\n",
      "---\n",
      "\n",
      "## 6ï¸âƒ£ ì»´í“¨í„° ë¹„ì „Â·ì˜ìƒ ì²˜ë¦¬ ì—”ì§€ë‹ˆì–´  \n",
      "**ì§ë¬´** : ì´ë¯¸ì§€Â·ë™ì˜ìƒ ë¶„ì„, ê°ì²´ íƒì§€Â·ì„¸ë¶„í™”, AR/VR ì½˜í…ì¸  ê°œë°œ  \n",
      "**í•µì‹¬ ê¸°ìˆ **  \n",
      "- OpenCV, PyTorch/TensorFlow (CNN, Transformer)  \n",
      "- Edge AI (NVIDIA Jetson, Coral)  \n",
      "- 3D ëª¨ë¸ë§ ê¸°ì´ˆ (Blender, Unity)  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- ììœ¨ì£¼í–‰, ìŠ¤ë§ˆíŠ¸ ì‹œí‹°, ì˜ë£Œ ì˜ìƒ ë“± **ì‹œê° ë°ì´í„°** í™œìš© ë¶„ì•¼ê°€ ê¸‰ì„±ì¥  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ CCTV ì˜ìƒì—ì„œ ì‚¬ëŒ/ì°¨ëŸ‰ ê²€ì¶œ í”„ë¡œì íŠ¸  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ ì˜ë£Œ ì˜ìƒ AI, AR/VR ì½˜í…ì¸  ì—”ì§€ë‹ˆì–´  \n",
      "\n",
      "---\n",
      "\n",
      "## 7ï¸âƒ£ ìì—°ì–´ ì²˜ë¦¬(NLP) ì—”ì§€ë‹ˆì–´  \n",
      "**ì§ë¬´** : í…ìŠ¤íŠ¸ ë¶„ì„Â·ì±—ë´‡Â·ìš”ì•½Â·ë²ˆì—­Â·ê°ì„± ë¶„ì„ ì‹œìŠ¤í…œ ê°œë°œ  \n",
      "**í•µì‹¬ ê¸°ìˆ **  \n",
      "- Transformers (BERT, GPT, T5)  \n",
      "- Hugging Face, spaCy, NLTK  \n",
      "- ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ (ElasticSearch, Kafka)  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- ê¸°ì—…ì˜ ê³ ê° ì„œë¹„ìŠ¤Â·ë§ˆì¼€íŒ…Â·ë¬¸ì„œ ìë™í™”ì— **ì–¸ì–´ AI**ê°€ í•„ìˆ˜ â†’ ê¾¸ì¤€í•œ ìˆ˜ìš”  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ ë‰´ìŠ¤ ê¸°ì‚¬ ìš”ì•½ ëª¨ë¸ ë§Œë“¤ê¸°  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ ëŒ€í™”í˜• AI, ë„ë©”ì¸ íŠ¹í™” ì–¸ì–´ ëª¨ë¸ êµ¬ì¶•  \n",
      "\n",
      "---\n",
      "\n",
      "## 8ï¸âƒ£ AI ì œí’ˆÂ·ì„œë¹„ìŠ¤ ê¸°íšì (AI PM)  \n",
      "**ì§ë¬´** : AI ì œí’ˆ ë¡œë“œë§µ ì„¤ê³„Â·ìš”êµ¬ì‚¬í•­ ì •ì˜Â·íŒ€ ì¡°ìœ¨Â·ì‹œì¥ ê²€ì¦  \n",
      "**í•µì‹¬ ì—­ëŸ‰**  \n",
      "- AI ê¸°ìˆ  ê¸°ë³¸ ì´í•´ (ëª¨ë¸Â·ë°ì´í„°Â·ì¸í”„ë¼)  \n",
      "- UX/UI ê¸°ì´ˆ, ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì„¤ê³„  \n",
      "- ë°ì´í„°Â·AI í”„ë¡œì íŠ¸ ê´€ë¦¬ (Agile, Scrum)  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- ê¸°ìˆ ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ì—°ê²°í•˜ëŠ” â€œê°€êµâ€ ì—­í•  â†’ ê¸°ìˆ  ì´í•´ë„ê°€ ë†’ì€ ê¸°íšìë¥¼ ê¸°ì—…ì´ ì°¾ìŒ  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ í•™êµÂ·ë™ì•„ë¦¬ AI í”„ë¡œì íŠ¸ ê¸°íšÂ·ì‹œì—°  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ AI ìŠ¤íƒ€íŠ¸ì—… ê³µë™ì°½ì—…, ëŒ€ê¸°ì—… AI ì „ëµíŒ€  \n",
      "\n",
      "---\n",
      "\n",
      "## 9ï¸âƒ£ AI ìœ¤ë¦¬Â·ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ì „ë¬¸ê°€  \n",
      "**ì§ë¬´** : AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ ìˆ˜ë¦½Â·ë°ì´í„° í”„ë¼ì´ë²„ì‹œÂ·ê·œì œ ëŒ€ì‘Â·ê³µì •ì„± ê²€ì¦  \n",
      "**í•µì‹¬ ì§€ì‹**  \n",
      "- ê°œì¸ì •ë³´ ë³´í˜¸ë²•, GDPR, AI ìœ¤ë¦¬ ì›ì¹™  \n",
      "- ë°ì´í„° í’ˆì§ˆÂ·ë¼ë²¨ë§ ê´€ë¦¬  \n",
      "- AI Explainability (SHAP, LIME)  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- AI ê·œì œì™€ ì‚¬íšŒì  ì±…ì„ì´ ê°•ì¡°ë˜ë©´ì„œ **ì „ë¬¸ê°€** ìˆ˜ìš”ê°€ ê¸‰ì¦  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ AI ìœ¤ë¦¬ ì›Œí¬ìˆ ì°¸ì—¬Â·ê´€ë ¨ ë…¼ë¬¸/ë³´ê³ ì„œ ë¦¬ë·°  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ ê¸°ì—… AI ìœ¤ë¦¬ ë‹´ë‹¹, ì •ë¶€Â·ê³µê³µê¸°ê´€ ë°ì´í„° ì •ì±… ìë¬¸  \n",
      "\n",
      "---\n",
      "\n",
      "## ğŸ”Ÿ AI ìŠ¤íƒ€íŠ¸ì—… ì°½ì—…Â·í”„ë¦¬ëœì„œ  \n",
      "**ì§ë¬´** : ì•„ì´ë””ì–´ ë°œêµ´Â·MVP ê°œë°œÂ·íˆ¬ì ìœ ì¹˜Â·ì‹œì¥ ê²€ì¦  \n",
      "**í•µì‹¬ ì¤€ë¹„**  \n",
      "- í•œë‘ ê°œì˜ **í•µì‹¬ ê¸°ìˆ **ì— ê¹Šì´ íŒŒê³ ë“¤ê¸° (ì˜ˆ: ì´ë¯¸ì§€ AI, ì±—ë´‡)  \n",
      "- ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ìº”ë²„ìŠ¤, ë¦° ìŠ¤íƒ€íŠ¸ì—… ë°©ë²•ë¡   \n",
      "- ë„¤íŠ¸ì›Œí‚¹Â·ë©˜í† ë§ (ì°½ì—… ì§€ì›ì„¼í„°, í•´ì»¤í†¤)  \n",
      "\n",
      "**ì™œ ì¢‹ì€ê°€?**  \n",
      "- AI ê¸°ë°˜ ì„œë¹„ìŠ¤ëŠ” **ì´ˆê¸° ì§„ì… ì¥ë²½ì´ ë‚®ì•„** ë¹ ë¥´ê²Œ ì‹œì¥ ê²€ì¦ ê°€ëŠ¥ â†’ ì„±ê³µ ì‹œ ë†’ì€ ë³´ìƒ  \n",
      "\n",
      "**ì…ë¬¸ ë‹¨ê³„** â†’ ëŒ€í•™ ë‚´ ì°½ì—…ë™ì•„ë¦¬Â·í•´ì»¤í†¤ ì°¸ê°€ â†’ ì‘ì€ í”„ë¡œì íŠ¸ MVP ë§Œë“¤ê¸°  \n",
      "**ê³ ê¸‰ ë‹¨ê³„** â†’ ì‹œë“œ íˆ¬ì ìœ ì¹˜Â·ì‹œë¦¬ì¦ˆ A ë¼ìš´ë“œ ì§„í–‰  \n",
      "\n",
      "---\n",
      "\n",
      "## ğŸ“š **ê³µí†µìœ¼ë¡œ ê°–ì¶”ë©´ ì¢‹ì€ ìŠ¤í‚¬**  \n",
      "\n",
      "| ì˜ì—­ | êµ¬ì²´ì ì¸ í•™ìŠµ ë°©ë²• |\n",
      "|------|-------------------|\n",
      "| **í”„ë¡œê·¸ë˜ë°** | Python ê¸°ë³¸ â†’ í”„ë¡œì íŠ¸ ê¸°ë°˜ í•™ìŠµ (GitHubì— ì½”ë“œ ê³µê°œ) |\n",
      "| **ìˆ˜í•™Â·í†µê³„** | Khan Academy, Coursera â€œMathematics for Machine Learningâ€ |\n",
      "| **í´ë¼ìš°ë“œ** | AWS/Azure/GCP ë¬´ë£Œ í‹°ì–´ í™œìš©, â€œAI/ML on Cloudâ€ ì‹¤ìŠµ |\n",
      "| **í˜‘ì—…Â·ì†Œí†µ** | Git í˜‘ì—… íë¦„, Agile ìŠ¤í”„ë¦°íŠ¸ ê²½í—˜ (íŒ€ í”„ë¡œì íŠ¸) |\n",
      "| **í¬íŠ¸í´ë¦¬ì˜¤** | 1~2ê°œì˜ **ì‹¤ì œ ë¬¸ì œ í•´ê²°** í”„ë¡œì íŠ¸ (ë°ì´í„° ì „ì²˜ë¦¬ â†’ ëª¨ë¸ â†’ ë°°í¬) ë¥¼ ë¸”ë¡œê·¸/Notionì— ì •ë¦¬ |\n",
      "| **ìê²©Â·ì¸ì¦** | (ì„ íƒ) AWS Certified Machine Learning â€“ Specialty, Google Cloud Professional Data Engineer ë“± |\n",
      "\n",
      "---\n",
      "\n",
      "## ğŸ—“ï¸ **3â€‘5ë…„ ì°¨ ë¡œë“œë§µ ì˜ˆì‹œ**  \n",
      "\n",
      "| ì—°ë„ | ëª©í‘œ | êµ¬ì²´ì ì¸ ì•¡ì…˜ |\n",
      "|------|------|----------------|\n",
      "| **1í•™ë…„~2í•™ë…„** | ê¸°ì´ˆ í”„ë¡œê·¸ë˜ë°Â·ìˆ˜í•™Â·ë°ì´í„° ë¶„ì„ ìŠµë“ | êµê³¼ëª© ì™¸ì— Python ì…ë¬¸, Kaggle ì´ˆê¸‰ ëŒ€íšŒ, ë°ì´í„° ì‹œê°í™” í”„ë¡œì íŠ¸ |\n",
      "| **3í•™ë…„** | AIÂ·ML ê¸°ë³¸ ëª¨ë¸ êµ¬í˜„ ê²½í—˜ | êµë‚´ AI ê²½ì§„ëŒ€íšŒ ì°¸ê°€, êµìˆ˜Â·ì—°êµ¬ì‹¤ ì¸í„´, ê°„ë‹¨í•œ ì›¹ ì„œë¹„ìŠ¤ì— ëª¨ë¸ ì—°ë™ |\n",
      "| **ì¡¸ì—… ì „** | í¬íŠ¸í´ë¦¬ì˜¤ 2~3ê°œ ì™„ì„± + ì¸í„´ì‹­ | ê¸°ì—…Â·ì—°êµ¬ì†Œ AI ì¸í„´ (MLOps, NLP ë“±), GitHubì— ì½”ë“œ ê³µê°œ |\n",
      "| **ì¡¸ì—… í›„ 1~2ë…„** | ì „ë¬¸ ë¶„ì•¼ ì„ íƒ â†’ ì£¼ë‹ˆì–´ ì—”ì§€ë‹ˆì–´ | ì„ íƒí•œ ë¶„ì•¼(AI ì—”ì§€ë‹ˆì–´, ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ë“±)ì—ì„œ **ì‹¤ë¬´ í”„ë¡œì íŠ¸** ìˆ˜í–‰, í´ë¼ìš°ë“œ ì¸ì¦ ì·¨ë“ |\n",
      "| **3~5ë…„ ì°¨** | ê³ ê¸‰ ì—­í• Â·ë¦¬ë”ì‹­ | MLOps íŒ€ ë¦¬ë“œ, AI ì œí’ˆ ë§¤ë‹ˆì €, í˜¹ì€ ìŠ¤íƒ€íŠ¸ì—… ê³µë™ì°½ì—… ë“± ëª©í‘œì— ë§ê²Œ ê²½ë ¥ ì „í™˜ |\n",
      "\n",
      "---\n",
      "\n",
      "## ğŸ¯ **ë§ˆë¬´ë¦¬ íŒ**  \n",
      "\n",
      "1. **â€œë¬¸ì œ í•´ê²°â€ì— ì´ˆì ** â€“ ê¸°ìˆ ë³´ë‹¤ *ì–´ë–¤ ë¬¸ì œë¥¼ AIë¡œ í’€ ìˆ˜ ìˆëŠëƒ*ê°€ ì±„ìš© ë‹´ë‹¹ìì˜ ëˆˆì— ë•ë‹ˆë‹¤.  \n",
      "2. **ì˜¤í”ˆì†ŒìŠ¤Â·ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬** â€“ GitHub, Hugging Face, Papers With Code ë“±ì—ì„œ ê¸°ì—¬í•˜ë©´ ëˆˆì— ë³´ì´ëŠ” ì‹¤ë ¥ì´ ìŒ“ì…ë‹ˆë‹¤.  \n",
      "3. **ê¾¸ì¤€í•œ í•™ìŠµ** â€“ AIëŠ” ë¹ ë¥´ê²Œ ë³€í•˜ë‹ˆ, ë§¤ì£¼ 2~3ì‹œê°„ì”© ìµœì‹  ë…¼ë¬¸Â·ê¸°ìˆ  ë¸”ë¡œê·¸(ArXiv, Medium) ì½ê¸°ë¥¼ ìŠµê´€í™”í•˜ì„¸ìš”.  \n",
      "4. **ë„¤íŠ¸ì›Œí‚¹** â€“ í•™êµ ë™ì•„ë¦¬, AI ì»¨í¼ëŸ°ìŠ¤, ì˜¨ë¼ì¸ ì„¸ë¯¸ë‚˜(Zoom, MeetUp)ì—ì„œ ì‚¬ëŒì„ ë§Œë‚˜ë©´ ê¸°íšŒê°€ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.  \n",
      "\n",
      "> **ë‹¹ì‹ ì´ ì§€ê¸ˆ ìŒ“ëŠ” ì‘ì€ ì‹¤í—˜Â·í”„ë¡œì íŠ¸ê°€, 5ë…„ ë’¤ â€œAI ì „ë¬¸ê°€â€ë¼ëŠ” í° ê·¸ë¦¼ì„ ì™„ì„±í•˜ëŠ” í¼ì¦ ì¡°ê°**ì´ ë©ë‹ˆë‹¤.  \n",
      "ì§€ê¸ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ í•œ ê±¸ìŒì”© ë‚˜ì•„ê°€ë©´, AI ì‹œëŒ€ì—ë„ ìì‹ ê° ìˆê²Œ í™œèºí•  ìˆ˜ ìˆì„ ê±°ì˜ˆìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\n",
    "1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\n",
    "- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\n",
    "- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\n",
    "- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° ì²´ì¸ êµ¬ì„±\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": \"ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©í•™ê³¼ë¥¼ ì¬í•™ì¤‘ì¸ë° ì¡¸ì—… í›„ ìš”ì¦˜ AIë•Œë¬¸ì— ë¯¸ë˜ë¥¼ ìƒê°í–ˆì„ë•Œ ì·¨ì—…í•˜ê¸° ì¢‹ì€ ì§ì—…ì„ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* í”„ë¡¬í”„íŠ¸ë¥¼ ë” ë™ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, AI ì‘ë‹µì„ ë” ì¼ê´€ì„± ìˆê²Œ ì¡°ì • ê°€ëŠ¥í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " í”„ë¡¬í”„íŠ¸: ê°€ì„ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ íƒœí’ ë°œìƒì´ ë§ë‚˜ìš”? ê°€ì„ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒì„ 3ê°œ ì•Œë ¤ì£¼ì„¸ìš”\n",
      " ëª¨ë¸ ì‘ë‹µ: **ê°€ì„ì— ì£¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ**  \n",
      "\n",
      "| # | í˜„ìƒ | ì™œ ê°€ì„ì— ë§ì´ ë‚˜íƒ€ë‚˜ëŠ”ê°€? (ì£¼ìš” ë©”ì»¤ë‹ˆì¦˜) | ì£¼ìš” ì˜í–¥Â·ê´€ì¸¡ íŠ¹ì§• |\n",
      "|---|------|---------------------------------------------|-------------------|\n",
      "| 1 | **íƒœí’(ì—´ëŒ€ ì €ê¸°ì••) ë°œìƒÂ·ì ‘ê·¼** | â€¢ 7Â·8ì›”ì— ê°€ì¥ í™œë°œí•œ ì—´ëŒ€ ì €ê¸°ì••ì´ í˜•ì„±ë˜ì§€ë§Œ, **ê°€ì„ ì´ˆ(9ì›”~10ì›”)** ì€ ë‚¨ì„œìª½ íƒœí‰ì–‘ì˜ í•´ìˆ˜ë©´ ì˜¨ë„ê°€ ì•„ì§ 26â€¯Â°Câ€¯~â€¯28â€¯Â°C ë¡œ ë†’ì•„ íƒœí’ì´ ê³„ì† ë°œë‹¬í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì´ ìœ ì§€ë©ë‹ˆë‹¤.<br>â€¢ ê°€ì„ì´ ë˜ë©´ ì„œìª½ íƒœí‰ì–‘ ê³ ê¸°ì••(íƒœí‰ì–‘ ê³ ê¸°ì••Â·ë™ì•„ì‹œì•„ ê³ ê¸°ì••)ì´ ì„œì„œíˆ ë‚¨í•˜í•˜ë©´ì„œ, íƒœí’ì´ ë¶ìª½ìœ¼ë¡œ ì´ë™Â·ì§„ë¡œê°€ ë°”ë€Œì–´ í•œë°˜ë„Â·ë™ë¶ì•„ ì§€ì—­ì— ì ‘ê·¼í•˜ê¸° ì‰¬ì›Œì§‘ë‹ˆë‹¤. | â€¢ ê°•í’Â·í­ìš°Â·í•´ì¼(Storm surge) ë“± ì¬í•´ ìœ„í—˜ì´ ê¸‰ì¦.<br>â€¢ ê¸°ìƒì²­Â·ìœ„ì„±Â·ë ˆì´ë‹¤ë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì¶”ì ì´ í™œë°œíˆ ì´ë£¨ì–´ì§. |\n",
      "| 2 | **ì¤‘ìœ„ë„ ì €ê¸°ì••Â·ì „ì„  í™œë™ ê°•í™”** (ëƒ‰ë‚œë¥˜ êµì°¨) | â€¢ ê°€ì„ì€ **ì—¬ë¦„ì²  ê³ ì˜¨Â·ìŠµí•œ ëŒ€ë¥˜ì™€ ê²¨ìš¸ì²  ì°¨ê°€ìš´ ëŒ€ë¥™ ê³ ê¸°ì••** ì‚¬ì´ì˜ ì „ì´ê¸°.<br>â€¢ ë‚¨ìª½ì—ì„œ ë”°ëœ»í•˜ê³  ìŠµí•œ í•´ì–‘ì„± ê³µê¸°ê°€, ë¶ìª½ì—ì„œ ì°¨ê°€ìš´ ëŒ€ë¥™ì„± ê³µê¸°ê°€ ë§Œë‚˜ë©´ì„œ **ì „ì„ (íŠ¹íˆ í•œë­ ì „ì„ )ê³¼ ì €ê¸°ì••**ì´ ìì£¼ í˜•ì„±ë©ë‹ˆë‹¤.<br>â€¢ ì œíŠ¸ê¸°ë¥˜ê°€ ë‚¨ìª½ìœ¼ë¡œ ë‚´ë ¤ì˜¤ë©´ì„œ ì „ì„ ì˜ ì´ë™ ì†ë„ê°€ ë¹¨ë¼ì§€ê³ , ì €ê¸°ì••ì˜ ê°•ë„ê°€ ê°•í™”ë©ë‹ˆë‹¤. | â€¢ ê¸‰ê²©í•œ ê¸°ì˜¨ ê°•í•˜, ê°•ìˆ˜(ì†Œë‚˜ê¸°Â·í­ìš°)ì™€ ë°”ëŒì´ ë™ë°˜ë˜ëŠ” ë‚ ì”¨.<br>â€¢ êµí†µÂ·ë†ì—…Â·ì—ë„ˆì§€(ë‚œë°©) ìˆ˜ìš”ì— í° ì˜í–¥ì„ ë¯¸ì¹¨. |\n",
      "| 3 | **ëŒ€ê¸° ì˜¨ë„ì—­ì „Â·ì•ˆê°œÂ·ì—°ë¬´ ë°œìƒ** | â€¢ ê°€ì„ ë°¤ì—ëŠ” **ì§€í‘œë©´ì´ ê¸‰ê²©íˆ ëƒ‰ê°**ë˜ê³ , ìœ„ì¸µì— ë‚¨ì•„ ìˆë˜ ì—¬ë¦„ì˜ ë”°ëœ»í•œ ê³µê¸°ê°€ ìœ„ì— ë¨¸ë¬´ë¥´ê²Œ ë©ë‹ˆë‹¤.<br>â€¢ ì´ë•Œ **ì˜¨ë„ì—­ì „ì¸µ**ì´ í˜•ì„±ë¼ ìˆ˜ì§ í˜¼í•©ì´ ì–µì œë˜ê³ , ìŠµë„ê°€ ë†’ì€ ì €ì¸µ ê³µê¸°ê°€ í¬í™”ìƒíƒœì— ê°€ê¹Œì›Œì ¸ **ì•ˆê°œÂ·ì—°ë¬´**ê°€ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤.<br>â€¢ íŠ¹íˆ í•´ì•ˆÂ·ê°•ë³€Â·ì‚°ê°„ ê³„ê³¡ ë“± ì§€í˜•ì ì¸ ìš”ì¸ì´ ê²°í•©í•˜ë©´ ì•ˆê°œì˜ ì§€ì† ì‹œê°„ì´ ê¸¸ì–´ì§‘ë‹ˆë‹¤. | â€¢ ê°€ì‹œê±°ë¦¬ ì €í•˜ â†’ í•­ê³µÂ·í•´ìš´Â·ë„ë¡œ êµí†µì— ì§€ì¥.<br>â€¢ ëŒ€ê¸°ì˜¤ì—¼ ë¬¼ì§ˆ(ì˜ˆ: ë¯¸ì„¸ë¨¼ì§€Â·í™©ì‚¬)ì˜ í•˜ê°• ë° ë†ì¶•ì„ ì´‰ì§„. |\n",
      "\n",
      "---\n",
      "\n",
      "### ìš”ì•½\n",
      "\n",
      "- **íƒœí’**ì€ ê°€ì„ ì´ˆì— ê°€ì¥ í™œë°œíˆ ë‚˜íƒ€ë‚˜ëŠ” ëŒ€í‘œì ì¸ í˜„ìƒì´ë©°, â€œê°€ì„ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒâ€ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ê°€ì„ì—ëŠ” ì´ ì™¸ì—ë„ **ì¤‘ìœ„ë„ ì €ê¸°ì••Â·ì „ì„  í™œë™**ê³¼ **ëŒ€ê¸° ì˜¨ë„ì—­ì „Â·ì•ˆê°œ**ì™€ ê°™ì€ í˜„ìƒì´ ë™ì‹œì— ë§ì´ ë°œìƒí•©ë‹ˆë‹¤.  \n",
      "- ì´ ì„¸ ê°€ì§€ í˜„ìƒì€ ëª¨ë‘ **ëŒ€ê¸°Â·í•´ì–‘ì˜ ì—´Â·ìˆ˜ë¶„ íë¦„ì´ ê³„ì ˆ ì „ì´ ê³¼ì •ì—ì„œ ê¸‰ê²©íˆ ë³€í•  ë•Œ** ë‚˜íƒ€ë‚˜ëŠ” í˜„ìƒìœ¼ë¡œ, ê¸°ìƒÂ·ì¬í•´ ëŒ€ë¹„ì— ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ê°–ìŠµë‹ˆë‹¤.  \n",
      "\n",
      "í•„ìš”í•˜ì‹œë©´ ê° í˜„ìƒì˜ ìì„¸í•œ ì‹œê³„ì—´ ìë£Œ(ì˜ˆ: ê¸°ìƒì²­ ê´€ì¸¡ ê·¸ë˜í”„)ë‚˜ ëŒ€ë¹„Â·ì˜ˆë°© íŒë„ ì¶”ê°€ë¡œ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–¸ì œë“  ì§ˆë¬¸ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë¶€ë¶„ ë³€ìˆ˜ ì ìš©)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ {phenomenon}ì´ ë§ë‚˜ìš”? {season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒì„ 3ê°œ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "    input_variables=[\"phenomenon\"],  # ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n",
    "    partial_variables={\"season\": get_current_season()}  # ë™ì ìœ¼ë¡œ ê³„ì ˆ ê°’ í• ë‹¹\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# íŠ¹ì • ê³„ì ˆì˜ í˜„ìƒ ì§ˆì˜\n",
    "query = prompt.format(phenomenon=\"íƒœí’ ë°œìƒ\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\" í”„ë¡¬í”„íŠ¸: {query}\")\n",
    "print(f\" ëª¨ë¸ ì‘ë‹µ: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ê³„ì ˆ: ê°€ì„\n",
      "\n",
      " ê°€ì„ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ:\n",
      "ê°€ì„ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "*   **í¸ì„œí’ì˜ ê³„ì ˆ ë³€í™”**: ê°€ì„ì´ ë˜ë©´ ë¶ë°˜êµ¬ì—ì„œ ë‚®ê³¼ ë°¤ì˜ ê¸¸ì´(ì¼êµì°¨)ê°€ ì§§ì•„ì§€ê²Œ ë˜ë©°, í¸ì„œí’ì˜ ìœ„ì¹˜ê°€ ë‚¨ìª½ìœ¼ë¡œ ì´ë™í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ìš°ë¦¬ë‚˜ë¼ì—ëŠ” ë”°ëœ»í•œ ë¶íƒœí‰ì–‘ ê¸°ë‹¨ê³¼ ì°¨ê°€ìš´ ì˜¤í˜¸ì¸ í¬ í•´ ê¸°ë‹¨ì´ ë§Œë‚˜ì„œ í˜•ì„±ëœ ì „ì„ ì˜ ì˜í–¥ìœ¼ë¡œ ë¹„ê°€ ìì£¼ ë‚´ë¦¬ê²Œ ë©ë‹ˆë‹¤.\n",
      "\n",
      "*   **ì„±ì¸µê¶Œ ì˜¤ì¡´ì¸µ ê°ì†Œ**: ê°€ì„ì´ ë˜ë©´ ì§€êµ¬ì˜ ìì „ì¶•ì— ë”°ë¥¸ íƒœì–‘ ë¹›ì˜ ì…ì‚¬ê°ë„ ë³€í™”ë¡œ ì¸í•´ ì˜¤ì¡´ì¸µì´ ì•½í™”ë˜ì–´ ì˜¤ì¡´ì¸µì˜ êµ¬ë©ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ìì™¸ì„  ì°¨ë‹¨ íš¨ê³¼ê°€ ì•½í™”ë˜ì–´ ì¸ì²´ì— ë¯¸ì¹˜ëŠ” í”¼í•´ê°€ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "*   **ë¶ë°˜êµ¬ ë‹¨í’**: ê°€ì„ì´ ë˜ë©´ ë¶ë°˜êµ¬ì˜ ë‚®ì˜ ê¸¸ì´ê°€ ì§§ì•„ì§€ê²Œ ë˜ë©°, ë°¤ê³¼ ë‚®ì˜ ì¼êµì°¨ê°€ ì»¤ì§€ê²Œ ë©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë‚˜ë¬´ì˜ ìì´ ë³€ìƒ‰ë˜ì–´ ë‹¨í’ì´ ë°œìƒí•˜ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë‹¨í’ì€ ëŒ€ê°œ 10ì›” ì¤‘ìˆœì— ì ˆì •ì— ì´ë¥´ê²Œ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# Step 1: í˜„ì¬ ê³„ì ˆ ê²°ì •\n",
    "season = get_current_season(\"north\")  # ê³„ì ˆ ê°’ ì–»ê¸°\n",
    "print(f\"í˜„ì¬ ê³„ì ˆ: {season}\")\n",
    "\n",
    "# Step 2: í•´ë‹¹ ê³„ì ˆì˜ ìì—° í˜„ìƒ ì¶”ì²œ\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \"\n",
    "    \"ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# ì²´ì¸ 2: ìì—° í˜„ìƒ ì¶”ì²œ (ì…ë ¥: ê³„ì ˆ â†’ ì¶œë ¥: ìì—° í˜„ìƒ ëª©ë¡)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season}  # chain1ì˜ ì¶œë ¥ì„ season ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰: í˜„ì¬ ê³„ì ˆì— ë”°ë¥¸ ìì—° í˜„ìƒ ì¶”ì²œ\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season}ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API í˜¸ì¶œ ë°ì´í„°, ì‹œê°„ ì •ë³´, ì‚¬ìš©ì ì •ë³´ ë“±ì„ ë°˜ì˜í•  ë•Œ ë§¤ìš° ìœ ìš©í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " í”„ë¡¬í”„íŠ¸: í˜„ì¬ 1ë‹¬ëŸ¬ = 1377.98ì› ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n",
      " ëª¨ë¸ ì‘ë‹µ: ## Summary\n",
      "\n",
      "Based on the current exchange rate of 1 USD = 1,377.98 KRW, this response provides an analysis of the currency market.\n",
      "\n",
      "## Analysis\n",
      "\n",
      "The current exchange rate of 1 USD = 1,377.98 KRW indicates that the Korean won (KRW) is relatively weak compared to the US dollar (USD). A higher exchange rate means that it takes more won to buy one dollar.\n",
      "\n",
      "## Possible Reasons for the Exchange Rate\n",
      "\n",
      "Several factors contribute to the current exchange rate:\n",
      "\n",
      "*   **Economic indicators**: Korea's economic growth rate, inflation rate, and interest rates influence the value of the won.\n",
      "*   **Global market trends**: The US dollar's value against other major currencies, such as the euro and yen, also affects the KRW/USD exchange rate.\n",
      "*   **Trade balance**: Korea's trade balance, including exports and imports, impacts the demand for and supply of won and dollars.\n",
      "*   **Capital flows**: Foreign investment in Korea and Korean investment abroad influence the exchange rate.\n",
      "\n",
      "## Implications\n",
      "\n",
      "The current exchange rate may have implications for:\n",
      "\n",
      "*   **Exporters and importers**: A weaker won can make Korean exports more competitive in the global market, but it may also increase the cost of imports.\n",
      "*   **Investors**: The exchange rate affects the attractiveness of Korean assets to foreign investors and vice versa.\n",
      "*   **Tourists and travelers**: A weaker won can make traveling to Korea more expensive for foreigners, while a stronger won can make traveling abroad more affordable for Koreans.\n",
      "\n",
      "## Outlook\n",
      "\n",
      "The exchange rate may fluctuate based on various market and economic factors. It is essential to monitor economic indicators, global market trends, and geopolitical events to predict future exchange rate movements.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The current exchange rate of 1 USD = 1,377.98 KRW reflects the complex interactions of various economic and market factors. Understanding these factors and their implications can help individuals and businesses make informed decisions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì‹¤ì‹œê°„ í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1ë‹¬ëŸ¬ = {data['rates']['KRW']}ì›\"\n",
    "\n",
    "# Partial Prompt í™œìš©\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[],  # ì‚¬ìš©ì ì…ë ¥ ì—†ìŒ\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ìë™ ë°˜ì˜\n",
    ")\n",
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì •\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\" í”„ë¡¬í”„íŠ¸:\", prompt.format())\n",
    "print(\" ëª¨ë¸ ì‘ë‹µ:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
